{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet_65.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kKCZKCvxwcdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "28ec7ee8-6a53-4b55-ec6d-a72773ee699f"
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install Pillow==4.0.0\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Collecting pillow>=4.1.1 (from torchvision)\n",
            "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Installing collected packages: pillow\n",
            "  Found existing installation: Pillow 4.0.0\n",
            "    Uninstalling Pillow-4.0.0:\n",
            "      Successfully uninstalled Pillow-4.0.0\n",
            "Successfully installed pillow-5.3.0\n",
            "Collecting Pillow==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Opyd_G9mwXs4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from zipfile import ZipFile\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vz255ihwoCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bVr6JddnBsG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "listed = drive.ListFile().GetList()\n",
        "for file in listed:\n",
        "    print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LW0AEY1twrbl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id': '1nJeSkGcVqeYD40rLyjlzCFBhFkmUmCSH'})\n",
        "downloaded.GetContentFile('train.zip')\n",
        "with ZipFile(\"train.zip\", 'r') as z:\n",
        "    z.extractall()\n",
        "os.remove(\"train.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T05EtlovwXtF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TGSSaltTrainDataset(Dataset):\n",
        "    def __init__(self, image_dir,mask_dir,depth_csv,train_csv):\n",
        "        self.image_dir=image_dir\n",
        "        self.mask_dir=mask_dir\n",
        "        \n",
        "        depth=pd.read_csv(depth_csv)\n",
        "        depth[\"z\"]=(depth[\"z\"]-depth[\"z\"].min())/(depth[\"z\"].max()-depth[\"z\"].min())\n",
        "        self.filter = np.array([(0,-1,-1,-1),(1,0,0,0),(1,0,1,0),(0,1,0,1)])/8\n",
        "        self.input = pd.read_csv(train_csv)\n",
        "        self.input.drop(['rle_mask'],axis=1,inplace=True)\n",
        "        self.input = self.input.merge(depth,how=\"left\",on=\"id\")\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir,self.input.iloc[idx,0]+\".png\")\n",
        "        img = cv2.imread(img_name)\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "        img1 = cv2.filter2D(img,-1,self.filter)\n",
        "        \n",
        "        sigma=0.33\n",
        "        \n",
        "        \n",
        "        v = np.median(img1)\n",
        "\n",
        "        #---- apply automatic Canny edge detection using the computed median----\n",
        "        lower = int(max(0, (1.0 - sigma) * v))\n",
        "        upper = int(min(255, (1.0 + sigma) * v))\n",
        "        img1 = cv2.Canny(img1, lower, upper)\n",
        "        \n",
        "        img2 = (cv2.Laplacian(img, cv2.CV_32F) + 127.0)\n",
        "#         img2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        img = torch.tensor(img).view(1,101,101).float()\n",
        "        img1 = torch.tensor(img1).view(1,101,101).float()\n",
        "        img2 = torch.tensor(img2).view(1,101,101)\n",
        "        \n",
        "        img = torch.cat((img,img1,img2),dim=0)/255\n",
        "        \n",
        "        mask_name = os.path.join(self.mask_dir,self.input.iloc[idx,0]+\".png\")\n",
        "        mask = cv2.imread(mask_name)\n",
        "        mask = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
        "        mask = torch.tensor(mask).float()/255\n",
        "        return img,mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bgQNyCiXwXtM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = TGSSaltTrainDataset(\"images\",\"masks\",\"depths.csv\",\"train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HPrgWtu2wXtU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "validation_split = 0.2\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "validation_sampler = SubsetRandomSampler(val_indices)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ILpmwaDtwXth",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BinaryCrossEntropyLoss2d(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        \"\"\"\n",
        "        Binary cross entropy loss 2D\n",
        "        Args:\n",
        "            weight:\n",
        "            size_average:\n",
        "        \"\"\"\n",
        "        super(BinaryCrossEntropyLoss2d, self).__init__()\n",
        "        self.bce_loss = nn.BCELoss(weight, size_average)\n",
        "        if torch.cuda.is_available():\n",
        "            self.bce_loss = self.bce_loss.cuda()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = F.sigmoid(pred)\n",
        "        pred = pred.view(-1)  # Flatten\n",
        "        target = target.view(-1)  # Flatten\n",
        "        return self.bce_loss(pred, target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cLvCr3IQwXtm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "    def forward(self, pred, target):\n",
        "        smooth = 1\n",
        "        num = target.size(0)\n",
        "        pred = F.sigmoid(pred)\n",
        "        pred = pred.view(num, -1)\n",
        "        target = target.view(num, -1)\n",
        "        intersection = (pred * target)\n",
        "        score = 2. * (intersection.sum(1) + smooth) / (pred.sum(1) + target.sum(1) + smooth)\n",
        "        score = 1 - score.sum() / num\n",
        "        return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9CU7PcdGwXtt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_coeff(pred, target):\n",
        "    smooth = 1.\n",
        "    num = target.size(0)\n",
        "    pred = pred.view(num, -1)  # Flatten\n",
        "    target = target.view(num, -1)  # Flatten\n",
        "    intersection = (pred * target)\n",
        "    score = (2. * intersection.sum(1) + smooth).float() / (pred.sum(1) + target.sum(1) + smooth).float()\n",
        "    return score.sum()/num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcxIxXq5wXtz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return 0.5*BinaryCrossEntropyLoss2d()(y_true, y_pred)-dice_coeff(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OL9OQNTawXt-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=UNet(30,1)\n",
        "criterion = SoftDiceLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "krdeJDd5wXuL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate(threshold):\n",
        "    total_loss = 0\n",
        "    accuracy = 0\n",
        "    model.eval()\n",
        "    for batch_idx, (data,target) in enumerate(validation_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        # forward\n",
        "        output = model(data)\n",
        "        predict = (F.sigmoid(output) > threshold).float()\n",
        "        # backward + optimize\n",
        "        loss = criterion(predict, target)\n",
        "        # print statistics\n",
        "        accuracy += dice_coeff(predict, target).item()\n",
        "        total_loss+=loss.item()\n",
        "    print('Validation Loss: {:.5f} Validation Accuracy: {:.5f}'.format(total_loss*batch_size/len(val_indices),accuracy*batch_size/len(val_indices)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ci5neK7wXuU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(threshold):\n",
        "    epoch=1\n",
        "    while True:\n",
        "        total_loss = 0\n",
        "        total_accuracy = 0\n",
        "        model.train()\n",
        "        exp_lr_scheduler.step()\n",
        "        print(exp_lr_scheduler.get_lr())\n",
        "        for batch_idx, (data,target) in enumerate(train_loader):\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "                target = target.cuda()\n",
        "            # forward\n",
        "            output = model(data)\n",
        "            predict = (F.sigmoid(output) > threshold).float()\n",
        "            # backward + optimize\n",
        "            loss = criterion(output, target)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # print statistics\n",
        "            accuracy = dice_coeff(predict, target)\n",
        "            total_accuracy+=accuracy\n",
        "            total_loss+=loss\n",
        "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.5f}\\tAccuracy: {:.5f}'.format(epoch, (batch_idx + 1) * len(data), len(train_indices),100*(batch_idx + 1)* len(data) / len(train_indices), loss.item(),accuracy))\n",
        "        print('Train Loss: {:.5f} Train Accuracy: {:.5f}'.format(total_loss.item()*batch_size/len(train_indices),total_accuracy.item()*batch_size/len(train_indices)))\n",
        "        validate(threshold)\n",
        "        epoch+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1XQF7jq5wXud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41342
        },
        "outputId": "94b0563b-b74c-49eb-d893-a1608196f661"
      },
      "cell_type": "code",
      "source": [
        "train(0.5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.001]\n",
            "Epoch: 1 [50/3200 (2%)]\tLoss: 0.77395\tAccuracy: 0.15785\n",
            "Epoch: 1 [100/3200 (3%)]\tLoss: 0.77017\tAccuracy: 0.28543\n",
            "Epoch: 1 [150/3200 (5%)]\tLoss: 0.75423\tAccuracy: 0.30140\n",
            "Epoch: 1 [200/3200 (6%)]\tLoss: 0.63498\tAccuracy: 0.46187\n",
            "Epoch: 1 [250/3200 (8%)]\tLoss: 0.69970\tAccuracy: 0.33683\n",
            "Epoch: 1 [300/3200 (9%)]\tLoss: 0.72061\tAccuracy: 0.33162\n",
            "Epoch: 1 [350/3200 (11%)]\tLoss: 0.69251\tAccuracy: 0.37427\n",
            "Epoch: 1 [400/3200 (12%)]\tLoss: 0.71903\tAccuracy: 0.32846\n",
            "Epoch: 1 [450/3200 (14%)]\tLoss: 0.64421\tAccuracy: 0.41695\n",
            "Epoch: 1 [500/3200 (16%)]\tLoss: 0.81807\tAccuracy: 0.21709\n",
            "Epoch: 1 [550/3200 (17%)]\tLoss: 0.71801\tAccuracy: 0.33596\n",
            "Epoch: 1 [600/3200 (19%)]\tLoss: 0.71115\tAccuracy: 0.33214\n",
            "Epoch: 1 [650/3200 (20%)]\tLoss: 0.63779\tAccuracy: 0.43325\n",
            "Epoch: 1 [700/3200 (22%)]\tLoss: 0.67204\tAccuracy: 0.37749\n",
            "Epoch: 1 [750/3200 (23%)]\tLoss: 0.62441\tAccuracy: 0.44177\n",
            "Epoch: 1 [800/3200 (25%)]\tLoss: 0.74590\tAccuracy: 0.29768\n",
            "Epoch: 1 [850/3200 (27%)]\tLoss: 0.68070\tAccuracy: 0.36939\n",
            "Epoch: 1 [900/3200 (28%)]\tLoss: 0.68571\tAccuracy: 0.36299\n",
            "Epoch: 1 [950/3200 (30%)]\tLoss: 0.66579\tAccuracy: 0.38518\n",
            "Epoch: 1 [1000/3200 (31%)]\tLoss: 0.79288\tAccuracy: 0.23775\n",
            "Epoch: 1 [1050/3200 (33%)]\tLoss: 0.69877\tAccuracy: 0.34082\n",
            "Epoch: 1 [1100/3200 (34%)]\tLoss: 0.73458\tAccuracy: 0.31033\n",
            "Epoch: 1 [1150/3200 (36%)]\tLoss: 0.63117\tAccuracy: 0.44087\n",
            "Epoch: 1 [1200/3200 (38%)]\tLoss: 0.63662\tAccuracy: 0.41340\n",
            "Epoch: 1 [1250/3200 (39%)]\tLoss: 0.59160\tAccuracy: 0.46685\n",
            "Epoch: 1 [1300/3200 (41%)]\tLoss: 0.66402\tAccuracy: 0.39185\n",
            "Epoch: 1 [1350/3200 (42%)]\tLoss: 0.74724\tAccuracy: 0.29486\n",
            "Epoch: 1 [1400/3200 (44%)]\tLoss: 0.69474\tAccuracy: 0.35775\n",
            "Epoch: 1 [1450/3200 (45%)]\tLoss: 0.67920\tAccuracy: 0.36776\n",
            "Epoch: 1 [1500/3200 (47%)]\tLoss: 0.73330\tAccuracy: 0.30082\n",
            "Epoch: 1 [1550/3200 (48%)]\tLoss: 0.65910\tAccuracy: 0.39649\n",
            "Epoch: 1 [1600/3200 (50%)]\tLoss: 0.69222\tAccuracy: 0.33748\n",
            "Epoch: 1 [1650/3200 (52%)]\tLoss: 0.68243\tAccuracy: 0.36257\n",
            "Epoch: 1 [1700/3200 (53%)]\tLoss: 0.60688\tAccuracy: 0.45002\n",
            "Epoch: 1 [1750/3200 (55%)]\tLoss: 0.63614\tAccuracy: 0.41750\n",
            "Epoch: 1 [1800/3200 (56%)]\tLoss: 0.73184\tAccuracy: 0.29623\n",
            "Epoch: 1 [1850/3200 (58%)]\tLoss: 0.55616\tAccuracy: 0.50711\n",
            "Epoch: 1 [1900/3200 (59%)]\tLoss: 0.76888\tAccuracy: 0.25575\n",
            "Epoch: 1 [1950/3200 (61%)]\tLoss: 0.74054\tAccuracy: 0.28460\n",
            "Epoch: 1 [2000/3200 (62%)]\tLoss: 0.76770\tAccuracy: 0.25976\n",
            "Epoch: 1 [2050/3200 (64%)]\tLoss: 0.72224\tAccuracy: 0.31744\n",
            "Epoch: 1 [2100/3200 (66%)]\tLoss: 0.58426\tAccuracy: 0.46001\n",
            "Epoch: 1 [2150/3200 (67%)]\tLoss: 0.63617\tAccuracy: 0.43115\n",
            "Epoch: 1 [2200/3200 (69%)]\tLoss: 0.63613\tAccuracy: 0.42077\n",
            "Epoch: 1 [2250/3200 (70%)]\tLoss: 0.67034\tAccuracy: 0.36796\n",
            "Epoch: 1 [2300/3200 (72%)]\tLoss: 0.65554\tAccuracy: 0.38018\n",
            "Epoch: 1 [2350/3200 (73%)]\tLoss: 0.70649\tAccuracy: 0.32484\n",
            "Epoch: 1 [2400/3200 (75%)]\tLoss: 0.68057\tAccuracy: 0.34833\n",
            "Epoch: 1 [2450/3200 (77%)]\tLoss: 0.69922\tAccuracy: 0.32187\n",
            "Epoch: 1 [2500/3200 (78%)]\tLoss: 0.65205\tAccuracy: 0.37081\n",
            "Epoch: 1 [2550/3200 (80%)]\tLoss: 0.59210\tAccuracy: 0.44284\n",
            "Epoch: 1 [2600/3200 (81%)]\tLoss: 0.70765\tAccuracy: 0.31974\n",
            "Epoch: 1 [2650/3200 (83%)]\tLoss: 0.61979\tAccuracy: 0.41114\n",
            "Epoch: 1 [2700/3200 (84%)]\tLoss: 0.59030\tAccuracy: 0.45408\n",
            "Epoch: 1 [2750/3200 (86%)]\tLoss: 0.68996\tAccuracy: 0.33253\n",
            "Epoch: 1 [2800/3200 (88%)]\tLoss: 0.61924\tAccuracy: 0.40815\n",
            "Epoch: 1 [2850/3200 (89%)]\tLoss: 0.68679\tAccuracy: 0.33681\n",
            "Epoch: 1 [2900/3200 (91%)]\tLoss: 0.66356\tAccuracy: 0.36132\n",
            "Epoch: 1 [2950/3200 (92%)]\tLoss: 0.64626\tAccuracy: 0.37543\n",
            "Epoch: 1 [3000/3200 (94%)]\tLoss: 0.69868\tAccuracy: 0.32959\n",
            "Epoch: 1 [3050/3200 (95%)]\tLoss: 0.64506\tAccuracy: 0.38632\n",
            "Epoch: 1 [3100/3200 (97%)]\tLoss: 0.69985\tAccuracy: 0.32082\n",
            "Epoch: 1 [3150/3200 (98%)]\tLoss: 0.68914\tAccuracy: 0.34337\n",
            "Epoch: 1 [3200/3200 (100%)]\tLoss: 0.64278\tAccuracy: 0.38419\n",
            "Train Loss: 0.68202 Train Accuracy: 0.35918\n",
            "Validation Loss: 0.71346 Validation Accuracy: 0.37722\n",
            "[0.001]\n",
            "Epoch: 2 [50/3200 (2%)]\tLoss: 0.69863\tAccuracy: 0.33357\n",
            "Epoch: 2 [100/3200 (3%)]\tLoss: 0.65736\tAccuracy: 0.36115\n",
            "Epoch: 2 [150/3200 (5%)]\tLoss: 0.76618\tAccuracy: 0.25277\n",
            "Epoch: 2 [200/3200 (6%)]\tLoss: 0.65977\tAccuracy: 0.37280\n",
            "Epoch: 2 [250/3200 (8%)]\tLoss: 0.76232\tAccuracy: 0.25716\n",
            "Epoch: 2 [300/3200 (9%)]\tLoss: 0.70308\tAccuracy: 0.33044\n",
            "Epoch: 2 [350/3200 (11%)]\tLoss: 0.66181\tAccuracy: 0.36373\n",
            "Epoch: 2 [400/3200 (12%)]\tLoss: 0.61565\tAccuracy: 0.40698\n",
            "Epoch: 2 [450/3200 (14%)]\tLoss: 0.67698\tAccuracy: 0.34243\n",
            "Epoch: 2 [500/3200 (16%)]\tLoss: 0.62183\tAccuracy: 0.39194\n",
            "Epoch: 2 [550/3200 (17%)]\tLoss: 0.64874\tAccuracy: 0.38031\n",
            "Epoch: 2 [600/3200 (19%)]\tLoss: 0.58023\tAccuracy: 0.44957\n",
            "Epoch: 2 [650/3200 (20%)]\tLoss: 0.56870\tAccuracy: 0.46397\n",
            "Epoch: 2 [700/3200 (22%)]\tLoss: 0.69165\tAccuracy: 0.32524\n",
            "Epoch: 2 [750/3200 (23%)]\tLoss: 0.59512\tAccuracy: 0.42457\n",
            "Epoch: 2 [800/3200 (25%)]\tLoss: 0.63680\tAccuracy: 0.38162\n",
            "Epoch: 2 [850/3200 (27%)]\tLoss: 0.56627\tAccuracy: 0.45665\n",
            "Epoch: 2 [900/3200 (28%)]\tLoss: 0.66702\tAccuracy: 0.35033\n",
            "Epoch: 2 [950/3200 (30%)]\tLoss: 0.61441\tAccuracy: 0.39835\n",
            "Epoch: 2 [1000/3200 (31%)]\tLoss: 0.58983\tAccuracy: 0.44011\n",
            "Epoch: 2 [1050/3200 (33%)]\tLoss: 0.62618\tAccuracy: 0.41722\n",
            "Epoch: 2 [1100/3200 (34%)]\tLoss: 0.72082\tAccuracy: 0.30386\n",
            "Epoch: 2 [1150/3200 (36%)]\tLoss: 0.58644\tAccuracy: 0.43204\n",
            "Epoch: 2 [1200/3200 (38%)]\tLoss: 0.55060\tAccuracy: 0.47389\n",
            "Epoch: 2 [1250/3200 (39%)]\tLoss: 0.62654\tAccuracy: 0.39618\n",
            "Epoch: 2 [1300/3200 (41%)]\tLoss: 0.57522\tAccuracy: 0.45973\n",
            "Epoch: 2 [1350/3200 (42%)]\tLoss: 0.55426\tAccuracy: 0.48039\n",
            "Epoch: 2 [1400/3200 (44%)]\tLoss: 0.60597\tAccuracy: 0.43469\n",
            "Epoch: 2 [1450/3200 (45%)]\tLoss: 0.62891\tAccuracy: 0.39615\n",
            "Epoch: 2 [1500/3200 (47%)]\tLoss: 0.51037\tAccuracy: 0.52700\n",
            "Epoch: 2 [1550/3200 (48%)]\tLoss: 0.63753\tAccuracy: 0.38163\n",
            "Epoch: 2 [1600/3200 (50%)]\tLoss: 0.58240\tAccuracy: 0.43962\n",
            "Epoch: 2 [1650/3200 (52%)]\tLoss: 0.66434\tAccuracy: 0.35141\n",
            "Epoch: 2 [1700/3200 (53%)]\tLoss: 0.64088\tAccuracy: 0.39139\n",
            "Epoch: 2 [1750/3200 (55%)]\tLoss: 0.66931\tAccuracy: 0.34556\n",
            "Epoch: 2 [1800/3200 (56%)]\tLoss: 0.69346\tAccuracy: 0.32365\n",
            "Epoch: 2 [1850/3200 (58%)]\tLoss: 0.63242\tAccuracy: 0.40892\n",
            "Epoch: 2 [1900/3200 (59%)]\tLoss: 0.68221\tAccuracy: 0.33218\n",
            "Epoch: 2 [1950/3200 (61%)]\tLoss: 0.60301\tAccuracy: 0.41450\n",
            "Epoch: 2 [2000/3200 (62%)]\tLoss: 0.65836\tAccuracy: 0.35248\n",
            "Epoch: 2 [2050/3200 (64%)]\tLoss: 0.64147\tAccuracy: 0.37003\n",
            "Epoch: 2 [2100/3200 (66%)]\tLoss: 0.69974\tAccuracy: 0.31026\n",
            "Epoch: 2 [2150/3200 (67%)]\tLoss: 0.59317\tAccuracy: 0.42162\n",
            "Epoch: 2 [2200/3200 (69%)]\tLoss: 0.63068\tAccuracy: 0.38214\n",
            "Epoch: 2 [2250/3200 (70%)]\tLoss: 0.60970\tAccuracy: 0.40634\n",
            "Epoch: 2 [2300/3200 (72%)]\tLoss: 0.61639\tAccuracy: 0.40275\n",
            "Epoch: 2 [2350/3200 (73%)]\tLoss: 0.62515\tAccuracy: 0.38788\n",
            "Epoch: 2 [2400/3200 (75%)]\tLoss: 0.58446\tAccuracy: 0.44575\n",
            "Epoch: 2 [2450/3200 (77%)]\tLoss: 0.60484\tAccuracy: 0.41269\n",
            "Epoch: 2 [2500/3200 (78%)]\tLoss: 0.62170\tAccuracy: 0.38992\n",
            "Epoch: 2 [2550/3200 (80%)]\tLoss: 0.56467\tAccuracy: 0.45466\n",
            "Epoch: 2 [2600/3200 (81%)]\tLoss: 0.57059\tAccuracy: 0.44758\n",
            "Epoch: 2 [2650/3200 (83%)]\tLoss: 0.65490\tAccuracy: 0.35578\n",
            "Epoch: 2 [2700/3200 (84%)]\tLoss: 0.65357\tAccuracy: 0.35944\n",
            "Epoch: 2 [2750/3200 (86%)]\tLoss: 0.61404\tAccuracy: 0.42282\n",
            "Epoch: 2 [2800/3200 (88%)]\tLoss: 0.67684\tAccuracy: 0.33233\n",
            "Epoch: 2 [2850/3200 (89%)]\tLoss: 0.56625\tAccuracy: 0.46398\n",
            "Epoch: 2 [2900/3200 (91%)]\tLoss: 0.63241\tAccuracy: 0.38144\n",
            "Epoch: 2 [2950/3200 (92%)]\tLoss: 0.58389\tAccuracy: 0.45299\n",
            "Epoch: 2 [3000/3200 (94%)]\tLoss: 0.55032\tAccuracy: 0.50393\n",
            "Epoch: 2 [3050/3200 (95%)]\tLoss: 0.55368\tAccuracy: 0.46802\n",
            "Epoch: 2 [3100/3200 (97%)]\tLoss: 0.70003\tAccuracy: 0.31223\n",
            "Epoch: 2 [3150/3200 (98%)]\tLoss: 0.64597\tAccuracy: 0.36286\n",
            "Epoch: 2 [3200/3200 (100%)]\tLoss: 0.68739\tAccuracy: 0.32146\n",
            "Train Loss: 0.62990 Train Accuracy: 0.39242\n",
            "Validation Loss: 0.70451 Validation Accuracy: 0.40674\n",
            "[0.001]\n",
            "Epoch: 3 [50/3200 (2%)]\tLoss: 0.62620\tAccuracy: 0.38439\n",
            "Epoch: 3 [100/3200 (3%)]\tLoss: 0.65255\tAccuracy: 0.35592\n",
            "Epoch: 3 [150/3200 (5%)]\tLoss: 0.64291\tAccuracy: 0.36483\n",
            "Epoch: 3 [200/3200 (6%)]\tLoss: 0.59547\tAccuracy: 0.43676\n",
            "Epoch: 3 [250/3200 (8%)]\tLoss: 0.63645\tAccuracy: 0.39149\n",
            "Epoch: 3 [300/3200 (9%)]\tLoss: 0.62336\tAccuracy: 0.40951\n",
            "Epoch: 3 [350/3200 (11%)]\tLoss: 0.54056\tAccuracy: 0.47419\n",
            "Epoch: 3 [400/3200 (12%)]\tLoss: 0.62783\tAccuracy: 0.38295\n",
            "Epoch: 3 [450/3200 (14%)]\tLoss: 0.60514\tAccuracy: 0.42392\n",
            "Epoch: 3 [500/3200 (16%)]\tLoss: 0.56157\tAccuracy: 0.48877\n",
            "Epoch: 3 [550/3200 (17%)]\tLoss: 0.63069\tAccuracy: 0.39926\n",
            "Epoch: 3 [600/3200 (19%)]\tLoss: 0.57749\tAccuracy: 0.49357\n",
            "Epoch: 3 [650/3200 (20%)]\tLoss: 0.52998\tAccuracy: 0.53022\n",
            "Epoch: 3 [700/3200 (22%)]\tLoss: 0.62100\tAccuracy: 0.40352\n",
            "Epoch: 3 [750/3200 (23%)]\tLoss: 0.60916\tAccuracy: 0.44766\n",
            "Epoch: 3 [800/3200 (25%)]\tLoss: 0.65075\tAccuracy: 0.37665\n",
            "Epoch: 3 [850/3200 (27%)]\tLoss: 0.56957\tAccuracy: 0.43675\n",
            "Epoch: 3 [900/3200 (28%)]\tLoss: 0.56551\tAccuracy: 0.45436\n",
            "Epoch: 3 [950/3200 (30%)]\tLoss: 0.56328\tAccuracy: 0.46697\n",
            "Epoch: 3 [1000/3200 (31%)]\tLoss: 0.55445\tAccuracy: 0.47314\n",
            "Epoch: 3 [1050/3200 (33%)]\tLoss: 0.64430\tAccuracy: 0.40258\n",
            "Epoch: 3 [1100/3200 (34%)]\tLoss: 0.62317\tAccuracy: 0.38485\n",
            "Epoch: 3 [1150/3200 (36%)]\tLoss: 0.57601\tAccuracy: 0.45527\n",
            "Epoch: 3 [1200/3200 (38%)]\tLoss: 0.57946\tAccuracy: 0.47045\n",
            "Epoch: 3 [1250/3200 (39%)]\tLoss: 0.56857\tAccuracy: 0.52916\n",
            "Epoch: 3 [1300/3200 (41%)]\tLoss: 0.51493\tAccuracy: 0.52240\n",
            "Epoch: 3 [1350/3200 (42%)]\tLoss: 0.70495\tAccuracy: 0.32120\n",
            "Epoch: 3 [1400/3200 (44%)]\tLoss: 0.65190\tAccuracy: 0.35331\n",
            "Epoch: 3 [1450/3200 (45%)]\tLoss: 0.65123\tAccuracy: 0.37319\n",
            "Epoch: 3 [1500/3200 (47%)]\tLoss: 0.53827\tAccuracy: 0.47029\n",
            "Epoch: 3 [1550/3200 (48%)]\tLoss: 0.58192\tAccuracy: 0.42615\n",
            "Epoch: 3 [1600/3200 (50%)]\tLoss: 0.65261\tAccuracy: 0.35332\n",
            "Epoch: 3 [1650/3200 (52%)]\tLoss: 0.58997\tAccuracy: 0.43861\n",
            "Epoch: 3 [1700/3200 (53%)]\tLoss: 0.70460\tAccuracy: 0.29967\n",
            "Epoch: 3 [1750/3200 (55%)]\tLoss: 0.62685\tAccuracy: 0.37924\n",
            "Epoch: 3 [1800/3200 (56%)]\tLoss: 0.60631\tAccuracy: 0.40163\n",
            "Epoch: 3 [1850/3200 (58%)]\tLoss: 0.60511\tAccuracy: 0.40474\n",
            "Epoch: 3 [1900/3200 (59%)]\tLoss: 0.62984\tAccuracy: 0.37636\n",
            "Epoch: 3 [1950/3200 (61%)]\tLoss: 0.53888\tAccuracy: 0.46724\n",
            "Epoch: 3 [2000/3200 (62%)]\tLoss: 0.56528\tAccuracy: 0.45872\n",
            "Epoch: 3 [2050/3200 (64%)]\tLoss: 0.67740\tAccuracy: 0.32699\n",
            "Epoch: 3 [2100/3200 (66%)]\tLoss: 0.61674\tAccuracy: 0.39082\n",
            "Epoch: 3 [2150/3200 (67%)]\tLoss: 0.65172\tAccuracy: 0.35622\n",
            "Epoch: 3 [2200/3200 (69%)]\tLoss: 0.72234\tAccuracy: 0.29967\n",
            "Epoch: 3 [2250/3200 (70%)]\tLoss: 0.60225\tAccuracy: 0.40942\n",
            "Epoch: 3 [2300/3200 (72%)]\tLoss: 0.58894\tAccuracy: 0.45943\n",
            "Epoch: 3 [2350/3200 (73%)]\tLoss: 0.62723\tAccuracy: 0.40047\n",
            "Epoch: 3 [2400/3200 (75%)]\tLoss: 0.61626\tAccuracy: 0.39123\n",
            "Epoch: 3 [2450/3200 (77%)]\tLoss: 0.62958\tAccuracy: 0.39876\n",
            "Epoch: 3 [2500/3200 (78%)]\tLoss: 0.58925\tAccuracy: 0.45509\n",
            "Epoch: 3 [2550/3200 (80%)]\tLoss: 0.61596\tAccuracy: 0.42698\n",
            "Epoch: 3 [2600/3200 (81%)]\tLoss: 0.55229\tAccuracy: 0.45720\n",
            "Epoch: 3 [2650/3200 (83%)]\tLoss: 0.66500\tAccuracy: 0.34793\n",
            "Epoch: 3 [2700/3200 (84%)]\tLoss: 0.59953\tAccuracy: 0.44370\n",
            "Epoch: 3 [2750/3200 (86%)]\tLoss: 0.62682\tAccuracy: 0.39636\n",
            "Epoch: 3 [2800/3200 (88%)]\tLoss: 0.69888\tAccuracy: 0.38094\n",
            "Epoch: 3 [2850/3200 (89%)]\tLoss: 0.60248\tAccuracy: 0.42715\n",
            "Epoch: 3 [2900/3200 (91%)]\tLoss: 0.56632\tAccuracy: 0.57187\n",
            "Epoch: 3 [2950/3200 (92%)]\tLoss: 0.52350\tAccuracy: 0.52183\n",
            "Epoch: 3 [3000/3200 (94%)]\tLoss: 0.61494\tAccuracy: 0.39307\n",
            "Epoch: 3 [3050/3200 (95%)]\tLoss: 0.59370\tAccuracy: 0.44781\n",
            "Epoch: 3 [3100/3200 (97%)]\tLoss: 0.54734\tAccuracy: 0.55170\n",
            "Epoch: 3 [3150/3200 (98%)]\tLoss: 0.54792\tAccuracy: 0.47745\n",
            "Epoch: 3 [3200/3200 (100%)]\tLoss: 0.62349\tAccuracy: 0.40310\n",
            "Train Loss: 0.60684 Train Accuracy: 0.42216\n",
            "Validation Loss: 0.70443 Validation Accuracy: 0.43653\n",
            "[0.001]\n",
            "Epoch: 4 [50/3200 (2%)]\tLoss: 0.61964\tAccuracy: 0.38960\n",
            "Epoch: 4 [100/3200 (3%)]\tLoss: 0.70955\tAccuracy: 0.31318\n",
            "Epoch: 4 [150/3200 (5%)]\tLoss: 0.57385\tAccuracy: 0.46827\n",
            "Epoch: 4 [200/3200 (6%)]\tLoss: 0.65260\tAccuracy: 0.36970\n",
            "Epoch: 4 [250/3200 (8%)]\tLoss: 0.50533\tAccuracy: 0.53547\n",
            "Epoch: 4 [300/3200 (9%)]\tLoss: 0.57857\tAccuracy: 0.47894\n",
            "Epoch: 4 [350/3200 (11%)]\tLoss: 0.63649\tAccuracy: 0.42149\n",
            "Epoch: 4 [400/3200 (12%)]\tLoss: 0.61594\tAccuracy: 0.40510\n",
            "Epoch: 4 [450/3200 (14%)]\tLoss: 0.54125\tAccuracy: 0.54807\n",
            "Epoch: 4 [500/3200 (16%)]\tLoss: 0.64127\tAccuracy: 0.46863\n",
            "Epoch: 4 [550/3200 (17%)]\tLoss: 0.57093\tAccuracy: 0.50168\n",
            "Epoch: 4 [600/3200 (19%)]\tLoss: 0.64018\tAccuracy: 0.43185\n",
            "Epoch: 4 [650/3200 (20%)]\tLoss: 0.57044\tAccuracy: 0.50363\n",
            "Epoch: 4 [700/3200 (22%)]\tLoss: 0.61906\tAccuracy: 0.48804\n",
            "Epoch: 4 [750/3200 (23%)]\tLoss: 0.60251\tAccuracy: 0.49196\n",
            "Epoch: 4 [800/3200 (25%)]\tLoss: 0.49140\tAccuracy: 0.54504\n",
            "Epoch: 4 [850/3200 (27%)]\tLoss: 0.40846\tAccuracy: 0.63232\n",
            "Epoch: 4 [900/3200 (28%)]\tLoss: 0.53625\tAccuracy: 0.47929\n",
            "Epoch: 4 [950/3200 (30%)]\tLoss: 0.53377\tAccuracy: 0.48136\n",
            "Epoch: 4 [1000/3200 (31%)]\tLoss: 0.47956\tAccuracy: 0.49389\n",
            "Epoch: 4 [1050/3200 (33%)]\tLoss: 0.56182\tAccuracy: 0.48405\n",
            "Epoch: 4 [1100/3200 (34%)]\tLoss: 0.56679\tAccuracy: 0.45782\n",
            "Epoch: 4 [1150/3200 (36%)]\tLoss: 0.48804\tAccuracy: 0.47420\n",
            "Epoch: 4 [1200/3200 (38%)]\tLoss: 0.48599\tAccuracy: 0.50245\n",
            "Epoch: 4 [1250/3200 (39%)]\tLoss: 0.45039\tAccuracy: 0.55058\n",
            "Epoch: 4 [1300/3200 (41%)]\tLoss: 0.35339\tAccuracy: 0.55770\n",
            "Epoch: 4 [1350/3200 (42%)]\tLoss: 0.33469\tAccuracy: 0.60134\n",
            "Epoch: 4 [1400/3200 (44%)]\tLoss: 0.37972\tAccuracy: 0.55118\n",
            "Epoch: 4 [1450/3200 (45%)]\tLoss: 0.30029\tAccuracy: 0.60757\n",
            "Epoch: 4 [1500/3200 (47%)]\tLoss: 0.56054\tAccuracy: 0.41384\n",
            "Epoch: 4 [1550/3200 (48%)]\tLoss: 0.32349\tAccuracy: 0.57042\n",
            "Epoch: 4 [1600/3200 (50%)]\tLoss: 0.31113\tAccuracy: 0.56864\n",
            "Epoch: 4 [1650/3200 (52%)]\tLoss: 0.36154\tAccuracy: 0.50343\n",
            "Epoch: 4 [1700/3200 (53%)]\tLoss: 0.58298\tAccuracy: 0.40890\n",
            "Epoch: 4 [1750/3200 (55%)]\tLoss: 0.48657\tAccuracy: 0.40477\n",
            "Epoch: 4 [1800/3200 (56%)]\tLoss: 0.52780\tAccuracy: 0.36378\n",
            "Epoch: 4 [1850/3200 (58%)]\tLoss: 0.51493\tAccuracy: 0.45662\n",
            "Epoch: 4 [1900/3200 (59%)]\tLoss: 0.40183\tAccuracy: 0.50099\n",
            "Epoch: 4 [1950/3200 (61%)]\tLoss: 0.48584\tAccuracy: 0.43880\n",
            "Epoch: 4 [2000/3200 (62%)]\tLoss: 0.37001\tAccuracy: 0.52174\n",
            "Epoch: 4 [2050/3200 (64%)]\tLoss: 0.52728\tAccuracy: 0.38712\n",
            "Epoch: 4 [2100/3200 (66%)]\tLoss: 0.30099\tAccuracy: 0.50787\n",
            "Epoch: 4 [2150/3200 (67%)]\tLoss: 0.46611\tAccuracy: 0.45018\n",
            "Epoch: 4 [2200/3200 (69%)]\tLoss: 0.45072\tAccuracy: 0.45784\n",
            "Epoch: 4 [2250/3200 (70%)]\tLoss: 0.42086\tAccuracy: 0.47815\n",
            "Epoch: 4 [2300/3200 (72%)]\tLoss: 0.34685\tAccuracy: 0.48308\n",
            "Epoch: 4 [2350/3200 (73%)]\tLoss: 0.30538\tAccuracy: 0.57596\n",
            "Epoch: 4 [2400/3200 (75%)]\tLoss: 0.29588\tAccuracy: 0.55546\n",
            "Epoch: 4 [2450/3200 (77%)]\tLoss: 0.43478\tAccuracy: 0.41907\n",
            "Epoch: 4 [2500/3200 (78%)]\tLoss: 0.45868\tAccuracy: 0.46471\n",
            "Epoch: 4 [2550/3200 (80%)]\tLoss: 0.46994\tAccuracy: 0.46000\n",
            "Epoch: 4 [2600/3200 (81%)]\tLoss: 0.24864\tAccuracy: 0.58376\n",
            "Epoch: 4 [2650/3200 (83%)]\tLoss: 0.24757\tAccuracy: 0.57104\n",
            "Epoch: 4 [2700/3200 (84%)]\tLoss: 0.29182\tAccuracy: 0.55337\n",
            "Epoch: 4 [2750/3200 (86%)]\tLoss: 0.20095\tAccuracy: 0.59460\n",
            "Epoch: 4 [2800/3200 (88%)]\tLoss: 0.34692\tAccuracy: 0.55387\n",
            "Epoch: 4 [2850/3200 (89%)]\tLoss: 0.44749\tAccuracy: 0.46608\n",
            "Epoch: 4 [2900/3200 (91%)]\tLoss: 0.32232\tAccuracy: 0.50453\n",
            "Epoch: 4 [2950/3200 (92%)]\tLoss: 0.43768\tAccuracy: 0.44094\n",
            "Epoch: 4 [3000/3200 (94%)]\tLoss: 0.27806\tAccuracy: 0.54766\n",
            "Epoch: 4 [3050/3200 (95%)]\tLoss: 0.30317\tAccuracy: 0.54739\n",
            "Epoch: 4 [3100/3200 (97%)]\tLoss: 0.19744\tAccuracy: 0.59981\n",
            "Epoch: 4 [3150/3200 (98%)]\tLoss: 0.45699\tAccuracy: 0.40765\n",
            "Epoch: 4 [3200/3200 (100%)]\tLoss: 0.27516\tAccuracy: 0.50036\n",
            "Train Loss: 0.45166 Train Accuracy: 0.49214\n",
            "Validation Loss: 0.71684 Validation Accuracy: 0.60759\n",
            "[0.001]\n",
            "Epoch: 5 [50/3200 (2%)]\tLoss: 0.37689\tAccuracy: 0.46156\n",
            "Epoch: 5 [100/3200 (3%)]\tLoss: 0.20482\tAccuracy: 0.57051\n",
            "Epoch: 5 [150/3200 (5%)]\tLoss: 0.20141\tAccuracy: 0.59885\n",
            "Epoch: 5 [200/3200 (6%)]\tLoss: 0.24717\tAccuracy: 0.53803\n",
            "Epoch: 5 [250/3200 (8%)]\tLoss: 0.39836\tAccuracy: 0.49012\n",
            "Epoch: 5 [300/3200 (9%)]\tLoss: 0.21128\tAccuracy: 0.53906\n",
            "Epoch: 5 [350/3200 (11%)]\tLoss: 0.45246\tAccuracy: 0.41665\n",
            "Epoch: 5 [400/3200 (12%)]\tLoss: 0.33633\tAccuracy: 0.45059\n",
            "Epoch: 5 [450/3200 (14%)]\tLoss: 0.31842\tAccuracy: 0.50853\n",
            "Epoch: 5 [500/3200 (16%)]\tLoss: 0.47576\tAccuracy: 0.42511\n",
            "Epoch: 5 [550/3200 (17%)]\tLoss: 0.24170\tAccuracy: 0.52295\n",
            "Epoch: 5 [600/3200 (19%)]\tLoss: 0.17935\tAccuracy: 0.56501\n",
            "Epoch: 5 [650/3200 (20%)]\tLoss: 0.24787\tAccuracy: 0.51198\n",
            "Epoch: 5 [700/3200 (22%)]\tLoss: 0.14865\tAccuracy: 0.55311\n",
            "Epoch: 5 [750/3200 (23%)]\tLoss: 0.08917\tAccuracy: 0.62037\n",
            "Epoch: 5 [800/3200 (25%)]\tLoss: 0.19438\tAccuracy: 0.54668\n",
            "Epoch: 5 [850/3200 (27%)]\tLoss: 0.16439\tAccuracy: 0.53995\n",
            "Epoch: 5 [900/3200 (28%)]\tLoss: 0.13229\tAccuracy: 0.59468\n",
            "Epoch: 5 [950/3200 (30%)]\tLoss: 0.26127\tAccuracy: 0.52245\n",
            "Epoch: 5 [1000/3200 (31%)]\tLoss: 0.24978\tAccuracy: 0.57131\n",
            "Epoch: 5 [1050/3200 (33%)]\tLoss: 0.11395\tAccuracy: 0.63203\n",
            "Epoch: 5 [1100/3200 (34%)]\tLoss: 0.31889\tAccuracy: 0.44573\n",
            "Epoch: 5 [1150/3200 (36%)]\tLoss: 0.17660\tAccuracy: 0.53354\n",
            "Epoch: 5 [1200/3200 (38%)]\tLoss: 0.12401\tAccuracy: 0.60642\n",
            "Epoch: 5 [1250/3200 (39%)]\tLoss: -0.04385\tAccuracy: 0.68841\n",
            "Epoch: 5 [1300/3200 (41%)]\tLoss: 0.06421\tAccuracy: 0.66975\n",
            "Epoch: 5 [1350/3200 (42%)]\tLoss: 0.24687\tAccuracy: 0.50935\n",
            "Epoch: 5 [1400/3200 (44%)]\tLoss: 0.13087\tAccuracy: 0.56445\n",
            "Epoch: 5 [1450/3200 (45%)]\tLoss: 0.03949\tAccuracy: 0.61950\n",
            "Epoch: 5 [1500/3200 (47%)]\tLoss: 0.11836\tAccuracy: 0.62890\n",
            "Epoch: 5 [1550/3200 (48%)]\tLoss: 0.09937\tAccuracy: 0.63166\n",
            "Epoch: 5 [1600/3200 (50%)]\tLoss: 0.21335\tAccuracy: 0.52926\n",
            "Epoch: 5 [1650/3200 (52%)]\tLoss: 0.34865\tAccuracy: 0.48241\n",
            "Epoch: 5 [1700/3200 (53%)]\tLoss: 0.24164\tAccuracy: 0.54881\n",
            "Epoch: 5 [1750/3200 (55%)]\tLoss: 0.26402\tAccuracy: 0.54236\n",
            "Epoch: 5 [1800/3200 (56%)]\tLoss: 0.11031\tAccuracy: 0.63784\n",
            "Epoch: 5 [1850/3200 (58%)]\tLoss: 0.06333\tAccuracy: 0.66324\n",
            "Epoch: 5 [1900/3200 (59%)]\tLoss: -0.01695\tAccuracy: 0.65173\n",
            "Epoch: 5 [1950/3200 (61%)]\tLoss: 0.06666\tAccuracy: 0.60553\n",
            "Epoch: 5 [2000/3200 (62%)]\tLoss: 0.06143\tAccuracy: 0.61119\n",
            "Epoch: 5 [2050/3200 (64%)]\tLoss: 0.19371\tAccuracy: 0.55134\n",
            "Epoch: 5 [2100/3200 (66%)]\tLoss: 0.14746\tAccuracy: 0.63516\n",
            "Epoch: 5 [2150/3200 (67%)]\tLoss: 0.21494\tAccuracy: 0.51203\n",
            "Epoch: 5 [2200/3200 (69%)]\tLoss: 0.17981\tAccuracy: 0.52271\n",
            "Epoch: 5 [2250/3200 (70%)]\tLoss: 0.44799\tAccuracy: 0.43351\n",
            "Epoch: 5 [2300/3200 (72%)]\tLoss: 0.31757\tAccuracy: 0.50488\n",
            "Epoch: 5 [2350/3200 (73%)]\tLoss: 0.10197\tAccuracy: 0.64369\n",
            "Epoch: 5 [2400/3200 (75%)]\tLoss: 0.21430\tAccuracy: 0.53584\n",
            "Epoch: 5 [2450/3200 (77%)]\tLoss: 0.10821\tAccuracy: 0.59727\n",
            "Epoch: 5 [2500/3200 (78%)]\tLoss: 0.21969\tAccuracy: 0.56536\n",
            "Epoch: 5 [2550/3200 (80%)]\tLoss: 0.20960\tAccuracy: 0.53312\n",
            "Epoch: 5 [2600/3200 (81%)]\tLoss: 0.04171\tAccuracy: 0.64316\n",
            "Epoch: 5 [2650/3200 (83%)]\tLoss: 0.21212\tAccuracy: 0.59216\n",
            "Epoch: 5 [2700/3200 (84%)]\tLoss: 0.23912\tAccuracy: 0.51278\n",
            "Epoch: 5 [2750/3200 (86%)]\tLoss: -0.21948\tAccuracy: 0.77035\n",
            "Epoch: 5 [2800/3200 (88%)]\tLoss: 0.10624\tAccuracy: 0.65611\n",
            "Epoch: 5 [2850/3200 (89%)]\tLoss: 0.00669\tAccuracy: 0.70697\n",
            "Epoch: 5 [2900/3200 (91%)]\tLoss: 0.11232\tAccuracy: 0.60108\n",
            "Epoch: 5 [2950/3200 (92%)]\tLoss: 0.26963\tAccuracy: 0.47245\n",
            "Epoch: 5 [3000/3200 (94%)]\tLoss: 0.13633\tAccuracy: 0.61118\n",
            "Epoch: 5 [3050/3200 (95%)]\tLoss: 0.16439\tAccuracy: 0.55539\n",
            "Epoch: 5 [3100/3200 (97%)]\tLoss: 0.22134\tAccuracy: 0.55167\n",
            "Epoch: 5 [3150/3200 (98%)]\tLoss: -0.16635\tAccuracy: 0.75783\n",
            "Epoch: 5 [3200/3200 (100%)]\tLoss: -0.02906\tAccuracy: 0.66824\n",
            "Train Loss: 0.17693 Train Accuracy: 0.57006\n",
            "Validation Loss: 0.71131 Validation Accuracy: 0.60192\n",
            "[0.001]\n",
            "Epoch: 6 [50/3200 (2%)]\tLoss: -0.00268\tAccuracy: 0.69235\n",
            "Epoch: 6 [100/3200 (3%)]\tLoss: 0.03230\tAccuracy: 0.59700\n",
            "Epoch: 6 [150/3200 (5%)]\tLoss: 0.22613\tAccuracy: 0.50085\n",
            "Epoch: 6 [200/3200 (6%)]\tLoss: 0.15008\tAccuracy: 0.57500\n",
            "Epoch: 6 [250/3200 (8%)]\tLoss: 0.11647\tAccuracy: 0.59130\n",
            "Epoch: 6 [300/3200 (9%)]\tLoss: -0.13485\tAccuracy: 0.74478\n",
            "Epoch: 6 [350/3200 (11%)]\tLoss: 0.38335\tAccuracy: 0.47837\n",
            "Epoch: 6 [400/3200 (12%)]\tLoss: 0.09694\tAccuracy: 0.61500\n",
            "Epoch: 6 [450/3200 (14%)]\tLoss: 0.16812\tAccuracy: 0.56656\n",
            "Epoch: 6 [500/3200 (16%)]\tLoss: 0.08426\tAccuracy: 0.58552\n",
            "Epoch: 6 [550/3200 (17%)]\tLoss: 0.23224\tAccuracy: 0.53303\n",
            "Epoch: 6 [600/3200 (19%)]\tLoss: 0.24984\tAccuracy: 0.44580\n",
            "Epoch: 6 [650/3200 (20%)]\tLoss: 0.45834\tAccuracy: 0.35739\n",
            "Epoch: 6 [700/3200 (22%)]\tLoss: 0.19956\tAccuracy: 0.50750\n",
            "Epoch: 6 [750/3200 (23%)]\tLoss: 0.30686\tAccuracy: 0.41487\n",
            "Epoch: 6 [800/3200 (25%)]\tLoss: 0.19493\tAccuracy: 0.49734\n",
            "Epoch: 6 [850/3200 (27%)]\tLoss: 0.26237\tAccuracy: 0.48569\n",
            "Epoch: 6 [900/3200 (28%)]\tLoss: 0.38323\tAccuracy: 0.39459\n",
            "Epoch: 6 [950/3200 (30%)]\tLoss: 0.21242\tAccuracy: 0.52886\n",
            "Epoch: 6 [1000/3200 (31%)]\tLoss: 0.06054\tAccuracy: 0.62453\n",
            "Epoch: 6 [1050/3200 (33%)]\tLoss: -0.25782\tAccuracy: 0.78627\n",
            "Epoch: 6 [1100/3200 (34%)]\tLoss: 0.02287\tAccuracy: 0.65170\n",
            "Epoch: 6 [1150/3200 (36%)]\tLoss: -0.00996\tAccuracy: 0.67329\n",
            "Epoch: 6 [1200/3200 (38%)]\tLoss: 0.00880\tAccuracy: 0.64172\n",
            "Epoch: 6 [1250/3200 (39%)]\tLoss: -0.03671\tAccuracy: 0.64638\n",
            "Epoch: 6 [1300/3200 (41%)]\tLoss: 0.02351\tAccuracy: 0.64837\n",
            "Epoch: 6 [1350/3200 (42%)]\tLoss: 0.06079\tAccuracy: 0.64178\n",
            "Epoch: 6 [1400/3200 (44%)]\tLoss: 0.05567\tAccuracy: 0.61505\n",
            "Epoch: 6 [1450/3200 (45%)]\tLoss: -0.11256\tAccuracy: 0.71846\n",
            "Epoch: 6 [1500/3200 (47%)]\tLoss: 0.16145\tAccuracy: 0.61819\n",
            "Epoch: 6 [1550/3200 (48%)]\tLoss: 0.25607\tAccuracy: 0.49068\n",
            "Epoch: 6 [1600/3200 (50%)]\tLoss: 0.10464\tAccuracy: 0.60399\n",
            "Epoch: 6 [1650/3200 (52%)]\tLoss: 0.04824\tAccuracy: 0.61705\n",
            "Epoch: 6 [1700/3200 (53%)]\tLoss: 0.06207\tAccuracy: 0.62683\n",
            "Epoch: 6 [1750/3200 (55%)]\tLoss: 0.31927\tAccuracy: 0.45635\n",
            "Epoch: 6 [1800/3200 (56%)]\tLoss: -0.13432\tAccuracy: 0.72338\n",
            "Epoch: 6 [1850/3200 (58%)]\tLoss: -0.20265\tAccuracy: 0.77414\n",
            "Epoch: 6 [1900/3200 (59%)]\tLoss: -0.13922\tAccuracy: 0.70384\n",
            "Epoch: 6 [1950/3200 (61%)]\tLoss: -0.16623\tAccuracy: 0.75613\n",
            "Epoch: 6 [2000/3200 (62%)]\tLoss: 0.00451\tAccuracy: 0.63080\n",
            "Epoch: 6 [2050/3200 (64%)]\tLoss: 0.04530\tAccuracy: 0.63790\n",
            "Epoch: 6 [2100/3200 (66%)]\tLoss: -0.08112\tAccuracy: 0.70640\n",
            "Epoch: 6 [2150/3200 (67%)]\tLoss: 0.05767\tAccuracy: 0.66330\n",
            "Epoch: 6 [2200/3200 (69%)]\tLoss: 0.20854\tAccuracy: 0.55440\n",
            "Epoch: 6 [2250/3200 (70%)]\tLoss: 0.14316\tAccuracy: 0.55919\n",
            "Epoch: 6 [2300/3200 (72%)]\tLoss: 0.10969\tAccuracy: 0.59437\n",
            "Epoch: 6 [2350/3200 (73%)]\tLoss: 0.08848\tAccuracy: 0.61192\n",
            "Epoch: 6 [2400/3200 (75%)]\tLoss: -0.05574\tAccuracy: 0.64153\n",
            "Epoch: 6 [2450/3200 (77%)]\tLoss: 0.12413\tAccuracy: 0.63831\n",
            "Epoch: 6 [2500/3200 (78%)]\tLoss: 0.08571\tAccuracy: 0.59532\n",
            "Epoch: 6 [2550/3200 (80%)]\tLoss: 0.02137\tAccuracy: 0.67835\n",
            "Epoch: 6 [2600/3200 (81%)]\tLoss: 0.10938\tAccuracy: 0.61072\n",
            "Epoch: 6 [2650/3200 (83%)]\tLoss: 0.18339\tAccuracy: 0.57717\n",
            "Epoch: 6 [2700/3200 (84%)]\tLoss: 0.22371\tAccuracy: 0.51848\n",
            "Epoch: 6 [2750/3200 (86%)]\tLoss: 0.05505\tAccuracy: 0.60799\n",
            "Epoch: 6 [2800/3200 (88%)]\tLoss: 0.05923\tAccuracy: 0.62307\n",
            "Epoch: 6 [2850/3200 (89%)]\tLoss: 0.05038\tAccuracy: 0.66420\n",
            "Epoch: 6 [2900/3200 (91%)]\tLoss: -0.02645\tAccuracy: 0.64470\n",
            "Epoch: 6 [2950/3200 (92%)]\tLoss: 0.13912\tAccuracy: 0.57998\n",
            "Epoch: 6 [3000/3200 (94%)]\tLoss: 0.05191\tAccuracy: 0.60927\n",
            "Epoch: 6 [3050/3200 (95%)]\tLoss: 0.06493\tAccuracy: 0.62709\n",
            "Epoch: 6 [3100/3200 (97%)]\tLoss: 0.15847\tAccuracy: 0.62264\n",
            "Epoch: 6 [3150/3200 (98%)]\tLoss: 0.09171\tAccuracy: 0.56930\n",
            "Epoch: 6 [3200/3200 (100%)]\tLoss: -0.05963\tAccuracy: 0.70151\n",
            "Train Loss: 0.08746 Train Accuracy: 0.60309\n",
            "Validation Loss: 0.71181 Validation Accuracy: 0.63877\n",
            "[0.001]\n",
            "Epoch: 7 [50/3200 (2%)]\tLoss: -0.04518\tAccuracy: 0.68613\n",
            "Epoch: 7 [100/3200 (3%)]\tLoss: 0.08310\tAccuracy: 0.59835\n",
            "Epoch: 7 [150/3200 (5%)]\tLoss: 0.02848\tAccuracy: 0.61229\n",
            "Epoch: 7 [200/3200 (6%)]\tLoss: -0.11584\tAccuracy: 0.71776\n",
            "Epoch: 7 [250/3200 (8%)]\tLoss: 0.14838\tAccuracy: 0.53322\n",
            "Epoch: 7 [300/3200 (9%)]\tLoss: 0.16075\tAccuracy: 0.57980\n",
            "Epoch: 7 [350/3200 (11%)]\tLoss: 0.24512\tAccuracy: 0.49637\n",
            "Epoch: 7 [400/3200 (12%)]\tLoss: 0.09034\tAccuracy: 0.62878\n",
            "Epoch: 7 [450/3200 (14%)]\tLoss: -0.10405\tAccuracy: 0.69905\n",
            "Epoch: 7 [500/3200 (16%)]\tLoss: -0.04962\tAccuracy: 0.71153\n",
            "Epoch: 7 [550/3200 (17%)]\tLoss: 0.02034\tAccuracy: 0.65653\n",
            "Epoch: 7 [600/3200 (19%)]\tLoss: -0.11311\tAccuracy: 0.71895\n",
            "Epoch: 7 [650/3200 (20%)]\tLoss: -0.05037\tAccuracy: 0.67267\n",
            "Epoch: 7 [700/3200 (22%)]\tLoss: 0.06873\tAccuracy: 0.55788\n",
            "Epoch: 7 [750/3200 (23%)]\tLoss: 0.20700\tAccuracy: 0.49975\n",
            "Epoch: 7 [800/3200 (25%)]\tLoss: 0.36965\tAccuracy: 0.38309\n",
            "Epoch: 7 [850/3200 (27%)]\tLoss: 0.17527\tAccuracy: 0.53513\n",
            "Epoch: 7 [900/3200 (28%)]\tLoss: 0.21107\tAccuracy: 0.46185\n",
            "Epoch: 7 [950/3200 (30%)]\tLoss: 0.31257\tAccuracy: 0.39948\n",
            "Epoch: 7 [1000/3200 (31%)]\tLoss: 0.25932\tAccuracy: 0.44688\n",
            "Epoch: 7 [1050/3200 (33%)]\tLoss: 0.37764\tAccuracy: 0.37443\n",
            "Epoch: 7 [1100/3200 (34%)]\tLoss: 0.40331\tAccuracy: 0.35985\n",
            "Epoch: 7 [1150/3200 (36%)]\tLoss: 0.09323\tAccuracy: 0.51997\n",
            "Epoch: 7 [1200/3200 (38%)]\tLoss: 0.45524\tAccuracy: 0.32556\n",
            "Epoch: 7 [1250/3200 (39%)]\tLoss: 0.46445\tAccuracy: 0.33769\n",
            "Epoch: 7 [1300/3200 (41%)]\tLoss: 0.41989\tAccuracy: 0.35985\n",
            "Epoch: 7 [1350/3200 (42%)]\tLoss: 0.31525\tAccuracy: 0.39006\n",
            "Epoch: 7 [1400/3200 (44%)]\tLoss: 0.21988\tAccuracy: 0.42182\n",
            "Epoch: 7 [1450/3200 (45%)]\tLoss: 0.40807\tAccuracy: 0.34394\n",
            "Epoch: 7 [1500/3200 (47%)]\tLoss: 0.25189\tAccuracy: 0.43318\n",
            "Epoch: 7 [1550/3200 (48%)]\tLoss: 0.47671\tAccuracy: 0.32315\n",
            "Epoch: 7 [1600/3200 (50%)]\tLoss: 0.37059\tAccuracy: 0.37059\n",
            "Epoch: 7 [1650/3200 (52%)]\tLoss: 0.09951\tAccuracy: 0.50251\n",
            "Epoch: 7 [1700/3200 (53%)]\tLoss: 0.42185\tAccuracy: 0.33904\n",
            "Epoch: 7 [1750/3200 (55%)]\tLoss: 0.35434\tAccuracy: 0.38008\n",
            "Epoch: 7 [1800/3200 (56%)]\tLoss: 0.32165\tAccuracy: 0.41650\n",
            "Epoch: 7 [1850/3200 (58%)]\tLoss: 0.23712\tAccuracy: 0.46389\n",
            "Epoch: 7 [1900/3200 (59%)]\tLoss: 0.36414\tAccuracy: 0.39703\n",
            "Epoch: 7 [1950/3200 (61%)]\tLoss: 0.25985\tAccuracy: 0.44180\n",
            "Epoch: 7 [2000/3200 (62%)]\tLoss: 0.39217\tAccuracy: 0.34926\n",
            "Epoch: 7 [2050/3200 (64%)]\tLoss: 0.40560\tAccuracy: 0.35496\n",
            "Epoch: 7 [2100/3200 (66%)]\tLoss: 0.36981\tAccuracy: 0.38684\n",
            "Epoch: 7 [2150/3200 (67%)]\tLoss: 0.20649\tAccuracy: 0.45378\n",
            "Epoch: 7 [2200/3200 (69%)]\tLoss: 0.40735\tAccuracy: 0.35217\n",
            "Epoch: 7 [2250/3200 (70%)]\tLoss: 0.35692\tAccuracy: 0.37974\n",
            "Epoch: 7 [2300/3200 (72%)]\tLoss: 0.34444\tAccuracy: 0.39532\n",
            "Epoch: 7 [2350/3200 (73%)]\tLoss: 0.15106\tAccuracy: 0.49071\n",
            "Epoch: 7 [2400/3200 (75%)]\tLoss: 0.15041\tAccuracy: 0.50959\n",
            "Epoch: 7 [2450/3200 (77%)]\tLoss: 0.34168\tAccuracy: 0.41897\n",
            "Epoch: 7 [2500/3200 (78%)]\tLoss: 0.33362\tAccuracy: 0.38660\n",
            "Epoch: 7 [2550/3200 (80%)]\tLoss: 0.40188\tAccuracy: 0.37848\n",
            "Epoch: 7 [2600/3200 (81%)]\tLoss: 0.24027\tAccuracy: 0.46108\n",
            "Epoch: 7 [2650/3200 (83%)]\tLoss: 0.18551\tAccuracy: 0.47531\n",
            "Epoch: 7 [2700/3200 (84%)]\tLoss: 0.29945\tAccuracy: 0.44097\n",
            "Epoch: 7 [2750/3200 (86%)]\tLoss: 0.26242\tAccuracy: 0.45809\n",
            "Epoch: 7 [2800/3200 (88%)]\tLoss: 0.20436\tAccuracy: 0.51522\n",
            "Epoch: 7 [2850/3200 (89%)]\tLoss: 0.30487\tAccuracy: 0.41589\n",
            "Epoch: 7 [2900/3200 (91%)]\tLoss: 0.29589\tAccuracy: 0.44343\n",
            "Epoch: 7 [2950/3200 (92%)]\tLoss: 0.25488\tAccuracy: 0.42533\n",
            "Epoch: 7 [3000/3200 (94%)]\tLoss: 0.26679\tAccuracy: 0.48080\n",
            "Epoch: 7 [3050/3200 (95%)]\tLoss: 0.15593\tAccuracy: 0.50249\n",
            "Epoch: 7 [3100/3200 (97%)]\tLoss: 0.24965\tAccuracy: 0.48877\n",
            "Epoch: 7 [3150/3200 (98%)]\tLoss: 0.04172\tAccuracy: 0.57851\n",
            "Epoch: 7 [3200/3200 (100%)]\tLoss: 0.22984\tAccuracy: 0.46992\n",
            "Train Loss: 0.23546 Train Accuracy: 0.47045\n",
            "Validation Loss: 0.72430 Validation Accuracy: 0.51138\n",
            "[0.001]\n",
            "Epoch: 8 [50/3200 (2%)]\tLoss: 0.19864\tAccuracy: 0.50140\n",
            "Epoch: 8 [100/3200 (3%)]\tLoss: 0.31447\tAccuracy: 0.48518\n",
            "Epoch: 8 [150/3200 (5%)]\tLoss: 0.27065\tAccuracy: 0.46548\n",
            "Epoch: 8 [200/3200 (6%)]\tLoss: 0.08600\tAccuracy: 0.55399\n",
            "Epoch: 8 [250/3200 (8%)]\tLoss: 0.25047\tAccuracy: 0.46830\n",
            "Epoch: 8 [300/3200 (9%)]\tLoss: 0.06640\tAccuracy: 0.55345\n",
            "Epoch: 8 [350/3200 (11%)]\tLoss: 0.31990\tAccuracy: 0.49884\n",
            "Epoch: 8 [400/3200 (12%)]\tLoss: 0.14580\tAccuracy: 0.53420\n",
            "Epoch: 8 [450/3200 (14%)]\tLoss: 0.30118\tAccuracy: 0.49909\n",
            "Epoch: 8 [500/3200 (16%)]\tLoss: 0.03591\tAccuracy: 0.70490\n",
            "Epoch: 8 [550/3200 (17%)]\tLoss: 0.17070\tAccuracy: 0.56855\n",
            "Epoch: 8 [600/3200 (19%)]\tLoss: 0.22695\tAccuracy: 0.53335\n",
            "Epoch: 8 [650/3200 (20%)]\tLoss: 0.18359\tAccuracy: 0.53639\n",
            "Epoch: 8 [700/3200 (22%)]\tLoss: 0.10633\tAccuracy: 0.55291\n",
            "Epoch: 8 [750/3200 (23%)]\tLoss: 0.18193\tAccuracy: 0.54839\n",
            "Epoch: 8 [800/3200 (25%)]\tLoss: -0.03685\tAccuracy: 0.65709\n",
            "Epoch: 8 [850/3200 (27%)]\tLoss: 0.03671\tAccuracy: 0.62389\n",
            "Epoch: 8 [900/3200 (28%)]\tLoss: 0.14085\tAccuracy: 0.55993\n",
            "Epoch: 8 [950/3200 (30%)]\tLoss: 0.48190\tAccuracy: 0.35788\n",
            "Epoch: 8 [1000/3200 (31%)]\tLoss: 0.17358\tAccuracy: 0.56660\n",
            "Epoch: 8 [1050/3200 (33%)]\tLoss: 0.06079\tAccuracy: 0.57917\n",
            "Epoch: 8 [1100/3200 (34%)]\tLoss: 0.19734\tAccuracy: 0.56295\n",
            "Epoch: 8 [1150/3200 (36%)]\tLoss: 0.26246\tAccuracy: 0.49720\n",
            "Epoch: 8 [1200/3200 (38%)]\tLoss: 0.13146\tAccuracy: 0.62849\n",
            "Epoch: 8 [1250/3200 (39%)]\tLoss: 0.20708\tAccuracy: 0.54777\n",
            "Epoch: 8 [1300/3200 (41%)]\tLoss: 0.00609\tAccuracy: 0.66506\n",
            "Epoch: 8 [1350/3200 (42%)]\tLoss: 0.21402\tAccuracy: 0.56522\n",
            "Epoch: 8 [1400/3200 (44%)]\tLoss: 0.26076\tAccuracy: 0.47932\n",
            "Epoch: 8 [1450/3200 (45%)]\tLoss: 0.04721\tAccuracy: 0.63100\n",
            "Epoch: 8 [1500/3200 (47%)]\tLoss: 0.21559\tAccuracy: 0.54503\n",
            "Epoch: 8 [1550/3200 (48%)]\tLoss: 0.19201\tAccuracy: 0.58762\n",
            "Epoch: 8 [1600/3200 (50%)]\tLoss: -0.00632\tAccuracy: 0.64864\n",
            "Epoch: 8 [1650/3200 (52%)]\tLoss: -0.04753\tAccuracy: 0.64974\n",
            "Epoch: 8 [1700/3200 (53%)]\tLoss: 0.10016\tAccuracy: 0.59443\n",
            "Epoch: 8 [1750/3200 (55%)]\tLoss: 0.00461\tAccuracy: 0.65643\n",
            "Epoch: 8 [1800/3200 (56%)]\tLoss: 0.02239\tAccuracy: 0.59951\n",
            "Epoch: 8 [1850/3200 (58%)]\tLoss: 0.05185\tAccuracy: 0.65018\n",
            "Epoch: 8 [1900/3200 (59%)]\tLoss: -0.08494\tAccuracy: 0.68851\n",
            "Epoch: 8 [1950/3200 (61%)]\tLoss: -0.03998\tAccuracy: 0.64370\n",
            "Epoch: 8 [2000/3200 (62%)]\tLoss: 0.03427\tAccuracy: 0.65591\n",
            "Epoch: 8 [2050/3200 (64%)]\tLoss: 0.05713\tAccuracy: 0.65484\n",
            "Epoch: 8 [2100/3200 (66%)]\tLoss: 0.17381\tAccuracy: 0.55780\n",
            "Epoch: 8 [2150/3200 (67%)]\tLoss: -0.14863\tAccuracy: 0.73058\n",
            "Epoch: 8 [2200/3200 (69%)]\tLoss: 0.03331\tAccuracy: 0.62533\n",
            "Epoch: 8 [2250/3200 (70%)]\tLoss: 0.18079\tAccuracy: 0.57167\n",
            "Epoch: 8 [2300/3200 (72%)]\tLoss: -0.12850\tAccuracy: 0.72862\n",
            "Epoch: 8 [2350/3200 (73%)]\tLoss: 0.08545\tAccuracy: 0.61543\n",
            "Epoch: 8 [2400/3200 (75%)]\tLoss: -0.19001\tAccuracy: 0.73199\n",
            "Epoch: 8 [2450/3200 (77%)]\tLoss: 0.15071\tAccuracy: 0.56969\n",
            "Epoch: 8 [2500/3200 (78%)]\tLoss: 0.14646\tAccuracy: 0.59450\n",
            "Epoch: 8 [2550/3200 (80%)]\tLoss: 0.24434\tAccuracy: 0.53548\n",
            "Epoch: 8 [2600/3200 (81%)]\tLoss: -0.15542\tAccuracy: 0.71669\n",
            "Epoch: 8 [2650/3200 (83%)]\tLoss: 0.11443\tAccuracy: 0.56612\n",
            "Epoch: 8 [2700/3200 (84%)]\tLoss: -0.03431\tAccuracy: 0.68546\n",
            "Epoch: 8 [2750/3200 (86%)]\tLoss: -0.23123\tAccuracy: 0.79215\n",
            "Epoch: 8 [2800/3200 (88%)]\tLoss: 0.13747\tAccuracy: 0.62122\n",
            "Epoch: 8 [2850/3200 (89%)]\tLoss: 0.03177\tAccuracy: 0.66730\n",
            "Epoch: 8 [2900/3200 (91%)]\tLoss: -0.03202\tAccuracy: 0.67281\n",
            "Epoch: 8 [2950/3200 (92%)]\tLoss: 0.27686\tAccuracy: 0.50270\n",
            "Epoch: 8 [3000/3200 (94%)]\tLoss: 0.29902\tAccuracy: 0.48088\n",
            "Epoch: 8 [3050/3200 (95%)]\tLoss: -0.02146\tAccuracy: 0.68189\n",
            "Epoch: 8 [3100/3200 (97%)]\tLoss: 0.12594\tAccuracy: 0.63424\n",
            "Epoch: 8 [3150/3200 (98%)]\tLoss: -0.08091\tAccuracy: 0.68115\n",
            "Epoch: 8 [3200/3200 (100%)]\tLoss: -0.15494\tAccuracy: 0.71542\n",
            "Train Loss: 0.09944 Train Accuracy: 0.59656\n",
            "Validation Loss: 0.71096 Validation Accuracy: 0.65417\n",
            "[0.001]\n",
            "Epoch: 9 [50/3200 (2%)]\tLoss: 0.03030\tAccuracy: 0.61786\n",
            "Epoch: 9 [100/3200 (3%)]\tLoss: 0.26705\tAccuracy: 0.50143\n",
            "Epoch: 9 [150/3200 (5%)]\tLoss: 0.01202\tAccuracy: 0.62848\n",
            "Epoch: 9 [200/3200 (6%)]\tLoss: 0.08270\tAccuracy: 0.59640\n",
            "Epoch: 9 [250/3200 (8%)]\tLoss: -0.00972\tAccuracy: 0.67034\n",
            "Epoch: 9 [300/3200 (9%)]\tLoss: 0.15645\tAccuracy: 0.56337\n",
            "Epoch: 9 [350/3200 (11%)]\tLoss: 0.11145\tAccuracy: 0.58947\n",
            "Epoch: 9 [400/3200 (12%)]\tLoss: -0.04848\tAccuracy: 0.64928\n",
            "Epoch: 9 [450/3200 (14%)]\tLoss: -0.13103\tAccuracy: 0.71252\n",
            "Epoch: 9 [500/3200 (16%)]\tLoss: 0.05517\tAccuracy: 0.64523\n",
            "Epoch: 9 [550/3200 (17%)]\tLoss: 0.03985\tAccuracy: 0.63283\n",
            "Epoch: 9 [600/3200 (19%)]\tLoss: -0.09568\tAccuracy: 0.73665\n",
            "Epoch: 9 [650/3200 (20%)]\tLoss: 0.16290\tAccuracy: 0.59703\n",
            "Epoch: 9 [700/3200 (22%)]\tLoss: 0.03094\tAccuracy: 0.64925\n",
            "Epoch: 9 [750/3200 (23%)]\tLoss: -0.01381\tAccuracy: 0.63461\n",
            "Epoch: 9 [800/3200 (25%)]\tLoss: -0.08841\tAccuracy: 0.76938\n",
            "Epoch: 9 [850/3200 (27%)]\tLoss: 0.06337\tAccuracy: 0.61722\n",
            "Epoch: 9 [900/3200 (28%)]\tLoss: 0.00778\tAccuracy: 0.63248\n",
            "Epoch: 9 [950/3200 (30%)]\tLoss: -0.08329\tAccuracy: 0.67501\n",
            "Epoch: 9 [1000/3200 (31%)]\tLoss: -0.04139\tAccuracy: 0.64161\n",
            "Epoch: 9 [1050/3200 (33%)]\tLoss: -0.07810\tAccuracy: 0.68949\n",
            "Epoch: 9 [1100/3200 (34%)]\tLoss: -0.01741\tAccuracy: 0.65729\n",
            "Epoch: 9 [1150/3200 (36%)]\tLoss: 0.03988\tAccuracy: 0.66037\n",
            "Epoch: 9 [1200/3200 (38%)]\tLoss: -0.07046\tAccuracy: 0.67232\n",
            "Epoch: 9 [1250/3200 (39%)]\tLoss: 0.17390\tAccuracy: 0.55133\n",
            "Epoch: 9 [1300/3200 (41%)]\tLoss: 0.01470\tAccuracy: 0.66632\n",
            "Epoch: 9 [1350/3200 (42%)]\tLoss: -0.09288\tAccuracy: 0.67469\n",
            "Epoch: 9 [1400/3200 (44%)]\tLoss: 0.03959\tAccuracy: 0.63917\n",
            "Epoch: 9 [1450/3200 (45%)]\tLoss: 0.00918\tAccuracy: 0.67031\n",
            "Epoch: 9 [1500/3200 (47%)]\tLoss: 0.03284\tAccuracy: 0.58950\n",
            "Epoch: 9 [1550/3200 (48%)]\tLoss: -0.09954\tAccuracy: 0.70006\n",
            "Epoch: 9 [1600/3200 (50%)]\tLoss: 0.21317\tAccuracy: 0.54481\n",
            "Epoch: 9 [1650/3200 (52%)]\tLoss: -0.16370\tAccuracy: 0.78441\n",
            "Epoch: 9 [1700/3200 (53%)]\tLoss: -0.08355\tAccuracy: 0.66090\n",
            "Epoch: 9 [1750/3200 (55%)]\tLoss: 0.04330\tAccuracy: 0.61708\n",
            "Epoch: 9 [1800/3200 (56%)]\tLoss: 0.16508\tAccuracy: 0.57078\n",
            "Epoch: 9 [1850/3200 (58%)]\tLoss: -0.01154\tAccuracy: 0.63232\n",
            "Epoch: 9 [1900/3200 (59%)]\tLoss: 0.16358\tAccuracy: 0.55590\n",
            "Epoch: 9 [1950/3200 (61%)]\tLoss: 0.12156\tAccuracy: 0.57515\n",
            "Epoch: 9 [2000/3200 (62%)]\tLoss: -0.16322\tAccuracy: 0.74331\n",
            "Epoch: 9 [2050/3200 (64%)]\tLoss: 0.04514\tAccuracy: 0.65453\n",
            "Epoch: 9 [2100/3200 (66%)]\tLoss: 0.10110\tAccuracy: 0.59928\n",
            "Epoch: 9 [2150/3200 (67%)]\tLoss: -0.08076\tAccuracy: 0.67179\n",
            "Epoch: 9 [2200/3200 (69%)]\tLoss: -0.13598\tAccuracy: 0.69597\n",
            "Epoch: 9 [2250/3200 (70%)]\tLoss: -0.14488\tAccuracy: 0.69582\n",
            "Epoch: 9 [2300/3200 (72%)]\tLoss: -0.00127\tAccuracy: 0.63832\n",
            "Epoch: 9 [2350/3200 (73%)]\tLoss: -0.19977\tAccuracy: 0.77879\n",
            "Epoch: 9 [2400/3200 (75%)]\tLoss: 0.06482\tAccuracy: 0.59786\n",
            "Epoch: 9 [2450/3200 (77%)]\tLoss: 0.07704\tAccuracy: 0.60314\n",
            "Epoch: 9 [2500/3200 (78%)]\tLoss: 0.14597\tAccuracy: 0.56500\n",
            "Epoch: 9 [2550/3200 (80%)]\tLoss: 0.06600\tAccuracy: 0.63439\n",
            "Epoch: 9 [2600/3200 (81%)]\tLoss: -0.00043\tAccuracy: 0.66091\n",
            "Epoch: 9 [2650/3200 (83%)]\tLoss: 0.09054\tAccuracy: 0.64439\n",
            "Epoch: 9 [2700/3200 (84%)]\tLoss: -0.03193\tAccuracy: 0.65327\n",
            "Epoch: 9 [2750/3200 (86%)]\tLoss: 0.14835\tAccuracy: 0.57056\n",
            "Epoch: 9 [2800/3200 (88%)]\tLoss: -0.03898\tAccuracy: 0.63955\n",
            "Epoch: 9 [2850/3200 (89%)]\tLoss: -0.03502\tAccuracy: 0.63596\n",
            "Epoch: 9 [2900/3200 (91%)]\tLoss: -0.11819\tAccuracy: 0.75880\n",
            "Epoch: 9 [2950/3200 (92%)]\tLoss: 0.08389\tAccuracy: 0.63572\n",
            "Epoch: 9 [3000/3200 (94%)]\tLoss: -0.03952\tAccuracy: 0.69956\n",
            "Epoch: 9 [3050/3200 (95%)]\tLoss: -0.03846\tAccuracy: 0.65742\n",
            "Epoch: 9 [3100/3200 (97%)]\tLoss: 0.15015\tAccuracy: 0.54942\n",
            "Epoch: 9 [3150/3200 (98%)]\tLoss: 0.06654\tAccuracy: 0.65384\n",
            "Epoch: 9 [3200/3200 (100%)]\tLoss: 0.04433\tAccuracy: 0.59048\n",
            "Train Loss: 0.01505 Train Accuracy: 0.64220\n",
            "Validation Loss: 0.71160 Validation Accuracy: 0.66817\n",
            "[0.001]\n",
            "Epoch: 10 [50/3200 (2%)]\tLoss: -0.19518\tAccuracy: 0.75555\n",
            "Epoch: 10 [100/3200 (3%)]\tLoss: 0.04511\tAccuracy: 0.63493\n",
            "Epoch: 10 [150/3200 (5%)]\tLoss: 0.04897\tAccuracy: 0.65104\n",
            "Epoch: 10 [200/3200 (6%)]\tLoss: 0.15718\tAccuracy: 0.56342\n",
            "Epoch: 10 [250/3200 (8%)]\tLoss: -0.11932\tAccuracy: 0.73989\n",
            "Epoch: 10 [300/3200 (9%)]\tLoss: 0.07057\tAccuracy: 0.64943\n",
            "Epoch: 10 [350/3200 (11%)]\tLoss: 0.04348\tAccuracy: 0.58682\n",
            "Epoch: 10 [400/3200 (12%)]\tLoss: 0.13029\tAccuracy: 0.56616\n",
            "Epoch: 10 [450/3200 (14%)]\tLoss: -0.03797\tAccuracy: 0.71808\n",
            "Epoch: 10 [500/3200 (16%)]\tLoss: -0.01014\tAccuracy: 0.71013\n",
            "Epoch: 10 [550/3200 (17%)]\tLoss: 0.15606\tAccuracy: 0.58244\n",
            "Epoch: 10 [600/3200 (19%)]\tLoss: 0.03005\tAccuracy: 0.64257\n",
            "Epoch: 10 [650/3200 (20%)]\tLoss: 0.09409\tAccuracy: 0.60223\n",
            "Epoch: 10 [700/3200 (22%)]\tLoss: 0.20375\tAccuracy: 0.53593\n",
            "Epoch: 10 [750/3200 (23%)]\tLoss: 0.03683\tAccuracy: 0.62345\n",
            "Epoch: 10 [800/3200 (25%)]\tLoss: 0.03464\tAccuracy: 0.62049\n",
            "Epoch: 10 [850/3200 (27%)]\tLoss: 0.00439\tAccuracy: 0.67334\n",
            "Epoch: 10 [900/3200 (28%)]\tLoss: 0.07805\tAccuracy: 0.68204\n",
            "Epoch: 10 [950/3200 (30%)]\tLoss: -0.10978\tAccuracy: 0.70543\n",
            "Epoch: 10 [1000/3200 (31%)]\tLoss: 0.21003\tAccuracy: 0.52806\n",
            "Epoch: 10 [1050/3200 (33%)]\tLoss: 0.08978\tAccuracy: 0.60926\n",
            "Epoch: 10 [1100/3200 (34%)]\tLoss: 0.03796\tAccuracy: 0.64060\n",
            "Epoch: 10 [1150/3200 (36%)]\tLoss: -0.08054\tAccuracy: 0.72069\n",
            "Epoch: 10 [1200/3200 (38%)]\tLoss: -0.02263\tAccuracy: 0.70029\n",
            "Epoch: 10 [1250/3200 (39%)]\tLoss: 0.01761\tAccuracy: 0.62488\n",
            "Epoch: 10 [1300/3200 (41%)]\tLoss: 0.17648\tAccuracy: 0.58250\n",
            "Epoch: 10 [1350/3200 (42%)]\tLoss: -0.34071\tAccuracy: 0.81163\n",
            "Epoch: 10 [1400/3200 (44%)]\tLoss: -0.05784\tAccuracy: 0.70124\n",
            "Epoch: 10 [1450/3200 (45%)]\tLoss: 0.03524\tAccuracy: 0.61466\n",
            "Epoch: 10 [1500/3200 (47%)]\tLoss: 0.00200\tAccuracy: 0.62320\n",
            "Epoch: 10 [1550/3200 (48%)]\tLoss: 0.29751\tAccuracy: 0.46390\n",
            "Epoch: 10 [1600/3200 (50%)]\tLoss: 0.13425\tAccuracy: 0.54891\n",
            "Epoch: 10 [1650/3200 (52%)]\tLoss: -0.11457\tAccuracy: 0.71108\n",
            "Epoch: 10 [1700/3200 (53%)]\tLoss: 0.10949\tAccuracy: 0.57027\n",
            "Epoch: 10 [1750/3200 (55%)]\tLoss: -0.09644\tAccuracy: 0.68132\n",
            "Epoch: 10 [1800/3200 (56%)]\tLoss: 0.07269\tAccuracy: 0.60767\n",
            "Epoch: 10 [1850/3200 (58%)]\tLoss: 0.07109\tAccuracy: 0.59500\n",
            "Epoch: 10 [1900/3200 (59%)]\tLoss: 0.00981\tAccuracy: 0.65274\n",
            "Epoch: 10 [1950/3200 (61%)]\tLoss: 0.12221\tAccuracy: 0.57856\n",
            "Epoch: 10 [2000/3200 (62%)]\tLoss: 0.00488\tAccuracy: 0.63959\n",
            "Epoch: 10 [2050/3200 (64%)]\tLoss: 0.13487\tAccuracy: 0.57075\n",
            "Epoch: 10 [2100/3200 (66%)]\tLoss: 0.14337\tAccuracy: 0.57588\n",
            "Epoch: 10 [2150/3200 (67%)]\tLoss: -0.00688\tAccuracy: 0.66973\n",
            "Epoch: 10 [2200/3200 (69%)]\tLoss: 0.11246\tAccuracy: 0.58943\n",
            "Epoch: 10 [2250/3200 (70%)]\tLoss: 0.09655\tAccuracy: 0.54217\n",
            "Epoch: 10 [2300/3200 (72%)]\tLoss: -0.11484\tAccuracy: 0.65847\n",
            "Epoch: 10 [2350/3200 (73%)]\tLoss: 0.24283\tAccuracy: 0.55603\n",
            "Epoch: 10 [2400/3200 (75%)]\tLoss: -0.03167\tAccuracy: 0.66227\n",
            "Epoch: 10 [2450/3200 (77%)]\tLoss: 0.02841\tAccuracy: 0.61247\n",
            "Epoch: 10 [2500/3200 (78%)]\tLoss: 0.06018\tAccuracy: 0.60128\n",
            "Epoch: 10 [2550/3200 (80%)]\tLoss: 0.06469\tAccuracy: 0.61496\n",
            "Epoch: 10 [2600/3200 (81%)]\tLoss: 0.10373\tAccuracy: 0.57577\n",
            "Epoch: 10 [2650/3200 (83%)]\tLoss: -0.09991\tAccuracy: 0.64062\n",
            "Epoch: 10 [2700/3200 (84%)]\tLoss: -0.07889\tAccuracy: 0.69795\n",
            "Epoch: 10 [2750/3200 (86%)]\tLoss: -0.11416\tAccuracy: 0.69529\n",
            "Epoch: 10 [2800/3200 (88%)]\tLoss: -0.12910\tAccuracy: 0.66844\n",
            "Epoch: 10 [2850/3200 (89%)]\tLoss: 0.12708\tAccuracy: 0.51314\n",
            "Epoch: 10 [2900/3200 (91%)]\tLoss: -0.06382\tAccuracy: 0.65386\n",
            "Epoch: 10 [2950/3200 (92%)]\tLoss: 0.38495\tAccuracy: 0.45316\n",
            "Epoch: 10 [3000/3200 (94%)]\tLoss: -0.02868\tAccuracy: 0.66996\n",
            "Epoch: 10 [3050/3200 (95%)]\tLoss: 0.01424\tAccuracy: 0.66518\n",
            "Epoch: 10 [3100/3200 (97%)]\tLoss: 0.05012\tAccuracy: 0.58952\n",
            "Epoch: 10 [3150/3200 (98%)]\tLoss: -0.22971\tAccuracy: 0.77048\n",
            "Epoch: 10 [3200/3200 (100%)]\tLoss: -0.00391\tAccuracy: 0.64081\n",
            "Train Loss: 0.03127 Train Accuracy: 0.63027\n",
            "Validation Loss: 0.71649 Validation Accuracy: 0.64265\n",
            "[0.001]\n",
            "Epoch: 11 [50/3200 (2%)]\tLoss: 0.22849\tAccuracy: 0.53084\n",
            "Epoch: 11 [100/3200 (3%)]\tLoss: -0.08913\tAccuracy: 0.72889\n",
            "Epoch: 11 [150/3200 (5%)]\tLoss: 0.21177\tAccuracy: 0.52646\n",
            "Epoch: 11 [200/3200 (6%)]\tLoss: 0.12654\tAccuracy: 0.63369\n",
            "Epoch: 11 [250/3200 (8%)]\tLoss: 0.19960\tAccuracy: 0.54040\n",
            "Epoch: 11 [300/3200 (9%)]\tLoss: -0.08986\tAccuracy: 0.67025\n",
            "Epoch: 11 [350/3200 (11%)]\tLoss: 0.11448\tAccuracy: 0.60414\n",
            "Epoch: 11 [400/3200 (12%)]\tLoss: 0.07249\tAccuracy: 0.60770\n",
            "Epoch: 11 [450/3200 (14%)]\tLoss: 0.08593\tAccuracy: 0.63440\n",
            "Epoch: 11 [500/3200 (16%)]\tLoss: 0.12936\tAccuracy: 0.59007\n",
            "Epoch: 11 [550/3200 (17%)]\tLoss: 0.09613\tAccuracy: 0.60019\n",
            "Epoch: 11 [600/3200 (19%)]\tLoss: 0.14795\tAccuracy: 0.60890\n",
            "Epoch: 11 [650/3200 (20%)]\tLoss: -0.29184\tAccuracy: 0.79229\n",
            "Epoch: 11 [700/3200 (22%)]\tLoss: -0.07300\tAccuracy: 0.69309\n",
            "Epoch: 11 [750/3200 (23%)]\tLoss: 0.10142\tAccuracy: 0.63830\n",
            "Epoch: 11 [800/3200 (25%)]\tLoss: -0.13010\tAccuracy: 0.73011\n",
            "Epoch: 11 [850/3200 (27%)]\tLoss: -0.05579\tAccuracy: 0.65470\n",
            "Epoch: 11 [900/3200 (28%)]\tLoss: 0.06972\tAccuracy: 0.60999\n",
            "Epoch: 11 [950/3200 (30%)]\tLoss: 0.08360\tAccuracy: 0.57641\n",
            "Epoch: 11 [1000/3200 (31%)]\tLoss: 0.07264\tAccuracy: 0.58610\n",
            "Epoch: 11 [1050/3200 (33%)]\tLoss: 0.32448\tAccuracy: 0.47406\n",
            "Epoch: 11 [1100/3200 (34%)]\tLoss: -0.02119\tAccuracy: 0.68139\n",
            "Epoch: 11 [1150/3200 (36%)]\tLoss: -0.09253\tAccuracy: 0.71275\n",
            "Epoch: 11 [1200/3200 (38%)]\tLoss: 0.12586\tAccuracy: 0.61355\n",
            "Epoch: 11 [1250/3200 (39%)]\tLoss: -0.07751\tAccuracy: 0.71780\n",
            "Epoch: 11 [1300/3200 (41%)]\tLoss: 0.02318\tAccuracy: 0.59785\n",
            "Epoch: 11 [1350/3200 (42%)]\tLoss: -0.03885\tAccuracy: 0.65152\n",
            "Epoch: 11 [1400/3200 (44%)]\tLoss: -0.01142\tAccuracy: 0.67013\n",
            "Epoch: 11 [1450/3200 (45%)]\tLoss: 0.19413\tAccuracy: 0.54395\n",
            "Epoch: 11 [1500/3200 (47%)]\tLoss: -0.07550\tAccuracy: 0.69575\n",
            "Epoch: 11 [1550/3200 (48%)]\tLoss: -0.07539\tAccuracy: 0.66572\n",
            "Epoch: 11 [1600/3200 (50%)]\tLoss: 0.24199\tAccuracy: 0.51755\n",
            "Epoch: 11 [1650/3200 (52%)]\tLoss: 0.01200\tAccuracy: 0.66752\n",
            "Epoch: 11 [1700/3200 (53%)]\tLoss: -0.05221\tAccuracy: 0.68751\n",
            "Epoch: 11 [1750/3200 (55%)]\tLoss: 0.20964\tAccuracy: 0.56753\n",
            "Epoch: 11 [1800/3200 (56%)]\tLoss: 0.00220\tAccuracy: 0.65541\n",
            "Epoch: 11 [1850/3200 (58%)]\tLoss: -0.01957\tAccuracy: 0.68911\n",
            "Epoch: 11 [1900/3200 (59%)]\tLoss: -0.01060\tAccuracy: 0.62772\n",
            "Epoch: 11 [1950/3200 (61%)]\tLoss: -0.04651\tAccuracy: 0.67520\n",
            "Epoch: 11 [2000/3200 (62%)]\tLoss: 0.04733\tAccuracy: 0.59314\n",
            "Epoch: 11 [2050/3200 (64%)]\tLoss: -0.01845\tAccuracy: 0.65478\n",
            "Epoch: 11 [2100/3200 (66%)]\tLoss: -0.18733\tAccuracy: 0.70868\n",
            "Epoch: 11 [2150/3200 (67%)]\tLoss: 0.04410\tAccuracy: 0.62303\n",
            "Epoch: 11 [2200/3200 (69%)]\tLoss: -0.04955\tAccuracy: 0.62185\n",
            "Epoch: 11 [2250/3200 (70%)]\tLoss: 0.09860\tAccuracy: 0.55796\n",
            "Epoch: 11 [2300/3200 (72%)]\tLoss: 0.18159\tAccuracy: 0.53794\n",
            "Epoch: 11 [2350/3200 (73%)]\tLoss: -0.03838\tAccuracy: 0.63959\n",
            "Epoch: 11 [2400/3200 (75%)]\tLoss: 0.13161\tAccuracy: 0.54019\n",
            "Epoch: 11 [2450/3200 (77%)]\tLoss: 0.17680\tAccuracy: 0.48650\n",
            "Epoch: 11 [2500/3200 (78%)]\tLoss: 0.15335\tAccuracy: 0.54670\n",
            "Epoch: 11 [2550/3200 (80%)]\tLoss: 0.04101\tAccuracy: 0.58164\n",
            "Epoch: 11 [2600/3200 (81%)]\tLoss: -0.14145\tAccuracy: 0.66629\n",
            "Epoch: 11 [2650/3200 (83%)]\tLoss: -0.14164\tAccuracy: 0.68531\n",
            "Epoch: 11 [2700/3200 (84%)]\tLoss: 0.13338\tAccuracy: 0.56779\n",
            "Epoch: 11 [2750/3200 (86%)]\tLoss: 0.06767\tAccuracy: 0.55262\n",
            "Epoch: 11 [2800/3200 (88%)]\tLoss: 0.09802\tAccuracy: 0.56251\n",
            "Epoch: 11 [2850/3200 (89%)]\tLoss: 0.24718\tAccuracy: 0.47499\n",
            "Epoch: 11 [2900/3200 (91%)]\tLoss: 0.07840\tAccuracy: 0.56420\n",
            "Epoch: 11 [2950/3200 (92%)]\tLoss: 0.07412\tAccuracy: 0.57353\n",
            "Epoch: 11 [3000/3200 (94%)]\tLoss: 0.12229\tAccuracy: 0.55811\n",
            "Epoch: 11 [3050/3200 (95%)]\tLoss: -0.01446\tAccuracy: 0.63553\n",
            "Epoch: 11 [3100/3200 (97%)]\tLoss: 0.00293\tAccuracy: 0.63630\n",
            "Epoch: 11 [3150/3200 (98%)]\tLoss: 0.01871\tAccuracy: 0.60102\n",
            "Epoch: 11 [3200/3200 (100%)]\tLoss: 0.18218\tAccuracy: 0.53819\n",
            "Train Loss: 0.04579 Train Accuracy: 0.61527\n",
            "Validation Loss: 0.71838 Validation Accuracy: 0.62483\n",
            "[0.001]\n",
            "Epoch: 12 [50/3200 (2%)]\tLoss: 0.08394\tAccuracy: 0.55758\n",
            "Epoch: 12 [100/3200 (3%)]\tLoss: -0.11215\tAccuracy: 0.67268\n",
            "Epoch: 12 [150/3200 (5%)]\tLoss: 0.34199\tAccuracy: 0.45816\n",
            "Epoch: 12 [200/3200 (6%)]\tLoss: 0.15455\tAccuracy: 0.52637\n",
            "Epoch: 12 [250/3200 (8%)]\tLoss: 0.09231\tAccuracy: 0.62604\n",
            "Epoch: 12 [300/3200 (9%)]\tLoss: 0.08281\tAccuracy: 0.59126\n",
            "Epoch: 12 [350/3200 (11%)]\tLoss: 0.00141\tAccuracy: 0.58963\n",
            "Epoch: 12 [400/3200 (12%)]\tLoss: -0.11888\tAccuracy: 0.69977\n",
            "Epoch: 12 [450/3200 (14%)]\tLoss: 0.04755\tAccuracy: 0.63250\n",
            "Epoch: 12 [500/3200 (16%)]\tLoss: 0.11614\tAccuracy: 0.58033\n",
            "Epoch: 12 [550/3200 (17%)]\tLoss: 0.00803\tAccuracy: 0.63257\n",
            "Epoch: 12 [600/3200 (19%)]\tLoss: 0.12417\tAccuracy: 0.58643\n",
            "Epoch: 12 [650/3200 (20%)]\tLoss: 0.09334\tAccuracy: 0.61906\n",
            "Epoch: 12 [700/3200 (22%)]\tLoss: 0.01136\tAccuracy: 0.62826\n",
            "Epoch: 12 [750/3200 (23%)]\tLoss: 0.01494\tAccuracy: 0.60568\n",
            "Epoch: 12 [800/3200 (25%)]\tLoss: 0.14294\tAccuracy: 0.52004\n",
            "Epoch: 12 [850/3200 (27%)]\tLoss: -0.10446\tAccuracy: 0.68104\n",
            "Epoch: 12 [900/3200 (28%)]\tLoss: -0.05937\tAccuracy: 0.65757\n",
            "Epoch: 12 [950/3200 (30%)]\tLoss: 0.00210\tAccuracy: 0.65859\n",
            "Epoch: 12 [1000/3200 (31%)]\tLoss: -0.16290\tAccuracy: 0.76189\n",
            "Epoch: 12 [1050/3200 (33%)]\tLoss: 0.10335\tAccuracy: 0.59511\n",
            "Epoch: 12 [1100/3200 (34%)]\tLoss: 0.16396\tAccuracy: 0.59466\n",
            "Epoch: 12 [1150/3200 (36%)]\tLoss: 0.05404\tAccuracy: 0.62466\n",
            "Epoch: 12 [1200/3200 (38%)]\tLoss: -0.13323\tAccuracy: 0.73349\n",
            "Epoch: 12 [1250/3200 (39%)]\tLoss: 0.02539\tAccuracy: 0.65212\n",
            "Epoch: 12 [1300/3200 (41%)]\tLoss: 0.02780\tAccuracy: 0.63043\n",
            "Epoch: 12 [1350/3200 (42%)]\tLoss: 0.29547\tAccuracy: 0.48357\n",
            "Epoch: 12 [1400/3200 (44%)]\tLoss: 0.11242\tAccuracy: 0.58667\n",
            "Epoch: 12 [1450/3200 (45%)]\tLoss: -0.09093\tAccuracy: 0.65180\n",
            "Epoch: 12 [1500/3200 (47%)]\tLoss: -0.00090\tAccuracy: 0.66058\n",
            "Epoch: 12 [1550/3200 (48%)]\tLoss: 0.13907\tAccuracy: 0.60089\n",
            "Epoch: 12 [1600/3200 (50%)]\tLoss: 0.02206\tAccuracy: 0.65815\n",
            "Epoch: 12 [1650/3200 (52%)]\tLoss: -0.04188\tAccuracy: 0.68143\n",
            "Epoch: 12 [1700/3200 (53%)]\tLoss: 0.17104\tAccuracy: 0.56778\n",
            "Epoch: 12 [1750/3200 (55%)]\tLoss: -0.08812\tAccuracy: 0.65160\n",
            "Epoch: 12 [1800/3200 (56%)]\tLoss: 0.13768\tAccuracy: 0.58149\n",
            "Epoch: 12 [1850/3200 (58%)]\tLoss: -0.02418\tAccuracy: 0.69380\n",
            "Epoch: 12 [1900/3200 (59%)]\tLoss: -0.05704\tAccuracy: 0.69041\n",
            "Epoch: 12 [1950/3200 (61%)]\tLoss: -0.03071\tAccuracy: 0.65300\n",
            "Epoch: 12 [2000/3200 (62%)]\tLoss: -0.24366\tAccuracy: 0.78429\n",
            "Epoch: 12 [2050/3200 (64%)]\tLoss: 0.06313\tAccuracy: 0.65672\n",
            "Epoch: 12 [2100/3200 (66%)]\tLoss: -0.12581\tAccuracy: 0.72590\n",
            "Epoch: 12 [2150/3200 (67%)]\tLoss: 0.02425\tAccuracy: 0.62576\n",
            "Epoch: 12 [2200/3200 (69%)]\tLoss: -0.16700\tAccuracy: 0.74705\n",
            "Epoch: 12 [2250/3200 (70%)]\tLoss: 0.06414\tAccuracy: 0.65534\n",
            "Epoch: 12 [2300/3200 (72%)]\tLoss: -0.08643\tAccuracy: 0.66679\n",
            "Epoch: 12 [2350/3200 (73%)]\tLoss: 0.02095\tAccuracy: 0.67418\n",
            "Epoch: 12 [2400/3200 (75%)]\tLoss: 0.20265\tAccuracy: 0.49753\n",
            "Epoch: 12 [2450/3200 (77%)]\tLoss: 0.03931\tAccuracy: 0.60928\n",
            "Epoch: 12 [2500/3200 (78%)]\tLoss: -0.25786\tAccuracy: 0.73837\n",
            "Epoch: 12 [2550/3200 (80%)]\tLoss: 0.04464\tAccuracy: 0.61219\n",
            "Epoch: 12 [2600/3200 (81%)]\tLoss: -0.07248\tAccuracy: 0.65242\n",
            "Epoch: 12 [2650/3200 (83%)]\tLoss: 0.09623\tAccuracy: 0.58425\n",
            "Epoch: 12 [2700/3200 (84%)]\tLoss: 0.11324\tAccuracy: 0.60592\n",
            "Epoch: 12 [2750/3200 (86%)]\tLoss: -0.02970\tAccuracy: 0.63056\n",
            "Epoch: 12 [2800/3200 (88%)]\tLoss: 0.22725\tAccuracy: 0.49202\n",
            "Epoch: 12 [2850/3200 (89%)]\tLoss: -0.06841\tAccuracy: 0.68677\n",
            "Epoch: 12 [2900/3200 (91%)]\tLoss: 0.06274\tAccuracy: 0.61703\n",
            "Epoch: 12 [2950/3200 (92%)]\tLoss: 0.14056\tAccuracy: 0.55725\n",
            "Epoch: 12 [3000/3200 (94%)]\tLoss: 0.02882\tAccuracy: 0.65033\n",
            "Epoch: 12 [3050/3200 (95%)]\tLoss: -0.00355\tAccuracy: 0.63306\n",
            "Epoch: 12 [3100/3200 (97%)]\tLoss: 0.16252\tAccuracy: 0.59720\n",
            "Epoch: 12 [3150/3200 (98%)]\tLoss: 0.13072\tAccuracy: 0.52659\n",
            "Epoch: 12 [3200/3200 (100%)]\tLoss: 0.15138\tAccuracy: 0.56746\n",
            "Train Loss: 0.03223 Train Accuracy: 0.62611\n",
            "Validation Loss: 0.71370 Validation Accuracy: 0.65433\n",
            "[0.001]\n",
            "Epoch: 13 [50/3200 (2%)]\tLoss: 0.03189\tAccuracy: 0.64776\n",
            "Epoch: 13 [100/3200 (3%)]\tLoss: -0.03030\tAccuracy: 0.70739\n",
            "Epoch: 13 [150/3200 (5%)]\tLoss: 0.08734\tAccuracy: 0.62476\n",
            "Epoch: 13 [200/3200 (6%)]\tLoss: -0.16305\tAccuracy: 0.74300\n",
            "Epoch: 13 [250/3200 (8%)]\tLoss: 0.12328\tAccuracy: 0.61638\n",
            "Epoch: 13 [300/3200 (9%)]\tLoss: 0.05571\tAccuracy: 0.66423\n",
            "Epoch: 13 [350/3200 (11%)]\tLoss: 0.08255\tAccuracy: 0.63730\n",
            "Epoch: 13 [400/3200 (12%)]\tLoss: 0.15174\tAccuracy: 0.58751\n",
            "Epoch: 13 [450/3200 (14%)]\tLoss: -0.04519\tAccuracy: 0.62631\n",
            "Epoch: 13 [500/3200 (16%)]\tLoss: -0.14987\tAccuracy: 0.72971\n",
            "Epoch: 13 [550/3200 (17%)]\tLoss: -0.06255\tAccuracy: 0.65864\n",
            "Epoch: 13 [600/3200 (19%)]\tLoss: 0.01081\tAccuracy: 0.64788\n",
            "Epoch: 13 [650/3200 (20%)]\tLoss: 0.00221\tAccuracy: 0.63388\n",
            "Epoch: 13 [700/3200 (22%)]\tLoss: -0.01523\tAccuracy: 0.65408\n",
            "Epoch: 13 [750/3200 (23%)]\tLoss: 0.00099\tAccuracy: 0.65498\n",
            "Epoch: 13 [800/3200 (25%)]\tLoss: -0.02857\tAccuracy: 0.64868\n",
            "Epoch: 13 [850/3200 (27%)]\tLoss: -0.22065\tAccuracy: 0.77821\n",
            "Epoch: 13 [900/3200 (28%)]\tLoss: 0.11778\tAccuracy: 0.62142\n",
            "Epoch: 13 [950/3200 (30%)]\tLoss: 0.17066\tAccuracy: 0.54769\n",
            "Epoch: 13 [1000/3200 (31%)]\tLoss: 0.12403\tAccuracy: 0.57360\n",
            "Epoch: 13 [1050/3200 (33%)]\tLoss: 0.00190\tAccuracy: 0.63054\n",
            "Epoch: 13 [1100/3200 (34%)]\tLoss: -0.03176\tAccuracy: 0.70916\n",
            "Epoch: 13 [1150/3200 (36%)]\tLoss: -0.06038\tAccuracy: 0.69767\n",
            "Epoch: 13 [1200/3200 (38%)]\tLoss: 0.05720\tAccuracy: 0.60043\n",
            "Epoch: 13 [1250/3200 (39%)]\tLoss: -0.02824\tAccuracy: 0.64810\n",
            "Epoch: 13 [1300/3200 (41%)]\tLoss: 0.32616\tAccuracy: 0.47348\n",
            "Epoch: 13 [1350/3200 (42%)]\tLoss: 0.10686\tAccuracy: 0.58845\n",
            "Epoch: 13 [1400/3200 (44%)]\tLoss: 0.03296\tAccuracy: 0.62601\n",
            "Epoch: 13 [1450/3200 (45%)]\tLoss: 0.11519\tAccuracy: 0.58428\n",
            "Epoch: 13 [1500/3200 (47%)]\tLoss: 0.05413\tAccuracy: 0.62572\n",
            "Epoch: 13 [1550/3200 (48%)]\tLoss: 0.08811\tAccuracy: 0.63111\n",
            "Epoch: 13 [1600/3200 (50%)]\tLoss: 0.01167\tAccuracy: 0.66821\n",
            "Epoch: 13 [1650/3200 (52%)]\tLoss: 0.07262\tAccuracy: 0.66412\n",
            "Epoch: 13 [1700/3200 (53%)]\tLoss: 0.07342\tAccuracy: 0.62284\n",
            "Epoch: 13 [1750/3200 (55%)]\tLoss: -0.17792\tAccuracy: 0.75699\n",
            "Epoch: 13 [1800/3200 (56%)]\tLoss: 0.07633\tAccuracy: 0.62262\n",
            "Epoch: 13 [1850/3200 (58%)]\tLoss: 0.06807\tAccuracy: 0.62843\n",
            "Epoch: 13 [1900/3200 (59%)]\tLoss: 0.08523\tAccuracy: 0.60050\n",
            "Epoch: 13 [1950/3200 (61%)]\tLoss: 0.02853\tAccuracy: 0.63172\n",
            "Epoch: 13 [2000/3200 (62%)]\tLoss: 0.09809\tAccuracy: 0.58159\n",
            "Epoch: 13 [2050/3200 (64%)]\tLoss: 0.19144\tAccuracy: 0.54801\n",
            "Epoch: 13 [2100/3200 (66%)]\tLoss: -0.06792\tAccuracy: 0.65502\n",
            "Epoch: 13 [2150/3200 (67%)]\tLoss: -0.03215\tAccuracy: 0.66889\n",
            "Epoch: 13 [2200/3200 (69%)]\tLoss: 0.03781\tAccuracy: 0.66197\n",
            "Epoch: 13 [2250/3200 (70%)]\tLoss: -0.13181\tAccuracy: 0.74164\n",
            "Epoch: 13 [2300/3200 (72%)]\tLoss: 0.23480\tAccuracy: 0.55281\n",
            "Epoch: 13 [2350/3200 (73%)]\tLoss: -0.30564\tAccuracy: 0.82551\n",
            "Epoch: 13 [2400/3200 (75%)]\tLoss: 0.18867\tAccuracy: 0.57099\n",
            "Epoch: 13 [2450/3200 (77%)]\tLoss: 0.15683\tAccuracy: 0.58206\n",
            "Epoch: 13 [2500/3200 (78%)]\tLoss: 0.19701\tAccuracy: 0.53184\n",
            "Epoch: 13 [2550/3200 (80%)]\tLoss: -0.04078\tAccuracy: 0.68075\n",
            "Epoch: 13 [2600/3200 (81%)]\tLoss: -0.06519\tAccuracy: 0.68312\n",
            "Epoch: 13 [2650/3200 (83%)]\tLoss: -0.04624\tAccuracy: 0.64622\n",
            "Epoch: 13 [2700/3200 (84%)]\tLoss: 0.04927\tAccuracy: 0.58073\n",
            "Epoch: 13 [2750/3200 (86%)]\tLoss: -0.05507\tAccuracy: 0.69432\n",
            "Epoch: 13 [2800/3200 (88%)]\tLoss: 0.19261\tAccuracy: 0.56749\n",
            "Epoch: 13 [2850/3200 (89%)]\tLoss: -0.05390\tAccuracy: 0.69363\n",
            "Epoch: 13 [2900/3200 (91%)]\tLoss: 0.11549\tAccuracy: 0.55581\n",
            "Epoch: 13 [2950/3200 (92%)]\tLoss: -0.10831\tAccuracy: 0.68826\n",
            "Epoch: 13 [3000/3200 (94%)]\tLoss: -0.08317\tAccuracy: 0.66362\n",
            "Epoch: 13 [3050/3200 (95%)]\tLoss: -0.14547\tAccuracy: 0.70495\n",
            "Epoch: 13 [3100/3200 (97%)]\tLoss: 0.07422\tAccuracy: 0.64442\n",
            "Epoch: 13 [3150/3200 (98%)]\tLoss: 0.10060\tAccuracy: 0.59857\n",
            "Epoch: 13 [3200/3200 (100%)]\tLoss: 0.10804\tAccuracy: 0.59176\n",
            "Train Loss: 0.02739 Train Accuracy: 0.63950\n",
            "Validation Loss: 0.71307 Validation Accuracy: 0.65709\n",
            "[0.001]\n",
            "Epoch: 14 [50/3200 (2%)]\tLoss: 0.16091\tAccuracy: 0.57471\n",
            "Epoch: 14 [100/3200 (3%)]\tLoss: 0.19658\tAccuracy: 0.53263\n",
            "Epoch: 14 [150/3200 (5%)]\tLoss: 0.03564\tAccuracy: 0.60380\n",
            "Epoch: 14 [200/3200 (6%)]\tLoss: 0.01483\tAccuracy: 0.62487\n",
            "Epoch: 14 [250/3200 (8%)]\tLoss: 0.08115\tAccuracy: 0.59858\n",
            "Epoch: 14 [300/3200 (9%)]\tLoss: 0.10996\tAccuracy: 0.58923\n",
            "Epoch: 14 [350/3200 (11%)]\tLoss: -0.16929\tAccuracy: 0.70747\n",
            "Epoch: 14 [400/3200 (12%)]\tLoss: 0.00548\tAccuracy: 0.65222\n",
            "Epoch: 14 [450/3200 (14%)]\tLoss: 0.06096\tAccuracy: 0.62461\n",
            "Epoch: 14 [500/3200 (16%)]\tLoss: 0.08415\tAccuracy: 0.59537\n",
            "Epoch: 14 [550/3200 (17%)]\tLoss: 0.08038\tAccuracy: 0.59765\n",
            "Epoch: 14 [600/3200 (19%)]\tLoss: 0.03276\tAccuracy: 0.62489\n",
            "Epoch: 14 [650/3200 (20%)]\tLoss: -0.02828\tAccuracy: 0.68125\n",
            "Epoch: 14 [700/3200 (22%)]\tLoss: -0.06532\tAccuracy: 0.70520\n",
            "Epoch: 14 [750/3200 (23%)]\tLoss: -0.03039\tAccuracy: 0.65061\n",
            "Epoch: 14 [800/3200 (25%)]\tLoss: -0.19065\tAccuracy: 0.74688\n",
            "Epoch: 14 [850/3200 (27%)]\tLoss: 0.10902\tAccuracy: 0.59004\n",
            "Epoch: 14 [900/3200 (28%)]\tLoss: 0.15772\tAccuracy: 0.60231\n",
            "Epoch: 14 [950/3200 (30%)]\tLoss: -0.07915\tAccuracy: 0.67912\n",
            "Epoch: 14 [1000/3200 (31%)]\tLoss: -0.11697\tAccuracy: 0.69594\n",
            "Epoch: 14 [1050/3200 (33%)]\tLoss: -0.02270\tAccuracy: 0.64061\n",
            "Epoch: 14 [1100/3200 (34%)]\tLoss: -0.05425\tAccuracy: 0.65313\n",
            "Epoch: 14 [1150/3200 (36%)]\tLoss: 0.01761\tAccuracy: 0.67890\n",
            "Epoch: 14 [1200/3200 (38%)]\tLoss: -0.00542\tAccuracy: 0.64540\n",
            "Epoch: 14 [1250/3200 (39%)]\tLoss: 0.10379\tAccuracy: 0.63480\n",
            "Epoch: 14 [1300/3200 (41%)]\tLoss: -0.16271\tAccuracy: 0.78292\n",
            "Epoch: 14 [1350/3200 (42%)]\tLoss: 0.02164\tAccuracy: 0.61686\n",
            "Epoch: 14 [1400/3200 (44%)]\tLoss: -0.01379\tAccuracy: 0.65374\n",
            "Epoch: 14 [1450/3200 (45%)]\tLoss: -0.03908\tAccuracy: 0.67884\n",
            "Epoch: 14 [1500/3200 (47%)]\tLoss: -0.02482\tAccuracy: 0.66398\n",
            "Epoch: 14 [1550/3200 (48%)]\tLoss: -0.15806\tAccuracy: 0.73757\n",
            "Epoch: 14 [1600/3200 (50%)]\tLoss: 0.04748\tAccuracy: 0.64224\n",
            "Epoch: 14 [1650/3200 (52%)]\tLoss: -0.04275\tAccuracy: 0.65929\n",
            "Epoch: 14 [1700/3200 (53%)]\tLoss: 0.04090\tAccuracy: 0.61814\n",
            "Epoch: 14 [1750/3200 (55%)]\tLoss: 0.05286\tAccuracy: 0.64646\n",
            "Epoch: 14 [1800/3200 (56%)]\tLoss: -0.07209\tAccuracy: 0.71208\n",
            "Epoch: 14 [1850/3200 (58%)]\tLoss: 0.14517\tAccuracy: 0.59328\n",
            "Epoch: 14 [1900/3200 (59%)]\tLoss: 0.04684\tAccuracy: 0.63257\n",
            "Epoch: 14 [1950/3200 (61%)]\tLoss: -0.02845\tAccuracy: 0.64595\n",
            "Epoch: 14 [2000/3200 (62%)]\tLoss: -0.01857\tAccuracy: 0.70155\n",
            "Epoch: 14 [2050/3200 (64%)]\tLoss: 0.12810\tAccuracy: 0.56950\n",
            "Epoch: 14 [2100/3200 (66%)]\tLoss: 0.10768\tAccuracy: 0.59143\n",
            "Epoch: 14 [2150/3200 (67%)]\tLoss: 0.15376\tAccuracy: 0.60450\n",
            "Epoch: 14 [2200/3200 (69%)]\tLoss: -0.07397\tAccuracy: 0.67186\n",
            "Epoch: 14 [2250/3200 (70%)]\tLoss: 0.08780\tAccuracy: 0.61140\n",
            "Epoch: 14 [2300/3200 (72%)]\tLoss: 0.07698\tAccuracy: 0.59276\n",
            "Epoch: 14 [2350/3200 (73%)]\tLoss: 0.01557\tAccuracy: 0.64442\n",
            "Epoch: 14 [2400/3200 (75%)]\tLoss: -0.00006\tAccuracy: 0.71951\n",
            "Epoch: 14 [2450/3200 (77%)]\tLoss: -0.03943\tAccuracy: 0.68915\n",
            "Epoch: 14 [2500/3200 (78%)]\tLoss: 0.10055\tAccuracy: 0.55355\n",
            "Epoch: 14 [2550/3200 (80%)]\tLoss: -0.07737\tAccuracy: 0.61112\n",
            "Epoch: 14 [2600/3200 (81%)]\tLoss: 0.24416\tAccuracy: 0.41548\n",
            "Epoch: 14 [2650/3200 (83%)]\tLoss: 0.55904\tAccuracy: 0.23924\n",
            "Epoch: 14 [2700/3200 (84%)]\tLoss: 0.54375\tAccuracy: 0.27567\n",
            "Epoch: 14 [2750/3200 (86%)]\tLoss: 0.62120\tAccuracy: 0.23554\n",
            "Epoch: 14 [2800/3200 (88%)]\tLoss: 0.60301\tAccuracy: 0.21684\n",
            "Epoch: 14 [2850/3200 (89%)]\tLoss: 0.57559\tAccuracy: 0.22422\n",
            "Epoch: 14 [2900/3200 (91%)]\tLoss: 0.83754\tAccuracy: 0.10156\n",
            "Epoch: 14 [2950/3200 (92%)]\tLoss: 0.54947\tAccuracy: 0.24773\n",
            "Epoch: 14 [3000/3200 (94%)]\tLoss: 0.70859\tAccuracy: 0.15776\n",
            "Epoch: 14 [3050/3200 (95%)]\tLoss: 0.77668\tAccuracy: 0.12306\n",
            "Epoch: 14 [3100/3200 (97%)]\tLoss: 0.75468\tAccuracy: 0.14313\n",
            "Epoch: 14 [3150/3200 (98%)]\tLoss: 0.81723\tAccuracy: 0.10241\n",
            "Epoch: 14 [3200/3200 (100%)]\tLoss: 0.85537\tAccuracy: 0.08170\n",
            "Train Loss: 0.14389 Train Accuracy: 0.55218\n",
            "Validation Loss: 0.76071 Validation Accuracy: 0.17406\n",
            "[0.001]\n",
            "Epoch: 15 [50/3200 (2%)]\tLoss: 0.61691\tAccuracy: 0.20239\n",
            "Epoch: 15 [100/3200 (3%)]\tLoss: 0.75430\tAccuracy: 0.14214\n",
            "Epoch: 15 [150/3200 (5%)]\tLoss: 0.58273\tAccuracy: 0.21336\n",
            "Epoch: 15 [200/3200 (6%)]\tLoss: 0.65809\tAccuracy: 0.17128\n",
            "Epoch: 15 [250/3200 (8%)]\tLoss: 0.70131\tAccuracy: 0.17767\n",
            "Epoch: 15 [300/3200 (9%)]\tLoss: 0.65639\tAccuracy: 0.18311\n",
            "Epoch: 15 [350/3200 (11%)]\tLoss: 0.63454\tAccuracy: 0.18470\n",
            "Epoch: 15 [400/3200 (12%)]\tLoss: 0.50835\tAccuracy: 0.25163\n",
            "Epoch: 15 [450/3200 (14%)]\tLoss: 0.69736\tAccuracy: 0.16162\n",
            "Epoch: 15 [500/3200 (16%)]\tLoss: 0.68803\tAccuracy: 0.17172\n",
            "Epoch: 15 [550/3200 (17%)]\tLoss: 0.71367\tAccuracy: 0.14612\n",
            "Epoch: 15 [600/3200 (19%)]\tLoss: 0.59255\tAccuracy: 0.20736\n",
            "Epoch: 15 [650/3200 (20%)]\tLoss: 0.73659\tAccuracy: 0.14071\n",
            "Epoch: 15 [700/3200 (22%)]\tLoss: 0.63471\tAccuracy: 0.18490\n",
            "Epoch: 15 [750/3200 (23%)]\tLoss: 0.65068\tAccuracy: 0.18766\n",
            "Epoch: 15 [800/3200 (25%)]\tLoss: 0.32879\tAccuracy: 0.35081\n",
            "Epoch: 15 [850/3200 (27%)]\tLoss: 0.46767\tAccuracy: 0.29205\n",
            "Epoch: 15 [900/3200 (28%)]\tLoss: 0.42971\tAccuracy: 0.29027\n",
            "Epoch: 15 [950/3200 (30%)]\tLoss: 0.35695\tAccuracy: 0.36308\n",
            "Epoch: 15 [1000/3200 (31%)]\tLoss: 0.37561\tAccuracy: 0.32432\n",
            "Epoch: 15 [1050/3200 (33%)]\tLoss: 0.64862\tAccuracy: 0.19035\n",
            "Epoch: 15 [1100/3200 (34%)]\tLoss: 0.64235\tAccuracy: 0.18344\n",
            "Epoch: 15 [1150/3200 (36%)]\tLoss: 0.53879\tAccuracy: 0.25804\n",
            "Epoch: 15 [1200/3200 (38%)]\tLoss: 0.58361\tAccuracy: 0.23513\n",
            "Epoch: 15 [1250/3200 (39%)]\tLoss: 0.74882\tAccuracy: 0.13046\n",
            "Epoch: 15 [1300/3200 (41%)]\tLoss: 0.48517\tAccuracy: 0.27467\n",
            "Epoch: 15 [1350/3200 (42%)]\tLoss: 0.69658\tAccuracy: 0.18208\n",
            "Epoch: 15 [1400/3200 (44%)]\tLoss: 0.46189\tAccuracy: 0.29585\n",
            "Epoch: 15 [1450/3200 (45%)]\tLoss: 0.42843\tAccuracy: 0.30998\n",
            "Epoch: 15 [1500/3200 (47%)]\tLoss: 0.44307\tAccuracy: 0.29650\n",
            "Epoch: 15 [1550/3200 (48%)]\tLoss: 0.58134\tAccuracy: 0.21836\n",
            "Epoch: 15 [1600/3200 (50%)]\tLoss: 0.43088\tAccuracy: 0.32773\n",
            "Epoch: 15 [1650/3200 (52%)]\tLoss: 0.52873\tAccuracy: 0.27062\n",
            "Epoch: 15 [1700/3200 (53%)]\tLoss: 0.51911\tAccuracy: 0.28057\n",
            "Epoch: 15 [1750/3200 (55%)]\tLoss: 0.36357\tAccuracy: 0.35305\n",
            "Epoch: 15 [1800/3200 (56%)]\tLoss: 0.43321\tAccuracy: 0.32481\n",
            "Epoch: 15 [1850/3200 (58%)]\tLoss: 0.46509\tAccuracy: 0.29437\n",
            "Epoch: 15 [1900/3200 (59%)]\tLoss: 0.31183\tAccuracy: 0.40792\n",
            "Epoch: 15 [1950/3200 (61%)]\tLoss: 0.16261\tAccuracy: 0.49626\n",
            "Epoch: 15 [2000/3200 (62%)]\tLoss: 0.38929\tAccuracy: 0.37006\n",
            "Epoch: 15 [2050/3200 (64%)]\tLoss: 0.44806\tAccuracy: 0.33121\n",
            "Epoch: 15 [2100/3200 (66%)]\tLoss: 0.37066\tAccuracy: 0.36892\n",
            "Epoch: 15 [2150/3200 (67%)]\tLoss: 0.18726\tAccuracy: 0.45010\n",
            "Epoch: 15 [2200/3200 (69%)]\tLoss: 0.34378\tAccuracy: 0.39613\n",
            "Epoch: 15 [2250/3200 (70%)]\tLoss: 0.33555\tAccuracy: 0.44428\n",
            "Epoch: 15 [2300/3200 (72%)]\tLoss: 0.17243\tAccuracy: 0.54569\n",
            "Epoch: 15 [2350/3200 (73%)]\tLoss: 0.24856\tAccuracy: 0.48799\n",
            "Epoch: 15 [2400/3200 (75%)]\tLoss: 0.00030\tAccuracy: 0.59680\n",
            "Epoch: 15 [2450/3200 (77%)]\tLoss: 0.13308\tAccuracy: 0.54573\n",
            "Epoch: 15 [2500/3200 (78%)]\tLoss: 0.23947\tAccuracy: 0.47817\n",
            "Epoch: 15 [2550/3200 (80%)]\tLoss: 0.02533\tAccuracy: 0.57251\n",
            "Epoch: 15 [2600/3200 (81%)]\tLoss: 0.07960\tAccuracy: 0.57932\n",
            "Epoch: 15 [2650/3200 (83%)]\tLoss: 0.08859\tAccuracy: 0.55065\n",
            "Epoch: 15 [2700/3200 (84%)]\tLoss: 0.09747\tAccuracy: 0.53887\n",
            "Epoch: 15 [2750/3200 (86%)]\tLoss: -0.04195\tAccuracy: 0.61858\n",
            "Epoch: 15 [2800/3200 (88%)]\tLoss: 0.12567\tAccuracy: 0.53409\n",
            "Epoch: 15 [2850/3200 (89%)]\tLoss: 0.18508\tAccuracy: 0.49402\n",
            "Epoch: 15 [2900/3200 (91%)]\tLoss: -0.07768\tAccuracy: 0.61759\n",
            "Epoch: 15 [2950/3200 (92%)]\tLoss: 0.20820\tAccuracy: 0.48669\n",
            "Epoch: 15 [3000/3200 (94%)]\tLoss: 0.20535\tAccuracy: 0.49428\n",
            "Epoch: 15 [3050/3200 (95%)]\tLoss: 0.01792\tAccuracy: 0.61101\n",
            "Epoch: 15 [3100/3200 (97%)]\tLoss: 0.21830\tAccuracy: 0.52144\n",
            "Epoch: 15 [3150/3200 (98%)]\tLoss: -0.04874\tAccuracy: 0.64752\n",
            "Epoch: 15 [3200/3200 (100%)]\tLoss: 0.08588\tAccuracy: 0.57390\n",
            "Train Loss: 0.39525 Train Accuracy: 0.35207\n",
            "Validation Loss: 0.71899 Validation Accuracy: 0.60143\n",
            "[0.001]\n",
            "Epoch: 16 [50/3200 (2%)]\tLoss: -0.05295\tAccuracy: 0.63110\n",
            "Epoch: 16 [100/3200 (3%)]\tLoss: 0.07904\tAccuracy: 0.56060\n",
            "Epoch: 16 [150/3200 (5%)]\tLoss: 0.23313\tAccuracy: 0.50606\n",
            "Epoch: 16 [200/3200 (6%)]\tLoss: -0.01870\tAccuracy: 0.63865\n",
            "Epoch: 16 [250/3200 (8%)]\tLoss: 0.10074\tAccuracy: 0.57859\n",
            "Epoch: 16 [300/3200 (9%)]\tLoss: 0.14673\tAccuracy: 0.57316\n",
            "Epoch: 16 [350/3200 (11%)]\tLoss: 0.17969\tAccuracy: 0.55804\n",
            "Epoch: 16 [400/3200 (12%)]\tLoss: 0.00841\tAccuracy: 0.63103\n",
            "Epoch: 16 [450/3200 (14%)]\tLoss: 0.31899\tAccuracy: 0.47555\n",
            "Epoch: 16 [500/3200 (16%)]\tLoss: 0.03548\tAccuracy: 0.62396\n",
            "Epoch: 16 [550/3200 (17%)]\tLoss: 0.22274\tAccuracy: 0.53339\n",
            "Epoch: 16 [600/3200 (19%)]\tLoss: 0.05781\tAccuracy: 0.60126\n",
            "Epoch: 16 [650/3200 (20%)]\tLoss: -0.02636\tAccuracy: 0.64189\n",
            "Epoch: 16 [700/3200 (22%)]\tLoss: 0.15326\tAccuracy: 0.60287\n",
            "Epoch: 16 [750/3200 (23%)]\tLoss: 0.03581\tAccuracy: 0.64207\n",
            "Epoch: 16 [800/3200 (25%)]\tLoss: 0.07521\tAccuracy: 0.58391\n",
            "Epoch: 16 [850/3200 (27%)]\tLoss: -0.07917\tAccuracy: 0.60983\n",
            "Epoch: 16 [900/3200 (28%)]\tLoss: 0.01551\tAccuracy: 0.60432\n",
            "Epoch: 16 [950/3200 (30%)]\tLoss: 0.38469\tAccuracy: 0.45493\n",
            "Epoch: 16 [1000/3200 (31%)]\tLoss: -0.09175\tAccuracy: 0.62846\n",
            "Epoch: 16 [1050/3200 (33%)]\tLoss: 0.26927\tAccuracy: 0.48951\n",
            "Epoch: 16 [1100/3200 (34%)]\tLoss: 0.09739\tAccuracy: 0.60198\n",
            "Epoch: 16 [1150/3200 (36%)]\tLoss: 0.15882\tAccuracy: 0.52130\n",
            "Epoch: 16 [1200/3200 (38%)]\tLoss: 0.14265\tAccuracy: 0.51748\n",
            "Epoch: 16 [1250/3200 (39%)]\tLoss: 0.06665\tAccuracy: 0.57381\n",
            "Epoch: 16 [1300/3200 (41%)]\tLoss: 0.00085\tAccuracy: 0.60084\n",
            "Epoch: 16 [1350/3200 (42%)]\tLoss: 0.18415\tAccuracy: 0.48879\n",
            "Epoch: 16 [1400/3200 (44%)]\tLoss: 0.10108\tAccuracy: 0.51981\n",
            "Epoch: 16 [1450/3200 (45%)]\tLoss: 0.07601\tAccuracy: 0.54023\n",
            "Epoch: 16 [1500/3200 (47%)]\tLoss: 0.21097\tAccuracy: 0.46788\n",
            "Epoch: 16 [1550/3200 (48%)]\tLoss: 0.09962\tAccuracy: 0.50956\n",
            "Epoch: 16 [1600/3200 (50%)]\tLoss: 0.23002\tAccuracy: 0.46736\n",
            "Epoch: 16 [1650/3200 (52%)]\tLoss: 0.08197\tAccuracy: 0.52778\n",
            "Epoch: 16 [1700/3200 (53%)]\tLoss: -0.22900\tAccuracy: 0.67150\n",
            "Epoch: 16 [1750/3200 (55%)]\tLoss: -0.19494\tAccuracy: 0.65623\n",
            "Epoch: 16 [1800/3200 (56%)]\tLoss: 0.03569\tAccuracy: 0.54502\n",
            "Epoch: 16 [1850/3200 (58%)]\tLoss: 0.12716\tAccuracy: 0.51312\n",
            "Epoch: 16 [1900/3200 (59%)]\tLoss: 0.24707\tAccuracy: 0.47227\n",
            "Epoch: 16 [1950/3200 (61%)]\tLoss: -0.03125\tAccuracy: 0.57165\n",
            "Epoch: 16 [2000/3200 (62%)]\tLoss: 0.34108\tAccuracy: 0.40809\n",
            "Epoch: 16 [2050/3200 (64%)]\tLoss: 0.02111\tAccuracy: 0.57843\n",
            "Epoch: 16 [2100/3200 (66%)]\tLoss: 0.15300\tAccuracy: 0.53644\n",
            "Epoch: 16 [2150/3200 (67%)]\tLoss: 0.13317\tAccuracy: 0.50666\n",
            "Epoch: 16 [2200/3200 (69%)]\tLoss: 0.10612\tAccuracy: 0.50961\n",
            "Epoch: 16 [2250/3200 (70%)]\tLoss: 0.01166\tAccuracy: 0.60579\n",
            "Epoch: 16 [2300/3200 (72%)]\tLoss: 0.15369\tAccuracy: 0.48418\n",
            "Epoch: 16 [2350/3200 (73%)]\tLoss: 0.38364\tAccuracy: 0.39613\n",
            "Epoch: 16 [2400/3200 (75%)]\tLoss: 0.08156\tAccuracy: 0.55779\n",
            "Epoch: 16 [2450/3200 (77%)]\tLoss: 0.15241\tAccuracy: 0.54006\n",
            "Epoch: 16 [2500/3200 (78%)]\tLoss: 0.01962\tAccuracy: 0.58072\n",
            "Epoch: 16 [2550/3200 (80%)]\tLoss: 0.25697\tAccuracy: 0.43158\n",
            "Epoch: 16 [2600/3200 (81%)]\tLoss: -0.11926\tAccuracy: 0.68000\n",
            "Epoch: 16 [2650/3200 (83%)]\tLoss: 0.18939\tAccuracy: 0.50962\n",
            "Epoch: 16 [2700/3200 (84%)]\tLoss: 0.03525\tAccuracy: 0.57948\n",
            "Epoch: 16 [2750/3200 (86%)]\tLoss: 0.03368\tAccuracy: 0.56576\n",
            "Epoch: 16 [2800/3200 (88%)]\tLoss: -0.09230\tAccuracy: 0.63134\n",
            "Epoch: 16 [2850/3200 (89%)]\tLoss: 0.01659\tAccuracy: 0.56353\n",
            "Epoch: 16 [2900/3200 (91%)]\tLoss: 0.06259\tAccuracy: 0.57551\n",
            "Epoch: 16 [2950/3200 (92%)]\tLoss: 0.05420\tAccuracy: 0.56149\n",
            "Epoch: 16 [3000/3200 (94%)]\tLoss: 0.01505\tAccuracy: 0.62345\n",
            "Epoch: 16 [3050/3200 (95%)]\tLoss: 0.02114\tAccuracy: 0.59789\n",
            "Epoch: 16 [3100/3200 (97%)]\tLoss: 0.22353\tAccuracy: 0.49273\n",
            "Epoch: 16 [3150/3200 (98%)]\tLoss: -0.02419\tAccuracy: 0.66418\n",
            "Epoch: 16 [3200/3200 (100%)]\tLoss: 0.05557\tAccuracy: 0.61329\n",
            "Train Loss: 0.08965 Train Accuracy: 0.55827\n",
            "Validation Loss: 0.72069 Validation Accuracy: 0.60505\n",
            "[0.001]\n",
            "Epoch: 17 [50/3200 (2%)]\tLoss: -0.21156\tAccuracy: 0.71082\n",
            "Epoch: 17 [100/3200 (3%)]\tLoss: 0.29170\tAccuracy: 0.48423\n",
            "Epoch: 17 [150/3200 (5%)]\tLoss: -0.09577\tAccuracy: 0.69572\n",
            "Epoch: 17 [200/3200 (6%)]\tLoss: 0.28534\tAccuracy: 0.49312\n",
            "Epoch: 17 [250/3200 (8%)]\tLoss: -0.02400\tAccuracy: 0.62360\n",
            "Epoch: 17 [300/3200 (9%)]\tLoss: 0.29723\tAccuracy: 0.47911\n",
            "Epoch: 17 [350/3200 (11%)]\tLoss: -0.23782\tAccuracy: 0.69803\n",
            "Epoch: 17 [400/3200 (12%)]\tLoss: -0.12404\tAccuracy: 0.68436\n",
            "Epoch: 17 [450/3200 (14%)]\tLoss: -0.03817\tAccuracy: 0.65236\n",
            "Epoch: 17 [500/3200 (16%)]\tLoss: -0.09571\tAccuracy: 0.67458\n",
            "Epoch: 17 [550/3200 (17%)]\tLoss: -0.05697\tAccuracy: 0.63281\n",
            "Epoch: 17 [600/3200 (19%)]\tLoss: 0.07303\tAccuracy: 0.58571\n",
            "Epoch: 17 [650/3200 (20%)]\tLoss: 0.04644\tAccuracy: 0.60835\n",
            "Epoch: 17 [700/3200 (22%)]\tLoss: 0.13731\tAccuracy: 0.55867\n",
            "Epoch: 17 [750/3200 (23%)]\tLoss: -0.09657\tAccuracy: 0.67553\n",
            "Epoch: 17 [800/3200 (25%)]\tLoss: 0.00264\tAccuracy: 0.65732\n",
            "Epoch: 17 [850/3200 (27%)]\tLoss: 0.06727\tAccuracy: 0.62218\n",
            "Epoch: 17 [900/3200 (28%)]\tLoss: -0.04917\tAccuracy: 0.63580\n",
            "Epoch: 17 [950/3200 (30%)]\tLoss: 0.24899\tAccuracy: 0.51044\n",
            "Epoch: 17 [1000/3200 (31%)]\tLoss: 0.04705\tAccuracy: 0.64924\n",
            "Epoch: 17 [1050/3200 (33%)]\tLoss: 0.15832\tAccuracy: 0.55711\n",
            "Epoch: 17 [1100/3200 (34%)]\tLoss: 0.09141\tAccuracy: 0.56743\n",
            "Epoch: 17 [1150/3200 (36%)]\tLoss: -0.07880\tAccuracy: 0.63851\n",
            "Epoch: 17 [1200/3200 (38%)]\tLoss: -0.00761\tAccuracy: 0.58644\n",
            "Epoch: 17 [1250/3200 (39%)]\tLoss: 0.11534\tAccuracy: 0.56387\n",
            "Epoch: 17 [1300/3200 (41%)]\tLoss: 0.10053\tAccuracy: 0.57522\n",
            "Epoch: 17 [1350/3200 (42%)]\tLoss: -0.09164\tAccuracy: 0.71154\n",
            "Epoch: 17 [1400/3200 (44%)]\tLoss: 0.03325\tAccuracy: 0.60473\n",
            "Epoch: 17 [1450/3200 (45%)]\tLoss: -0.06068\tAccuracy: 0.65965\n",
            "Epoch: 17 [1500/3200 (47%)]\tLoss: 0.08726\tAccuracy: 0.62187\n",
            "Epoch: 17 [1550/3200 (48%)]\tLoss: 0.13134\tAccuracy: 0.54758\n",
            "Epoch: 17 [1600/3200 (50%)]\tLoss: 0.11980\tAccuracy: 0.57559\n",
            "Epoch: 17 [1650/3200 (52%)]\tLoss: 0.08844\tAccuracy: 0.57102\n",
            "Epoch: 17 [1700/3200 (53%)]\tLoss: 0.01608\tAccuracy: 0.65707\n",
            "Epoch: 17 [1750/3200 (55%)]\tLoss: 0.23915\tAccuracy: 0.50013\n",
            "Epoch: 17 [1800/3200 (56%)]\tLoss: 0.00508\tAccuracy: 0.59198\n",
            "Epoch: 17 [1850/3200 (58%)]\tLoss: -0.02388\tAccuracy: 0.64201\n",
            "Epoch: 17 [1900/3200 (59%)]\tLoss: -0.16602\tAccuracy: 0.72587\n",
            "Epoch: 17 [1950/3200 (61%)]\tLoss: -0.12867\tAccuracy: 0.72860\n",
            "Epoch: 17 [2000/3200 (62%)]\tLoss: -0.02161\tAccuracy: 0.64196\n",
            "Epoch: 17 [2050/3200 (64%)]\tLoss: -0.03562\tAccuracy: 0.65545\n",
            "Epoch: 17 [2100/3200 (66%)]\tLoss: 0.04980\tAccuracy: 0.64982\n",
            "Epoch: 17 [2150/3200 (67%)]\tLoss: 0.09983\tAccuracy: 0.61964\n",
            "Epoch: 17 [2200/3200 (69%)]\tLoss: 0.11422\tAccuracy: 0.57998\n",
            "Epoch: 17 [2250/3200 (70%)]\tLoss: -0.10142\tAccuracy: 0.74118\n",
            "Epoch: 17 [2300/3200 (72%)]\tLoss: 0.01085\tAccuracy: 0.64846\n",
            "Epoch: 17 [2350/3200 (73%)]\tLoss: 0.08946\tAccuracy: 0.60497\n",
            "Epoch: 17 [2400/3200 (75%)]\tLoss: -0.11898\tAccuracy: 0.75817\n",
            "Epoch: 17 [2450/3200 (77%)]\tLoss: -0.02758\tAccuracy: 0.64620\n",
            "Epoch: 17 [2500/3200 (78%)]\tLoss: -0.02120\tAccuracy: 0.65998\n",
            "Epoch: 17 [2550/3200 (80%)]\tLoss: 0.05654\tAccuracy: 0.62315\n",
            "Epoch: 17 [2600/3200 (81%)]\tLoss: -0.08265\tAccuracy: 0.68552\n",
            "Epoch: 17 [2650/3200 (83%)]\tLoss: -0.06302\tAccuracy: 0.67374\n",
            "Epoch: 17 [2700/3200 (84%)]\tLoss: 0.15102\tAccuracy: 0.58718\n",
            "Epoch: 17 [2750/3200 (86%)]\tLoss: 0.26013\tAccuracy: 0.51459\n",
            "Epoch: 17 [2800/3200 (88%)]\tLoss: 0.25907\tAccuracy: 0.46235\n",
            "Epoch: 17 [2850/3200 (89%)]\tLoss: 0.12897\tAccuracy: 0.57791\n",
            "Epoch: 17 [2900/3200 (91%)]\tLoss: 0.16331\tAccuracy: 0.55599\n",
            "Epoch: 17 [2950/3200 (92%)]\tLoss: 0.06470\tAccuracy: 0.63389\n",
            "Epoch: 17 [3000/3200 (94%)]\tLoss: 0.04824\tAccuracy: 0.65165\n",
            "Epoch: 17 [3050/3200 (95%)]\tLoss: 0.11230\tAccuracy: 0.58611\n",
            "Epoch: 17 [3100/3200 (97%)]\tLoss: 0.09906\tAccuracy: 0.61972\n",
            "Epoch: 17 [3150/3200 (98%)]\tLoss: 0.24829\tAccuracy: 0.47090\n",
            "Epoch: 17 [3200/3200 (100%)]\tLoss: -0.03505\tAccuracy: 0.67158\n",
            "Train Loss: 0.03976 Train Accuracy: 0.61685\n",
            "Validation Loss: 0.75379 Validation Accuracy: 0.41515\n",
            "[0.001]\n",
            "Epoch: 18 [50/3200 (2%)]\tLoss: 0.01346\tAccuracy: 0.58431\n",
            "Epoch: 18 [100/3200 (3%)]\tLoss: 0.05701\tAccuracy: 0.60210\n",
            "Epoch: 18 [150/3200 (5%)]\tLoss: -0.05962\tAccuracy: 0.63832\n",
            "Epoch: 18 [200/3200 (6%)]\tLoss: 0.07683\tAccuracy: 0.58295\n",
            "Epoch: 18 [250/3200 (8%)]\tLoss: -0.03488\tAccuracy: 0.62989\n",
            "Epoch: 18 [300/3200 (9%)]\tLoss: -0.15759\tAccuracy: 0.67765\n",
            "Epoch: 18 [350/3200 (11%)]\tLoss: 0.08055\tAccuracy: 0.61285\n",
            "Epoch: 18 [400/3200 (12%)]\tLoss: -0.02854\tAccuracy: 0.64820\n",
            "Epoch: 18 [450/3200 (14%)]\tLoss: -0.04963\tAccuracy: 0.64919\n",
            "Epoch: 18 [500/3200 (16%)]\tLoss: 0.19188\tAccuracy: 0.48758\n",
            "Epoch: 18 [550/3200 (17%)]\tLoss: -0.17218\tAccuracy: 0.71134\n",
            "Epoch: 18 [600/3200 (19%)]\tLoss: 0.11842\tAccuracy: 0.57753\n",
            "Epoch: 18 [650/3200 (20%)]\tLoss: -0.06652\tAccuracy: 0.68646\n",
            "Epoch: 18 [700/3200 (22%)]\tLoss: 0.00804\tAccuracy: 0.63043\n",
            "Epoch: 18 [750/3200 (23%)]\tLoss: 0.18347\tAccuracy: 0.51274\n",
            "Epoch: 18 [800/3200 (25%)]\tLoss: 0.06530\tAccuracy: 0.63266\n",
            "Epoch: 18 [850/3200 (27%)]\tLoss: 0.03051\tAccuracy: 0.60834\n",
            "Epoch: 18 [900/3200 (28%)]\tLoss: -0.05790\tAccuracy: 0.65746\n",
            "Epoch: 18 [950/3200 (30%)]\tLoss: 0.13257\tAccuracy: 0.56433\n",
            "Epoch: 18 [1000/3200 (31%)]\tLoss: 0.07088\tAccuracy: 0.60599\n",
            "Epoch: 18 [1050/3200 (33%)]\tLoss: -0.00432\tAccuracy: 0.64399\n",
            "Epoch: 18 [1100/3200 (34%)]\tLoss: -0.04545\tAccuracy: 0.66442\n",
            "Epoch: 18 [1150/3200 (36%)]\tLoss: -0.10379\tAccuracy: 0.68013\n",
            "Epoch: 18 [1200/3200 (38%)]\tLoss: -0.03661\tAccuracy: 0.67674\n",
            "Epoch: 18 [1250/3200 (39%)]\tLoss: 0.08762\tAccuracy: 0.59136\n",
            "Epoch: 18 [1300/3200 (41%)]\tLoss: -0.12454\tAccuracy: 0.70364\n",
            "Epoch: 18 [1350/3200 (42%)]\tLoss: -0.00586\tAccuracy: 0.66574\n",
            "Epoch: 18 [1400/3200 (44%)]\tLoss: 0.05643\tAccuracy: 0.58113\n",
            "Epoch: 18 [1450/3200 (45%)]\tLoss: 0.10981\tAccuracy: 0.58946\n",
            "Epoch: 18 [1500/3200 (47%)]\tLoss: 0.05863\tAccuracy: 0.59120\n",
            "Epoch: 18 [1550/3200 (48%)]\tLoss: 0.16590\tAccuracy: 0.53080\n",
            "Epoch: 18 [1600/3200 (50%)]\tLoss: -0.06133\tAccuracy: 0.63894\n",
            "Epoch: 18 [1650/3200 (52%)]\tLoss: -0.20693\tAccuracy: 0.72676\n",
            "Epoch: 18 [1700/3200 (53%)]\tLoss: -0.02382\tAccuracy: 0.62229\n",
            "Epoch: 18 [1750/3200 (55%)]\tLoss: -0.00830\tAccuracy: 0.64785\n",
            "Epoch: 18 [1800/3200 (56%)]\tLoss: 0.01061\tAccuracy: 0.60938\n",
            "Epoch: 18 [1850/3200 (58%)]\tLoss: 0.00524\tAccuracy: 0.67035\n",
            "Epoch: 18 [1900/3200 (59%)]\tLoss: 0.34435\tAccuracy: 0.47225\n",
            "Epoch: 18 [1950/3200 (61%)]\tLoss: -0.05322\tAccuracy: 0.66933\n",
            "Epoch: 18 [2000/3200 (62%)]\tLoss: 0.21560\tAccuracy: 0.56045\n",
            "Epoch: 18 [2050/3200 (64%)]\tLoss: 0.14316\tAccuracy: 0.57622\n",
            "Epoch: 18 [2100/3200 (66%)]\tLoss: 0.05890\tAccuracy: 0.62092\n",
            "Epoch: 18 [2150/3200 (67%)]\tLoss: -0.07392\tAccuracy: 0.69359\n",
            "Epoch: 18 [2200/3200 (69%)]\tLoss: 0.16210\tAccuracy: 0.59634\n",
            "Epoch: 18 [2250/3200 (70%)]\tLoss: 0.05423\tAccuracy: 0.58514\n",
            "Epoch: 18 [2300/3200 (72%)]\tLoss: -0.06721\tAccuracy: 0.66647\n",
            "Epoch: 18 [2350/3200 (73%)]\tLoss: 0.10636\tAccuracy: 0.61195\n",
            "Epoch: 18 [2400/3200 (75%)]\tLoss: 0.02488\tAccuracy: 0.69018\n",
            "Epoch: 18 [2450/3200 (77%)]\tLoss: 0.07820\tAccuracy: 0.54316\n",
            "Epoch: 18 [2500/3200 (78%)]\tLoss: -0.09260\tAccuracy: 0.69213\n",
            "Epoch: 18 [2550/3200 (80%)]\tLoss: 0.07086\tAccuracy: 0.60894\n",
            "Epoch: 18 [2600/3200 (81%)]\tLoss: 0.01454\tAccuracy: 0.64489\n",
            "Epoch: 18 [2650/3200 (83%)]\tLoss: 0.11776\tAccuracy: 0.57949\n",
            "Epoch: 18 [2700/3200 (84%)]\tLoss: 0.10543\tAccuracy: 0.57396\n",
            "Epoch: 18 [2750/3200 (86%)]\tLoss: -0.02687\tAccuracy: 0.64623\n",
            "Epoch: 18 [2800/3200 (88%)]\tLoss: 0.17574\tAccuracy: 0.54206\n",
            "Epoch: 18 [2850/3200 (89%)]\tLoss: 0.05692\tAccuracy: 0.64073\n",
            "Epoch: 18 [2900/3200 (91%)]\tLoss: -0.09764\tAccuracy: 0.70723\n",
            "Epoch: 18 [2950/3200 (92%)]\tLoss: 0.14100\tAccuracy: 0.55852\n",
            "Epoch: 18 [3000/3200 (94%)]\tLoss: -0.08286\tAccuracy: 0.66275\n",
            "Epoch: 18 [3050/3200 (95%)]\tLoss: 0.07880\tAccuracy: 0.61703\n",
            "Epoch: 18 [3100/3200 (97%)]\tLoss: 0.10232\tAccuracy: 0.59791\n",
            "Epoch: 18 [3150/3200 (98%)]\tLoss: 0.11536\tAccuracy: 0.58344\n",
            "Epoch: 18 [3200/3200 (100%)]\tLoss: -0.11495\tAccuracy: 0.66986\n",
            "Train Loss: 0.02863 Train Accuracy: 0.62103\n",
            "Validation Loss: 0.71426 Validation Accuracy: 0.64358\n",
            "[0.001]\n",
            "Epoch: 19 [50/3200 (2%)]\tLoss: -0.01711\tAccuracy: 0.63136\n",
            "Epoch: 19 [100/3200 (3%)]\tLoss: -0.08742\tAccuracy: 0.70715\n",
            "Epoch: 19 [150/3200 (5%)]\tLoss: 0.22969\tAccuracy: 0.52629\n",
            "Epoch: 19 [200/3200 (6%)]\tLoss: 0.06825\tAccuracy: 0.60753\n",
            "Epoch: 19 [250/3200 (8%)]\tLoss: 0.09820\tAccuracy: 0.60109\n",
            "Epoch: 19 [300/3200 (9%)]\tLoss: 0.12060\tAccuracy: 0.57848\n",
            "Epoch: 19 [350/3200 (11%)]\tLoss: 0.19378\tAccuracy: 0.52528\n",
            "Epoch: 19 [400/3200 (12%)]\tLoss: -0.05066\tAccuracy: 0.63046\n",
            "Epoch: 19 [450/3200 (14%)]\tLoss: 0.12966\tAccuracy: 0.60632\n",
            "Epoch: 19 [500/3200 (16%)]\tLoss: 0.12597\tAccuracy: 0.59193\n",
            "Epoch: 19 [550/3200 (17%)]\tLoss: 0.11515\tAccuracy: 0.57463\n",
            "Epoch: 19 [600/3200 (19%)]\tLoss: 0.18394\tAccuracy: 0.55483\n",
            "Epoch: 19 [650/3200 (20%)]\tLoss: -0.00887\tAccuracy: 0.66879\n",
            "Epoch: 19 [700/3200 (22%)]\tLoss: -0.00762\tAccuracy: 0.62547\n",
            "Epoch: 19 [750/3200 (23%)]\tLoss: -0.04903\tAccuracy: 0.64844\n",
            "Epoch: 19 [800/3200 (25%)]\tLoss: 0.18377\tAccuracy: 0.53441\n",
            "Epoch: 19 [850/3200 (27%)]\tLoss: 0.06737\tAccuracy: 0.58358\n",
            "Epoch: 19 [900/3200 (28%)]\tLoss: 0.09566\tAccuracy: 0.62013\n",
            "Epoch: 19 [950/3200 (30%)]\tLoss: -0.11875\tAccuracy: 0.67794\n",
            "Epoch: 19 [1000/3200 (31%)]\tLoss: 0.01026\tAccuracy: 0.60604\n",
            "Epoch: 19 [1050/3200 (33%)]\tLoss: 0.06252\tAccuracy: 0.58008\n",
            "Epoch: 19 [1100/3200 (34%)]\tLoss: 0.15286\tAccuracy: 0.58618\n",
            "Epoch: 19 [1150/3200 (36%)]\tLoss: -0.05392\tAccuracy: 0.64888\n",
            "Epoch: 19 [1200/3200 (38%)]\tLoss: -0.03250\tAccuracy: 0.63121\n",
            "Epoch: 19 [1250/3200 (39%)]\tLoss: -0.00627\tAccuracy: 0.64082\n",
            "Epoch: 19 [1300/3200 (41%)]\tLoss: -0.01241\tAccuracy: 0.62681\n",
            "Epoch: 19 [1350/3200 (42%)]\tLoss: 0.00314\tAccuracy: 0.59683\n",
            "Epoch: 19 [1400/3200 (44%)]\tLoss: 0.10704\tAccuracy: 0.59249\n",
            "Epoch: 19 [1450/3200 (45%)]\tLoss: -0.05490\tAccuracy: 0.67476\n",
            "Epoch: 19 [1500/3200 (47%)]\tLoss: -0.04639\tAccuracy: 0.64581\n",
            "Epoch: 19 [1550/3200 (48%)]\tLoss: -0.17092\tAccuracy: 0.71075\n",
            "Epoch: 19 [1600/3200 (50%)]\tLoss: -0.05833\tAccuracy: 0.63775\n",
            "Epoch: 19 [1650/3200 (52%)]\tLoss: 0.09190\tAccuracy: 0.58710\n",
            "Epoch: 19 [1700/3200 (53%)]\tLoss: 0.13694\tAccuracy: 0.55211\n",
            "Epoch: 19 [1750/3200 (55%)]\tLoss: -0.20274\tAccuracy: 0.74230\n",
            "Epoch: 19 [1800/3200 (56%)]\tLoss: 0.04665\tAccuracy: 0.63020\n",
            "Epoch: 19 [1850/3200 (58%)]\tLoss: 0.12505\tAccuracy: 0.59265\n",
            "Epoch: 19 [1900/3200 (59%)]\tLoss: -0.03917\tAccuracy: 0.63718\n",
            "Epoch: 19 [1950/3200 (61%)]\tLoss: 0.10495\tAccuracy: 0.57179\n",
            "Epoch: 19 [2000/3200 (62%)]\tLoss: -0.03559\tAccuracy: 0.65478\n",
            "Epoch: 19 [2050/3200 (64%)]\tLoss: 0.11319\tAccuracy: 0.54376\n",
            "Epoch: 19 [2100/3200 (66%)]\tLoss: 0.06405\tAccuracy: 0.62520\n",
            "Epoch: 19 [2150/3200 (67%)]\tLoss: 0.13698\tAccuracy: 0.56049\n",
            "Epoch: 19 [2200/3200 (69%)]\tLoss: 0.02086\tAccuracy: 0.63310\n",
            "Epoch: 19 [2250/3200 (70%)]\tLoss: -0.06531\tAccuracy: 0.68237\n",
            "Epoch: 19 [2300/3200 (72%)]\tLoss: 0.02167\tAccuracy: 0.63653\n",
            "Epoch: 19 [2350/3200 (73%)]\tLoss: 0.05536\tAccuracy: 0.58402\n",
            "Epoch: 19 [2400/3200 (75%)]\tLoss: 0.11304\tAccuracy: 0.57961\n",
            "Epoch: 19 [2450/3200 (77%)]\tLoss: -0.01893\tAccuracy: 0.61610\n",
            "Epoch: 19 [2500/3200 (78%)]\tLoss: -0.12649\tAccuracy: 0.69780\n",
            "Epoch: 19 [2550/3200 (80%)]\tLoss: -0.20320\tAccuracy: 0.70329\n",
            "Epoch: 19 [2600/3200 (81%)]\tLoss: 0.18742\tAccuracy: 0.51126\n",
            "Epoch: 19 [2650/3200 (83%)]\tLoss: 0.00631\tAccuracy: 0.61359\n",
            "Epoch: 19 [2700/3200 (84%)]\tLoss: -0.05075\tAccuracy: 0.64746\n",
            "Epoch: 19 [2750/3200 (86%)]\tLoss: 0.07559\tAccuracy: 0.61257\n",
            "Epoch: 19 [2800/3200 (88%)]\tLoss: -0.02068\tAccuracy: 0.63922\n",
            "Epoch: 19 [2850/3200 (89%)]\tLoss: -0.04165\tAccuracy: 0.63840\n",
            "Epoch: 19 [2900/3200 (91%)]\tLoss: -0.10749\tAccuracy: 0.68686\n",
            "Epoch: 19 [2950/3200 (92%)]\tLoss: 0.14472\tAccuracy: 0.51408\n",
            "Epoch: 19 [3000/3200 (94%)]\tLoss: -0.01723\tAccuracy: 0.63521\n",
            "Epoch: 19 [3050/3200 (95%)]\tLoss: 0.16641\tAccuracy: 0.57205\n",
            "Epoch: 19 [3100/3200 (97%)]\tLoss: 0.08716\tAccuracy: 0.53211\n",
            "Epoch: 19 [3150/3200 (98%)]\tLoss: 0.10039\tAccuracy: 0.57944\n",
            "Epoch: 19 [3200/3200 (100%)]\tLoss: -0.03472\tAccuracy: 0.63440\n",
            "Train Loss: 0.03137 Train Accuracy: 0.61437\n",
            "Validation Loss: 0.71811 Validation Accuracy: 0.62250\n",
            "[0.001]\n",
            "Epoch: 20 [50/3200 (2%)]\tLoss: 0.21996\tAccuracy: 0.52944\n",
            "Epoch: 20 [100/3200 (3%)]\tLoss: 0.15080\tAccuracy: 0.58830\n",
            "Epoch: 20 [150/3200 (5%)]\tLoss: 0.14721\tAccuracy: 0.58837\n",
            "Epoch: 20 [200/3200 (6%)]\tLoss: -0.13161\tAccuracy: 0.66940\n",
            "Epoch: 20 [250/3200 (8%)]\tLoss: 0.09542\tAccuracy: 0.56323\n",
            "Epoch: 20 [300/3200 (9%)]\tLoss: 0.15628\tAccuracy: 0.58266\n",
            "Epoch: 20 [350/3200 (11%)]\tLoss: 0.14296\tAccuracy: 0.57602\n",
            "Epoch: 20 [400/3200 (12%)]\tLoss: -0.10382\tAccuracy: 0.68235\n",
            "Epoch: 20 [450/3200 (14%)]\tLoss: -0.01858\tAccuracy: 0.63823\n",
            "Epoch: 20 [500/3200 (16%)]\tLoss: -0.10258\tAccuracy: 0.70231\n",
            "Epoch: 20 [550/3200 (17%)]\tLoss: 0.08734\tAccuracy: 0.53939\n",
            "Epoch: 20 [600/3200 (19%)]\tLoss: 0.05797\tAccuracy: 0.60168\n",
            "Epoch: 20 [650/3200 (20%)]\tLoss: -0.04055\tAccuracy: 0.65948\n",
            "Epoch: 20 [700/3200 (22%)]\tLoss: -0.11140\tAccuracy: 0.69728\n",
            "Epoch: 20 [750/3200 (23%)]\tLoss: 0.15132\tAccuracy: 0.54853\n",
            "Epoch: 20 [800/3200 (25%)]\tLoss: -0.12342\tAccuracy: 0.67801\n",
            "Epoch: 20 [850/3200 (27%)]\tLoss: 0.07661\tAccuracy: 0.57742\n",
            "Epoch: 20 [900/3200 (28%)]\tLoss: 0.10025\tAccuracy: 0.59940\n",
            "Epoch: 20 [950/3200 (30%)]\tLoss: -0.08735\tAccuracy: 0.70449\n",
            "Epoch: 20 [1000/3200 (31%)]\tLoss: 0.03111\tAccuracy: 0.61866\n",
            "Epoch: 20 [1050/3200 (33%)]\tLoss: 0.02252\tAccuracy: 0.59418\n",
            "Epoch: 20 [1100/3200 (34%)]\tLoss: -0.02855\tAccuracy: 0.60747\n",
            "Epoch: 20 [1150/3200 (36%)]\tLoss: -0.08458\tAccuracy: 0.68385\n",
            "Epoch: 20 [1200/3200 (38%)]\tLoss: -0.03395\tAccuracy: 0.63318\n",
            "Epoch: 20 [1250/3200 (39%)]\tLoss: 0.06231\tAccuracy: 0.59662\n",
            "Epoch: 20 [1300/3200 (41%)]\tLoss: 0.00498\tAccuracy: 0.61485\n",
            "Epoch: 20 [1350/3200 (42%)]\tLoss: 0.09099\tAccuracy: 0.56766\n",
            "Epoch: 20 [1400/3200 (44%)]\tLoss: -0.05769\tAccuracy: 0.67722\n",
            "Epoch: 20 [1450/3200 (45%)]\tLoss: 0.29388\tAccuracy: 0.44250\n",
            "Epoch: 20 [1500/3200 (47%)]\tLoss: 0.03104\tAccuracy: 0.58783\n",
            "Epoch: 20 [1550/3200 (48%)]\tLoss: 0.18720\tAccuracy: 0.53225\n",
            "Epoch: 20 [1600/3200 (50%)]\tLoss: -0.05417\tAccuracy: 0.63385\n",
            "Epoch: 20 [1650/3200 (52%)]\tLoss: 0.03893\tAccuracy: 0.61017\n",
            "Epoch: 20 [1700/3200 (53%)]\tLoss: 0.11882\tAccuracy: 0.57531\n",
            "Epoch: 20 [1750/3200 (55%)]\tLoss: 0.13016\tAccuracy: 0.58552\n",
            "Epoch: 20 [1800/3200 (56%)]\tLoss: 0.00436\tAccuracy: 0.59443\n",
            "Epoch: 20 [1850/3200 (58%)]\tLoss: -0.12521\tAccuracy: 0.70014\n",
            "Epoch: 20 [1900/3200 (59%)]\tLoss: 0.14930\tAccuracy: 0.54812\n",
            "Epoch: 20 [1950/3200 (61%)]\tLoss: -0.03379\tAccuracy: 0.65291\n",
            "Epoch: 20 [2000/3200 (62%)]\tLoss: 0.01948\tAccuracy: 0.59461\n",
            "Epoch: 20 [2050/3200 (64%)]\tLoss: 0.05352\tAccuracy: 0.61601\n",
            "Epoch: 20 [2100/3200 (66%)]\tLoss: -0.05498\tAccuracy: 0.63376\n",
            "Epoch: 20 [2150/3200 (67%)]\tLoss: 0.19321\tAccuracy: 0.50602\n",
            "Epoch: 20 [2200/3200 (69%)]\tLoss: 0.20600\tAccuracy: 0.53364\n",
            "Epoch: 20 [2250/3200 (70%)]\tLoss: -0.15699\tAccuracy: 0.73673\n",
            "Epoch: 20 [2300/3200 (72%)]\tLoss: 0.25179\tAccuracy: 0.52467\n",
            "Epoch: 20 [2350/3200 (73%)]\tLoss: 0.35532\tAccuracy: 0.46436\n",
            "Epoch: 20 [2400/3200 (75%)]\tLoss: 0.20221\tAccuracy: 0.53680\n",
            "Epoch: 20 [2450/3200 (77%)]\tLoss: -0.15616\tAccuracy: 0.73513\n",
            "Epoch: 20 [2500/3200 (78%)]\tLoss: -0.09531\tAccuracy: 0.69175\n",
            "Epoch: 20 [2550/3200 (80%)]\tLoss: 0.19593\tAccuracy: 0.56292\n",
            "Epoch: 20 [2600/3200 (81%)]\tLoss: -0.02901\tAccuracy: 0.64562\n",
            "Epoch: 20 [2650/3200 (83%)]\tLoss: -0.04367\tAccuracy: 0.62156\n",
            "Epoch: 20 [2700/3200 (84%)]\tLoss: -0.01968\tAccuracy: 0.57951\n",
            "Epoch: 20 [2750/3200 (86%)]\tLoss: -0.02622\tAccuracy: 0.66584\n",
            "Epoch: 20 [2800/3200 (88%)]\tLoss: 0.00641\tAccuracy: 0.65322\n",
            "Epoch: 20 [2850/3200 (89%)]\tLoss: -0.08485\tAccuracy: 0.66434\n",
            "Epoch: 20 [2900/3200 (91%)]\tLoss: 0.08325\tAccuracy: 0.56758\n",
            "Epoch: 20 [2950/3200 (92%)]\tLoss: 0.19444\tAccuracy: 0.51999\n",
            "Epoch: 20 [3000/3200 (94%)]\tLoss: -0.02849\tAccuracy: 0.64573\n",
            "Epoch: 20 [3050/3200 (95%)]\tLoss: -0.13999\tAccuracy: 0.69934\n",
            "Epoch: 20 [3100/3200 (97%)]\tLoss: 0.19147\tAccuracy: 0.56700\n",
            "Epoch: 20 [3150/3200 (98%)]\tLoss: 0.09923\tAccuracy: 0.62001\n",
            "Epoch: 20 [3200/3200 (100%)]\tLoss: -0.11983\tAccuracy: 0.67960\n",
            "Train Loss: 0.03924 Train Accuracy: 0.61013\n",
            "Validation Loss: 0.71729 Validation Accuracy: 0.63364\n",
            "[0.0001]\n",
            "Epoch: 21 [50/3200 (2%)]\tLoss: 0.16831\tAccuracy: 0.53004\n",
            "Epoch: 21 [100/3200 (3%)]\tLoss: 0.04889\tAccuracy: 0.65080\n",
            "Epoch: 21 [150/3200 (5%)]\tLoss: 0.04098\tAccuracy: 0.60866\n",
            "Epoch: 21 [200/3200 (6%)]\tLoss: -0.00435\tAccuracy: 0.61901\n",
            "Epoch: 21 [250/3200 (8%)]\tLoss: 0.19566\tAccuracy: 0.55704\n",
            "Epoch: 21 [300/3200 (9%)]\tLoss: 0.11117\tAccuracy: 0.56715\n",
            "Epoch: 21 [350/3200 (11%)]\tLoss: -0.00875\tAccuracy: 0.60723\n",
            "Epoch: 21 [400/3200 (12%)]\tLoss: 0.06259\tAccuracy: 0.65651\n",
            "Epoch: 21 [450/3200 (14%)]\tLoss: 0.09597\tAccuracy: 0.58202\n",
            "Epoch: 21 [500/3200 (16%)]\tLoss: -0.08461\tAccuracy: 0.66452\n",
            "Epoch: 21 [550/3200 (17%)]\tLoss: 0.07257\tAccuracy: 0.58270\n",
            "Epoch: 21 [600/3200 (19%)]\tLoss: 0.19123\tAccuracy: 0.54553\n",
            "Epoch: 21 [650/3200 (20%)]\tLoss: 0.05454\tAccuracy: 0.58447\n",
            "Epoch: 21 [700/3200 (22%)]\tLoss: -0.08174\tAccuracy: 0.66022\n",
            "Epoch: 21 [750/3200 (23%)]\tLoss: 0.19167\tAccuracy: 0.52803\n",
            "Epoch: 21 [800/3200 (25%)]\tLoss: 0.17534\tAccuracy: 0.54418\n",
            "Epoch: 21 [850/3200 (27%)]\tLoss: -0.28607\tAccuracy: 0.76600\n",
            "Epoch: 21 [900/3200 (28%)]\tLoss: 0.00658\tAccuracy: 0.62822\n",
            "Epoch: 21 [950/3200 (30%)]\tLoss: 0.11197\tAccuracy: 0.54612\n",
            "Epoch: 21 [1000/3200 (31%)]\tLoss: 0.03612\tAccuracy: 0.62112\n",
            "Epoch: 21 [1050/3200 (33%)]\tLoss: 0.13591\tAccuracy: 0.54939\n",
            "Epoch: 21 [1100/3200 (34%)]\tLoss: -0.09795\tAccuracy: 0.63622\n",
            "Epoch: 21 [1150/3200 (36%)]\tLoss: -0.00689\tAccuracy: 0.64585\n",
            "Epoch: 21 [1200/3200 (38%)]\tLoss: -0.00071\tAccuracy: 0.63785\n",
            "Epoch: 21 [1250/3200 (39%)]\tLoss: 0.07232\tAccuracy: 0.58737\n",
            "Epoch: 21 [1300/3200 (41%)]\tLoss: -0.22778\tAccuracy: 0.74770\n",
            "Epoch: 21 [1350/3200 (42%)]\tLoss: -0.18969\tAccuracy: 0.72467\n",
            "Epoch: 21 [1400/3200 (44%)]\tLoss: 0.14919\tAccuracy: 0.54817\n",
            "Epoch: 21 [1450/3200 (45%)]\tLoss: -0.15426\tAccuracy: 0.68728\n",
            "Epoch: 21 [1500/3200 (47%)]\tLoss: 0.03167\tAccuracy: 0.64781\n",
            "Epoch: 21 [1550/3200 (48%)]\tLoss: 0.04977\tAccuracy: 0.62758\n",
            "Epoch: 21 [1600/3200 (50%)]\tLoss: -0.21991\tAccuracy: 0.76015\n",
            "Epoch: 21 [1650/3200 (52%)]\tLoss: 0.08342\tAccuracy: 0.53571\n",
            "Epoch: 21 [1700/3200 (53%)]\tLoss: 0.01980\tAccuracy: 0.65778\n",
            "Epoch: 21 [1750/3200 (55%)]\tLoss: 0.15802\tAccuracy: 0.58178\n",
            "Epoch: 21 [1800/3200 (56%)]\tLoss: 0.16215\tAccuracy: 0.57719\n",
            "Epoch: 21 [1850/3200 (58%)]\tLoss: -0.03783\tAccuracy: 0.71734\n",
            "Epoch: 21 [1900/3200 (59%)]\tLoss: 0.12906\tAccuracy: 0.59047\n",
            "Epoch: 21 [1950/3200 (61%)]\tLoss: -0.14222\tAccuracy: 0.68244\n",
            "Epoch: 21 [2000/3200 (62%)]\tLoss: -0.10323\tAccuracy: 0.71328\n",
            "Epoch: 21 [2050/3200 (64%)]\tLoss: -0.12470\tAccuracy: 0.70184\n",
            "Epoch: 21 [2100/3200 (66%)]\tLoss: 0.15505\tAccuracy: 0.58187\n",
            "Epoch: 21 [2150/3200 (67%)]\tLoss: -0.05825\tAccuracy: 0.67786\n",
            "Epoch: 21 [2200/3200 (69%)]\tLoss: 0.08621\tAccuracy: 0.58132\n",
            "Epoch: 21 [2250/3200 (70%)]\tLoss: 0.14409\tAccuracy: 0.59576\n",
            "Epoch: 21 [2300/3200 (72%)]\tLoss: 0.09598\tAccuracy: 0.60143\n",
            "Epoch: 21 [2350/3200 (73%)]\tLoss: 0.01343\tAccuracy: 0.66646\n",
            "Epoch: 21 [2400/3200 (75%)]\tLoss: 0.07671\tAccuracy: 0.64255\n",
            "Epoch: 21 [2450/3200 (77%)]\tLoss: -0.23902\tAccuracy: 0.75278\n",
            "Epoch: 21 [2500/3200 (78%)]\tLoss: 0.00989\tAccuracy: 0.59786\n",
            "Epoch: 21 [2550/3200 (80%)]\tLoss: 0.00450\tAccuracy: 0.63478\n",
            "Epoch: 21 [2600/3200 (81%)]\tLoss: -0.08147\tAccuracy: 0.67294\n",
            "Epoch: 21 [2650/3200 (83%)]\tLoss: -0.05547\tAccuracy: 0.67165\n",
            "Epoch: 21 [2700/3200 (84%)]\tLoss: -0.19526\tAccuracy: 0.67573\n",
            "Epoch: 21 [2750/3200 (86%)]\tLoss: -0.03038\tAccuracy: 0.66984\n",
            "Epoch: 21 [2800/3200 (88%)]\tLoss: -0.15340\tAccuracy: 0.73072\n",
            "Epoch: 21 [2850/3200 (89%)]\tLoss: 0.07242\tAccuracy: 0.56751\n",
            "Epoch: 21 [2900/3200 (91%)]\tLoss: 0.17673\tAccuracy: 0.52037\n",
            "Epoch: 21 [2950/3200 (92%)]\tLoss: 0.10180\tAccuracy: 0.57512\n",
            "Epoch: 21 [3000/3200 (94%)]\tLoss: 0.03762\tAccuracy: 0.58178\n",
            "Epoch: 21 [3050/3200 (95%)]\tLoss: -0.00249\tAccuracy: 0.64185\n",
            "Epoch: 21 [3100/3200 (97%)]\tLoss: -0.02371\tAccuracy: 0.66363\n",
            "Epoch: 21 [3150/3200 (98%)]\tLoss: -0.09433\tAccuracy: 0.69384\n",
            "Epoch: 21 [3200/3200 (100%)]\tLoss: 0.14895\tAccuracy: 0.61083\n",
            "Train Loss: 0.01522 Train Accuracy: 0.62837\n",
            "Validation Loss: 0.71537 Validation Accuracy: 0.64505\n",
            "[0.0001]\n",
            "Epoch: 22 [50/3200 (2%)]\tLoss: 0.36288\tAccuracy: 0.47493\n",
            "Epoch: 22 [100/3200 (3%)]\tLoss: -0.11635\tAccuracy: 0.69531\n",
            "Epoch: 22 [150/3200 (5%)]\tLoss: -0.02912\tAccuracy: 0.64800\n",
            "Epoch: 22 [200/3200 (6%)]\tLoss: 0.06501\tAccuracy: 0.59311\n",
            "Epoch: 22 [250/3200 (8%)]\tLoss: 0.04555\tAccuracy: 0.59408\n",
            "Epoch: 22 [300/3200 (9%)]\tLoss: 0.08294\tAccuracy: 0.57385\n",
            "Epoch: 22 [350/3200 (11%)]\tLoss: 0.05899\tAccuracy: 0.53927\n",
            "Epoch: 22 [400/3200 (12%)]\tLoss: 0.13010\tAccuracy: 0.56657\n",
            "Epoch: 22 [450/3200 (14%)]\tLoss: 0.00613\tAccuracy: 0.71411\n",
            "Epoch: 22 [500/3200 (16%)]\tLoss: 0.01834\tAccuracy: 0.64810\n",
            "Epoch: 22 [550/3200 (17%)]\tLoss: 0.01488\tAccuracy: 0.62504\n",
            "Epoch: 22 [600/3200 (19%)]\tLoss: -0.11121\tAccuracy: 0.71084\n",
            "Epoch: 22 [650/3200 (20%)]\tLoss: 0.03226\tAccuracy: 0.64245\n",
            "Epoch: 22 [700/3200 (22%)]\tLoss: -0.11079\tAccuracy: 0.66874\n",
            "Epoch: 22 [750/3200 (23%)]\tLoss: -0.05856\tAccuracy: 0.70850\n",
            "Epoch: 22 [800/3200 (25%)]\tLoss: 0.07923\tAccuracy: 0.59914\n",
            "Epoch: 22 [850/3200 (27%)]\tLoss: 0.07285\tAccuracy: 0.62685\n",
            "Epoch: 22 [900/3200 (28%)]\tLoss: 0.06131\tAccuracy: 0.61801\n",
            "Epoch: 22 [950/3200 (30%)]\tLoss: 0.10519\tAccuracy: 0.59039\n",
            "Epoch: 22 [1000/3200 (31%)]\tLoss: 0.20162\tAccuracy: 0.51757\n",
            "Epoch: 22 [1050/3200 (33%)]\tLoss: 0.06676\tAccuracy: 0.59241\n",
            "Epoch: 22 [1100/3200 (34%)]\tLoss: -0.01430\tAccuracy: 0.65377\n",
            "Epoch: 22 [1150/3200 (36%)]\tLoss: -0.11931\tAccuracy: 0.69778\n",
            "Epoch: 22 [1200/3200 (38%)]\tLoss: 0.11004\tAccuracy: 0.56906\n",
            "Epoch: 22 [1250/3200 (39%)]\tLoss: -0.05036\tAccuracy: 0.68959\n",
            "Epoch: 22 [1300/3200 (41%)]\tLoss: -0.05705\tAccuracy: 0.71261\n",
            "Epoch: 22 [1350/3200 (42%)]\tLoss: -0.17099\tAccuracy: 0.71118\n",
            "Epoch: 22 [1400/3200 (44%)]\tLoss: 0.20439\tAccuracy: 0.51327\n",
            "Epoch: 22 [1450/3200 (45%)]\tLoss: 0.01219\tAccuracy: 0.64712\n",
            "Epoch: 22 [1500/3200 (47%)]\tLoss: 0.03413\tAccuracy: 0.62883\n",
            "Epoch: 22 [1550/3200 (48%)]\tLoss: -0.00066\tAccuracy: 0.60037\n",
            "Epoch: 22 [1600/3200 (50%)]\tLoss: 0.02491\tAccuracy: 0.57285\n",
            "Epoch: 22 [1650/3200 (52%)]\tLoss: 0.07671\tAccuracy: 0.60244\n",
            "Epoch: 22 [1700/3200 (53%)]\tLoss: 0.17352\tAccuracy: 0.54355\n",
            "Epoch: 22 [1750/3200 (55%)]\tLoss: -0.27395\tAccuracy: 0.77397\n",
            "Epoch: 22 [1800/3200 (56%)]\tLoss: 0.10484\tAccuracy: 0.59436\n",
            "Epoch: 22 [1850/3200 (58%)]\tLoss: -0.14440\tAccuracy: 0.73440\n",
            "Epoch: 22 [1900/3200 (59%)]\tLoss: -0.27749\tAccuracy: 0.77729\n",
            "Epoch: 22 [1950/3200 (61%)]\tLoss: -0.04770\tAccuracy: 0.64288\n",
            "Epoch: 22 [2000/3200 (62%)]\tLoss: 0.03344\tAccuracy: 0.58513\n",
            "Epoch: 22 [2050/3200 (64%)]\tLoss: 0.11633\tAccuracy: 0.62221\n",
            "Epoch: 22 [2100/3200 (66%)]\tLoss: 0.06501\tAccuracy: 0.59085\n",
            "Epoch: 22 [2150/3200 (67%)]\tLoss: 0.01627\tAccuracy: 0.64160\n",
            "Epoch: 22 [2200/3200 (69%)]\tLoss: -0.05304\tAccuracy: 0.70872\n",
            "Epoch: 22 [2250/3200 (70%)]\tLoss: 0.01756\tAccuracy: 0.62078\n",
            "Epoch: 22 [2300/3200 (72%)]\tLoss: 0.13717\tAccuracy: 0.58233\n",
            "Epoch: 22 [2350/3200 (73%)]\tLoss: 0.17470\tAccuracy: 0.56346\n",
            "Epoch: 22 [2400/3200 (75%)]\tLoss: 0.03017\tAccuracy: 0.60945\n",
            "Epoch: 22 [2450/3200 (77%)]\tLoss: 0.10796\tAccuracy: 0.59185\n",
            "Epoch: 22 [2500/3200 (78%)]\tLoss: 0.25517\tAccuracy: 0.51277\n",
            "Epoch: 22 [2550/3200 (80%)]\tLoss: 0.07243\tAccuracy: 0.54394\n",
            "Epoch: 22 [2600/3200 (81%)]\tLoss: 0.07670\tAccuracy: 0.60222\n",
            "Epoch: 22 [2650/3200 (83%)]\tLoss: -0.05265\tAccuracy: 0.65168\n",
            "Epoch: 22 [2700/3200 (84%)]\tLoss: 0.07358\tAccuracy: 0.61886\n",
            "Epoch: 22 [2750/3200 (86%)]\tLoss: -0.01028\tAccuracy: 0.64994\n",
            "Epoch: 22 [2800/3200 (88%)]\tLoss: -0.02067\tAccuracy: 0.66055\n",
            "Epoch: 22 [2850/3200 (89%)]\tLoss: -0.23851\tAccuracy: 0.73634\n",
            "Epoch: 22 [2900/3200 (91%)]\tLoss: -0.08992\tAccuracy: 0.68515\n",
            "Epoch: 22 [2950/3200 (92%)]\tLoss: 0.16913\tAccuracy: 0.50810\n",
            "Epoch: 22 [3000/3200 (94%)]\tLoss: -0.15877\tAccuracy: 0.71698\n",
            "Epoch: 22 [3050/3200 (95%)]\tLoss: -0.04108\tAccuracy: 0.64106\n",
            "Epoch: 22 [3100/3200 (97%)]\tLoss: -0.11351\tAccuracy: 0.67329\n",
            "Epoch: 22 [3150/3200 (98%)]\tLoss: 0.12531\tAccuracy: 0.58369\n",
            "Epoch: 22 [3200/3200 (100%)]\tLoss: -0.05801\tAccuracy: 0.67673\n",
            "Train Loss: 0.01870 Train Accuracy: 0.62797\n",
            "Validation Loss: 0.71395 Validation Accuracy: 0.64975\n",
            "[0.0001]\n",
            "Epoch: 23 [50/3200 (2%)]\tLoss: 0.09417\tAccuracy: 0.60289\n",
            "Epoch: 23 [100/3200 (3%)]\tLoss: 0.15409\tAccuracy: 0.54577\n",
            "Epoch: 23 [150/3200 (5%)]\tLoss: -0.03360\tAccuracy: 0.65173\n",
            "Epoch: 23 [200/3200 (6%)]\tLoss: -0.16613\tAccuracy: 0.74553\n",
            "Epoch: 23 [250/3200 (8%)]\tLoss: -0.05370\tAccuracy: 0.70813\n",
            "Epoch: 23 [300/3200 (9%)]\tLoss: 0.25159\tAccuracy: 0.52302\n",
            "Epoch: 23 [350/3200 (11%)]\tLoss: -0.17089\tAccuracy: 0.73110\n",
            "Epoch: 23 [400/3200 (12%)]\tLoss: -0.17487\tAccuracy: 0.73371\n",
            "Epoch: 23 [450/3200 (14%)]\tLoss: 0.23986\tAccuracy: 0.51854\n",
            "Epoch: 23 [500/3200 (16%)]\tLoss: 0.09399\tAccuracy: 0.58377\n",
            "Epoch: 23 [550/3200 (17%)]\tLoss: 0.07214\tAccuracy: 0.62785\n",
            "Epoch: 23 [600/3200 (19%)]\tLoss: 0.04279\tAccuracy: 0.63198\n",
            "Epoch: 23 [650/3200 (20%)]\tLoss: 0.17852\tAccuracy: 0.57467\n",
            "Epoch: 23 [700/3200 (22%)]\tLoss: -0.16583\tAccuracy: 0.68474\n",
            "Epoch: 23 [750/3200 (23%)]\tLoss: 0.07108\tAccuracy: 0.60615\n",
            "Epoch: 23 [800/3200 (25%)]\tLoss: 0.09799\tAccuracy: 0.62097\n",
            "Epoch: 23 [850/3200 (27%)]\tLoss: -0.01911\tAccuracy: 0.61912\n",
            "Epoch: 23 [900/3200 (28%)]\tLoss: 0.06205\tAccuracy: 0.57110\n",
            "Epoch: 23 [950/3200 (30%)]\tLoss: 0.10718\tAccuracy: 0.59218\n",
            "Epoch: 23 [1000/3200 (31%)]\tLoss: 0.00804\tAccuracy: 0.67154\n",
            "Epoch: 23 [1050/3200 (33%)]\tLoss: -0.03785\tAccuracy: 0.65772\n",
            "Epoch: 23 [1100/3200 (34%)]\tLoss: -0.12947\tAccuracy: 0.73761\n",
            "Epoch: 23 [1150/3200 (36%)]\tLoss: 0.05409\tAccuracy: 0.58107\n",
            "Epoch: 23 [1200/3200 (38%)]\tLoss: 0.01831\tAccuracy: 0.64097\n",
            "Epoch: 23 [1250/3200 (39%)]\tLoss: 0.05457\tAccuracy: 0.60429\n",
            "Epoch: 23 [1300/3200 (41%)]\tLoss: 0.03418\tAccuracy: 0.60514\n",
            "Epoch: 23 [1350/3200 (42%)]\tLoss: -0.13149\tAccuracy: 0.67653\n",
            "Epoch: 23 [1400/3200 (44%)]\tLoss: -0.13239\tAccuracy: 0.66107\n",
            "Epoch: 23 [1450/3200 (45%)]\tLoss: -0.00635\tAccuracy: 0.66337\n",
            "Epoch: 23 [1500/3200 (47%)]\tLoss: 0.22954\tAccuracy: 0.50705\n",
            "Epoch: 23 [1550/3200 (48%)]\tLoss: 0.11635\tAccuracy: 0.56356\n",
            "Epoch: 23 [1600/3200 (50%)]\tLoss: -0.06660\tAccuracy: 0.64567\n",
            "Epoch: 23 [1650/3200 (52%)]\tLoss: -0.29225\tAccuracy: 0.79250\n",
            "Epoch: 23 [1700/3200 (53%)]\tLoss: -0.05277\tAccuracy: 0.64982\n",
            "Epoch: 23 [1750/3200 (55%)]\tLoss: 0.13451\tAccuracy: 0.56534\n",
            "Epoch: 23 [1800/3200 (56%)]\tLoss: 0.03426\tAccuracy: 0.62542\n",
            "Epoch: 23 [1850/3200 (58%)]\tLoss: -0.17129\tAccuracy: 0.69104\n",
            "Epoch: 23 [1900/3200 (59%)]\tLoss: 0.02428\tAccuracy: 0.67585\n",
            "Epoch: 23 [1950/3200 (61%)]\tLoss: -0.10059\tAccuracy: 0.67946\n",
            "Epoch: 23 [2000/3200 (62%)]\tLoss: -0.07311\tAccuracy: 0.67117\n",
            "Epoch: 23 [2050/3200 (64%)]\tLoss: 0.00707\tAccuracy: 0.61277\n",
            "Epoch: 23 [2100/3200 (66%)]\tLoss: 0.09448\tAccuracy: 0.58231\n",
            "Epoch: 23 [2150/3200 (67%)]\tLoss: -0.09762\tAccuracy: 0.73720\n",
            "Epoch: 23 [2200/3200 (69%)]\tLoss: -0.09255\tAccuracy: 0.68194\n",
            "Epoch: 23 [2250/3200 (70%)]\tLoss: -0.14974\tAccuracy: 0.66778\n",
            "Epoch: 23 [2300/3200 (72%)]\tLoss: 0.16338\tAccuracy: 0.53627\n",
            "Epoch: 23 [2350/3200 (73%)]\tLoss: 0.06454\tAccuracy: 0.63386\n",
            "Epoch: 23 [2400/3200 (75%)]\tLoss: -0.05376\tAccuracy: 0.66349\n",
            "Epoch: 23 [2450/3200 (77%)]\tLoss: -0.09888\tAccuracy: 0.71904\n",
            "Epoch: 23 [2500/3200 (78%)]\tLoss: -0.00280\tAccuracy: 0.58266\n",
            "Epoch: 23 [2550/3200 (80%)]\tLoss: 0.17669\tAccuracy: 0.52286\n",
            "Epoch: 23 [2600/3200 (81%)]\tLoss: 0.23976\tAccuracy: 0.55294\n",
            "Epoch: 23 [2650/3200 (83%)]\tLoss: -0.14146\tAccuracy: 0.73431\n",
            "Epoch: 23 [2700/3200 (84%)]\tLoss: 0.04304\tAccuracy: 0.59204\n",
            "Epoch: 23 [2750/3200 (86%)]\tLoss: 0.25720\tAccuracy: 0.54242\n",
            "Epoch: 23 [2800/3200 (88%)]\tLoss: 0.08719\tAccuracy: 0.55097\n",
            "Epoch: 23 [2850/3200 (89%)]\tLoss: -0.00310\tAccuracy: 0.62139\n",
            "Epoch: 23 [2900/3200 (91%)]\tLoss: 0.04079\tAccuracy: 0.63858\n",
            "Epoch: 23 [2950/3200 (92%)]\tLoss: 0.18900\tAccuracy: 0.55974\n",
            "Epoch: 23 [3000/3200 (94%)]\tLoss: 0.18965\tAccuracy: 0.55002\n",
            "Epoch: 23 [3050/3200 (95%)]\tLoss: -0.05456\tAccuracy: 0.65219\n",
            "Epoch: 23 [3100/3200 (97%)]\tLoss: 0.12400\tAccuracy: 0.57479\n",
            "Epoch: 23 [3150/3200 (98%)]\tLoss: -0.14524\tAccuracy: 0.66446\n",
            "Epoch: 23 [3200/3200 (100%)]\tLoss: 0.14541\tAccuracy: 0.61386\n",
            "Train Loss: 0.01840 Train Accuracy: 0.62855\n",
            "Validation Loss: 0.71465 Validation Accuracy: 0.65042\n",
            "[0.0001]\n",
            "Epoch: 24 [50/3200 (2%)]\tLoss: 0.27869\tAccuracy: 0.51803\n",
            "Epoch: 24 [100/3200 (3%)]\tLoss: 0.07628\tAccuracy: 0.56317\n",
            "Epoch: 24 [150/3200 (5%)]\tLoss: -0.11813\tAccuracy: 0.67552\n",
            "Epoch: 24 [200/3200 (6%)]\tLoss: -0.06905\tAccuracy: 0.64822\n",
            "Epoch: 24 [250/3200 (8%)]\tLoss: 0.00607\tAccuracy: 0.67386\n",
            "Epoch: 24 [300/3200 (9%)]\tLoss: -0.01461\tAccuracy: 0.65343\n",
            "Epoch: 24 [350/3200 (11%)]\tLoss: 0.02662\tAccuracy: 0.65297\n",
            "Epoch: 24 [400/3200 (12%)]\tLoss: 0.02531\tAccuracy: 0.63423\n",
            "Epoch: 24 [450/3200 (14%)]\tLoss: 0.14279\tAccuracy: 0.57638\n",
            "Epoch: 24 [500/3200 (16%)]\tLoss: -0.09341\tAccuracy: 0.69333\n",
            "Epoch: 24 [550/3200 (17%)]\tLoss: -0.07237\tAccuracy: 0.65241\n",
            "Epoch: 24 [600/3200 (19%)]\tLoss: 0.14443\tAccuracy: 0.54992\n",
            "Epoch: 24 [650/3200 (20%)]\tLoss: 0.10305\tAccuracy: 0.62315\n",
            "Epoch: 24 [700/3200 (22%)]\tLoss: -0.04594\tAccuracy: 0.66125\n",
            "Epoch: 24 [750/3200 (23%)]\tLoss: -0.00822\tAccuracy: 0.66309\n",
            "Epoch: 24 [800/3200 (25%)]\tLoss: -0.03962\tAccuracy: 0.63922\n",
            "Epoch: 24 [850/3200 (27%)]\tLoss: 0.02363\tAccuracy: 0.61590\n",
            "Epoch: 24 [900/3200 (28%)]\tLoss: -0.09391\tAccuracy: 0.67165\n",
            "Epoch: 24 [950/3200 (30%)]\tLoss: 0.05647\tAccuracy: 0.64202\n",
            "Epoch: 24 [1000/3200 (31%)]\tLoss: 0.14434\tAccuracy: 0.58397\n",
            "Epoch: 24 [1050/3200 (33%)]\tLoss: -0.04663\tAccuracy: 0.68444\n",
            "Epoch: 24 [1100/3200 (34%)]\tLoss: -0.09261\tAccuracy: 0.69243\n",
            "Epoch: 24 [1150/3200 (36%)]\tLoss: -0.07437\tAccuracy: 0.67295\n",
            "Epoch: 24 [1200/3200 (38%)]\tLoss: 0.00472\tAccuracy: 0.65403\n",
            "Epoch: 24 [1250/3200 (39%)]\tLoss: 0.08011\tAccuracy: 0.57717\n",
            "Epoch: 24 [1300/3200 (41%)]\tLoss: -0.08514\tAccuracy: 0.68318\n",
            "Epoch: 24 [1350/3200 (42%)]\tLoss: -0.16049\tAccuracy: 0.74015\n",
            "Epoch: 24 [1400/3200 (44%)]\tLoss: 0.09139\tAccuracy: 0.63664\n",
            "Epoch: 24 [1450/3200 (45%)]\tLoss: -0.00133\tAccuracy: 0.66021\n",
            "Epoch: 24 [1500/3200 (47%)]\tLoss: 0.09312\tAccuracy: 0.61309\n",
            "Epoch: 24 [1550/3200 (48%)]\tLoss: 0.00905\tAccuracy: 0.67038\n",
            "Epoch: 24 [1600/3200 (50%)]\tLoss: 0.06802\tAccuracy: 0.61177\n",
            "Epoch: 24 [1650/3200 (52%)]\tLoss: 0.02106\tAccuracy: 0.63826\n",
            "Epoch: 24 [1700/3200 (53%)]\tLoss: 0.19506\tAccuracy: 0.52197\n",
            "Epoch: 24 [1750/3200 (55%)]\tLoss: -0.04072\tAccuracy: 0.67714\n",
            "Epoch: 24 [1800/3200 (56%)]\tLoss: -0.05460\tAccuracy: 0.69365\n",
            "Epoch: 24 [1850/3200 (58%)]\tLoss: -0.20967\tAccuracy: 0.69020\n",
            "Epoch: 24 [1900/3200 (59%)]\tLoss: 0.04109\tAccuracy: 0.59821\n",
            "Epoch: 24 [1950/3200 (61%)]\tLoss: -0.13293\tAccuracy: 0.69240\n",
            "Epoch: 24 [2000/3200 (62%)]\tLoss: 0.07649\tAccuracy: 0.56180\n",
            "Epoch: 24 [2050/3200 (64%)]\tLoss: 0.17024\tAccuracy: 0.46892\n",
            "Epoch: 24 [2100/3200 (66%)]\tLoss: -0.15010\tAccuracy: 0.71846\n",
            "Epoch: 24 [2150/3200 (67%)]\tLoss: -0.13635\tAccuracy: 0.70872\n",
            "Epoch: 24 [2200/3200 (69%)]\tLoss: 0.08070\tAccuracy: 0.57819\n",
            "Epoch: 24 [2250/3200 (70%)]\tLoss: 0.26731\tAccuracy: 0.47188\n",
            "Epoch: 24 [2300/3200 (72%)]\tLoss: 0.03181\tAccuracy: 0.62810\n",
            "Epoch: 24 [2350/3200 (73%)]\tLoss: 0.03645\tAccuracy: 0.62268\n",
            "Epoch: 24 [2400/3200 (75%)]\tLoss: 0.07995\tAccuracy: 0.57856\n",
            "Epoch: 24 [2450/3200 (77%)]\tLoss: 0.14524\tAccuracy: 0.51872\n",
            "Epoch: 24 [2500/3200 (78%)]\tLoss: -0.07044\tAccuracy: 0.69039\n",
            "Epoch: 24 [2550/3200 (80%)]\tLoss: 0.03946\tAccuracy: 0.65803\n",
            "Epoch: 24 [2600/3200 (81%)]\tLoss: -0.00494\tAccuracy: 0.62446\n",
            "Epoch: 24 [2650/3200 (83%)]\tLoss: -0.05201\tAccuracy: 0.65172\n",
            "Epoch: 24 [2700/3200 (84%)]\tLoss: 0.08584\tAccuracy: 0.57181\n",
            "Epoch: 24 [2750/3200 (86%)]\tLoss: 0.13018\tAccuracy: 0.58963\n",
            "Epoch: 24 [2800/3200 (88%)]\tLoss: -0.04360\tAccuracy: 0.70324\n",
            "Epoch: 24 [2850/3200 (89%)]\tLoss: 0.12132\tAccuracy: 0.57819\n",
            "Epoch: 24 [2900/3200 (91%)]\tLoss: -0.14285\tAccuracy: 0.72286\n",
            "Epoch: 24 [2950/3200 (92%)]\tLoss: -0.06245\tAccuracy: 0.68260\n",
            "Epoch: 24 [3000/3200 (94%)]\tLoss: 0.17785\tAccuracy: 0.55963\n",
            "Epoch: 24 [3050/3200 (95%)]\tLoss: -0.06796\tAccuracy: 0.64771\n",
            "Epoch: 24 [3100/3200 (97%)]\tLoss: -0.02105\tAccuracy: 0.65618\n",
            "Epoch: 24 [3150/3200 (98%)]\tLoss: 0.06570\tAccuracy: 0.62404\n",
            "Epoch: 24 [3200/3200 (100%)]\tLoss: 0.13013\tAccuracy: 0.58554\n",
            "Train Loss: 0.01663 Train Accuracy: 0.63128\n",
            "Validation Loss: 0.71390 Validation Accuracy: 0.65085\n",
            "[0.0001]\n",
            "Epoch: 25 [50/3200 (2%)]\tLoss: -0.17089\tAccuracy: 0.76984\n",
            "Epoch: 25 [100/3200 (3%)]\tLoss: 0.09123\tAccuracy: 0.60798\n",
            "Epoch: 25 [150/3200 (5%)]\tLoss: 0.02588\tAccuracy: 0.63370\n",
            "Epoch: 25 [200/3200 (6%)]\tLoss: 0.06854\tAccuracy: 0.59118\n",
            "Epoch: 25 [250/3200 (8%)]\tLoss: -0.04215\tAccuracy: 0.67848\n",
            "Epoch: 25 [300/3200 (9%)]\tLoss: 0.13889\tAccuracy: 0.60046\n",
            "Epoch: 25 [350/3200 (11%)]\tLoss: 0.07135\tAccuracy: 0.60092\n",
            "Epoch: 25 [400/3200 (12%)]\tLoss: -0.09537\tAccuracy: 0.69278\n",
            "Epoch: 25 [450/3200 (14%)]\tLoss: -0.16879\tAccuracy: 0.70305\n",
            "Epoch: 25 [500/3200 (16%)]\tLoss: -0.08710\tAccuracy: 0.72703\n",
            "Epoch: 25 [550/3200 (17%)]\tLoss: 0.06479\tAccuracy: 0.61480\n",
            "Epoch: 25 [600/3200 (19%)]\tLoss: -0.23762\tAccuracy: 0.77700\n",
            "Epoch: 25 [650/3200 (20%)]\tLoss: 0.01917\tAccuracy: 0.64860\n",
            "Epoch: 25 [700/3200 (22%)]\tLoss: 0.16219\tAccuracy: 0.57699\n",
            "Epoch: 25 [750/3200 (23%)]\tLoss: 0.08708\tAccuracy: 0.58755\n",
            "Epoch: 25 [800/3200 (25%)]\tLoss: -0.08945\tAccuracy: 0.70909\n",
            "Epoch: 25 [850/3200 (27%)]\tLoss: -0.08958\tAccuracy: 0.66925\n",
            "Epoch: 25 [900/3200 (28%)]\tLoss: 0.00969\tAccuracy: 0.60968\n",
            "Epoch: 25 [950/3200 (30%)]\tLoss: 0.17442\tAccuracy: 0.52424\n",
            "Epoch: 25 [1000/3200 (31%)]\tLoss: -0.09632\tAccuracy: 0.67512\n",
            "Epoch: 25 [1050/3200 (33%)]\tLoss: -0.18167\tAccuracy: 0.73935\n",
            "Epoch: 25 [1100/3200 (34%)]\tLoss: -0.01918\tAccuracy: 0.63887\n",
            "Epoch: 25 [1150/3200 (36%)]\tLoss: 0.04079\tAccuracy: 0.59871\n",
            "Epoch: 25 [1200/3200 (38%)]\tLoss: 0.19995\tAccuracy: 0.51382\n",
            "Epoch: 25 [1250/3200 (39%)]\tLoss: 0.13589\tAccuracy: 0.53666\n",
            "Epoch: 25 [1300/3200 (41%)]\tLoss: -0.18255\tAccuracy: 0.70298\n",
            "Epoch: 25 [1350/3200 (42%)]\tLoss: -0.10847\tAccuracy: 0.68742\n",
            "Epoch: 25 [1400/3200 (44%)]\tLoss: 0.02312\tAccuracy: 0.61674\n",
            "Epoch: 25 [1450/3200 (45%)]\tLoss: 0.01657\tAccuracy: 0.59150\n",
            "Epoch: 25 [1500/3200 (47%)]\tLoss: -0.00625\tAccuracy: 0.68290\n",
            "Epoch: 25 [1550/3200 (48%)]\tLoss: 0.02643\tAccuracy: 0.63116\n",
            "Epoch: 25 [1600/3200 (50%)]\tLoss: -0.06940\tAccuracy: 0.68874\n",
            "Epoch: 25 [1650/3200 (52%)]\tLoss: -0.01543\tAccuracy: 0.65465\n",
            "Epoch: 25 [1700/3200 (53%)]\tLoss: -0.00502\tAccuracy: 0.66100\n",
            "Epoch: 25 [1750/3200 (55%)]\tLoss: -0.19625\tAccuracy: 0.71412\n",
            "Epoch: 25 [1800/3200 (56%)]\tLoss: -0.00823\tAccuracy: 0.62718\n",
            "Epoch: 25 [1850/3200 (58%)]\tLoss: 0.00725\tAccuracy: 0.62998\n",
            "Epoch: 25 [1900/3200 (59%)]\tLoss: 0.02961\tAccuracy: 0.63010\n",
            "Epoch: 25 [1950/3200 (61%)]\tLoss: 0.07069\tAccuracy: 0.62826\n",
            "Epoch: 25 [2000/3200 (62%)]\tLoss: 0.14569\tAccuracy: 0.55313\n",
            "Epoch: 25 [2050/3200 (64%)]\tLoss: -0.01030\tAccuracy: 0.66374\n",
            "Epoch: 25 [2100/3200 (66%)]\tLoss: -0.18892\tAccuracy: 0.70883\n",
            "Epoch: 25 [2150/3200 (67%)]\tLoss: 0.09131\tAccuracy: 0.54824\n",
            "Epoch: 25 [2200/3200 (69%)]\tLoss: 0.22749\tAccuracy: 0.53216\n",
            "Epoch: 25 [2250/3200 (70%)]\tLoss: 0.10442\tAccuracy: 0.61256\n",
            "Epoch: 25 [2300/3200 (72%)]\tLoss: -0.15419\tAccuracy: 0.69107\n",
            "Epoch: 25 [2350/3200 (73%)]\tLoss: -0.18233\tAccuracy: 0.74237\n",
            "Epoch: 25 [2400/3200 (75%)]\tLoss: 0.03944\tAccuracy: 0.61983\n",
            "Epoch: 25 [2450/3200 (77%)]\tLoss: 0.08983\tAccuracy: 0.62927\n",
            "Epoch: 25 [2500/3200 (78%)]\tLoss: 0.00827\tAccuracy: 0.65152\n",
            "Epoch: 25 [2550/3200 (80%)]\tLoss: 0.13121\tAccuracy: 0.58745\n",
            "Epoch: 25 [2600/3200 (81%)]\tLoss: -0.09947\tAccuracy: 0.75920\n",
            "Epoch: 25 [2650/3200 (83%)]\tLoss: -0.03412\tAccuracy: 0.67227\n",
            "Epoch: 25 [2700/3200 (84%)]\tLoss: 0.05933\tAccuracy: 0.57387\n",
            "Epoch: 25 [2750/3200 (86%)]\tLoss: -0.00785\tAccuracy: 0.59347\n",
            "Epoch: 25 [2800/3200 (88%)]\tLoss: -0.00204\tAccuracy: 0.66055\n",
            "Epoch: 25 [2850/3200 (89%)]\tLoss: -0.09023\tAccuracy: 0.71014\n",
            "Epoch: 25 [2900/3200 (91%)]\tLoss: 0.13736\tAccuracy: 0.58034\n",
            "Epoch: 25 [2950/3200 (92%)]\tLoss: 0.14328\tAccuracy: 0.57380\n",
            "Epoch: 25 [3000/3200 (94%)]\tLoss: 0.28419\tAccuracy: 0.49514\n",
            "Epoch: 25 [3050/3200 (95%)]\tLoss: 0.22616\tAccuracy: 0.51358\n",
            "Epoch: 25 [3100/3200 (97%)]\tLoss: 0.26109\tAccuracy: 0.52770\n",
            "Epoch: 25 [3150/3200 (98%)]\tLoss: 0.04588\tAccuracy: 0.59278\n",
            "Epoch: 25 [3200/3200 (100%)]\tLoss: 0.04951\tAccuracy: 0.60897\n",
            "Train Loss: 0.01357 Train Accuracy: 0.63397\n",
            "Validation Loss: 0.71354 Validation Accuracy: 0.65360\n",
            "[0.0001]\n",
            "Epoch: 26 [50/3200 (2%)]\tLoss: -0.24219\tAccuracy: 0.70290\n",
            "Epoch: 26 [100/3200 (3%)]\tLoss: 0.10302\tAccuracy: 0.57620\n",
            "Epoch: 26 [150/3200 (5%)]\tLoss: 0.11109\tAccuracy: 0.60476\n",
            "Epoch: 26 [200/3200 (6%)]\tLoss: 0.02438\tAccuracy: 0.63872\n",
            "Epoch: 26 [250/3200 (8%)]\tLoss: 0.07492\tAccuracy: 0.62430\n",
            "Epoch: 26 [300/3200 (9%)]\tLoss: 0.10000\tAccuracy: 0.59639\n",
            "Epoch: 26 [350/3200 (11%)]\tLoss: -0.13752\tAccuracy: 0.73706\n",
            "Epoch: 26 [400/3200 (12%)]\tLoss: -0.16542\tAccuracy: 0.72554\n",
            "Epoch: 26 [450/3200 (14%)]\tLoss: -0.09640\tAccuracy: 0.73566\n",
            "Epoch: 26 [500/3200 (16%)]\tLoss: -0.04674\tAccuracy: 0.64602\n",
            "Epoch: 26 [550/3200 (17%)]\tLoss: 0.02148\tAccuracy: 0.61831\n",
            "Epoch: 26 [600/3200 (19%)]\tLoss: -0.06633\tAccuracy: 0.64557\n",
            "Epoch: 26 [650/3200 (20%)]\tLoss: -0.17062\tAccuracy: 0.72993\n",
            "Epoch: 26 [700/3200 (22%)]\tLoss: 0.15747\tAccuracy: 0.60120\n",
            "Epoch: 26 [750/3200 (23%)]\tLoss: -0.00907\tAccuracy: 0.64826\n",
            "Epoch: 26 [800/3200 (25%)]\tLoss: -0.04379\tAccuracy: 0.67701\n",
            "Epoch: 26 [850/3200 (27%)]\tLoss: 0.05332\tAccuracy: 0.61908\n",
            "Epoch: 26 [900/3200 (28%)]\tLoss: 0.17173\tAccuracy: 0.52404\n",
            "Epoch: 26 [950/3200 (30%)]\tLoss: 0.15152\tAccuracy: 0.54702\n",
            "Epoch: 26 [1000/3200 (31%)]\tLoss: -0.00826\tAccuracy: 0.66735\n",
            "Epoch: 26 [1050/3200 (33%)]\tLoss: -0.08185\tAccuracy: 0.69203\n",
            "Epoch: 26 [1100/3200 (34%)]\tLoss: -0.10864\tAccuracy: 0.64918\n",
            "Epoch: 26 [1150/3200 (36%)]\tLoss: 0.14828\tAccuracy: 0.55111\n",
            "Epoch: 26 [1200/3200 (38%)]\tLoss: -0.01627\tAccuracy: 0.67533\n",
            "Epoch: 26 [1250/3200 (39%)]\tLoss: -0.01084\tAccuracy: 0.62936\n",
            "Epoch: 26 [1300/3200 (41%)]\tLoss: 0.00224\tAccuracy: 0.65105\n",
            "Epoch: 26 [1350/3200 (42%)]\tLoss: 0.12506\tAccuracy: 0.55239\n",
            "Epoch: 26 [1400/3200 (44%)]\tLoss: 0.00479\tAccuracy: 0.59463\n",
            "Epoch: 26 [1450/3200 (45%)]\tLoss: 0.08445\tAccuracy: 0.59442\n",
            "Epoch: 26 [1500/3200 (47%)]\tLoss: 0.04014\tAccuracy: 0.67713\n",
            "Epoch: 26 [1550/3200 (48%)]\tLoss: -0.03355\tAccuracy: 0.65324\n",
            "Epoch: 26 [1600/3200 (50%)]\tLoss: -0.14957\tAccuracy: 0.68946\n",
            "Epoch: 26 [1650/3200 (52%)]\tLoss: -0.30499\tAccuracy: 0.80519\n",
            "Epoch: 26 [1700/3200 (53%)]\tLoss: -0.04526\tAccuracy: 0.70509\n",
            "Epoch: 26 [1750/3200 (55%)]\tLoss: -0.00353\tAccuracy: 0.64176\n",
            "Epoch: 26 [1800/3200 (56%)]\tLoss: 0.24291\tAccuracy: 0.55608\n",
            "Epoch: 26 [1850/3200 (58%)]\tLoss: 0.00231\tAccuracy: 0.69436\n",
            "Epoch: 26 [1900/3200 (59%)]\tLoss: 0.07587\tAccuracy: 0.60362\n",
            "Epoch: 26 [1950/3200 (61%)]\tLoss: -0.00421\tAccuracy: 0.64846\n",
            "Epoch: 26 [2000/3200 (62%)]\tLoss: 0.02648\tAccuracy: 0.65294\n",
            "Epoch: 26 [2050/3200 (64%)]\tLoss: -0.12762\tAccuracy: 0.68697\n",
            "Epoch: 26 [2100/3200 (66%)]\tLoss: -0.06774\tAccuracy: 0.72752\n",
            "Epoch: 26 [2150/3200 (67%)]\tLoss: 0.18960\tAccuracy: 0.50970\n",
            "Epoch: 26 [2200/3200 (69%)]\tLoss: 0.12809\tAccuracy: 0.58362\n",
            "Epoch: 26 [2250/3200 (70%)]\tLoss: 0.06633\tAccuracy: 0.59050\n",
            "Epoch: 26 [2300/3200 (72%)]\tLoss: -0.04873\tAccuracy: 0.62840\n",
            "Epoch: 26 [2350/3200 (73%)]\tLoss: 0.06847\tAccuracy: 0.62938\n",
            "Epoch: 26 [2400/3200 (75%)]\tLoss: 0.16584\tAccuracy: 0.55348\n",
            "Epoch: 26 [2450/3200 (77%)]\tLoss: 0.07943\tAccuracy: 0.57974\n",
            "Epoch: 26 [2500/3200 (78%)]\tLoss: 0.17008\tAccuracy: 0.54730\n",
            "Epoch: 26 [2550/3200 (80%)]\tLoss: -0.02930\tAccuracy: 0.63923\n",
            "Epoch: 26 [2600/3200 (81%)]\tLoss: -0.21846\tAccuracy: 0.71867\n",
            "Epoch: 26 [2650/3200 (83%)]\tLoss: -0.05201\tAccuracy: 0.68854\n",
            "Epoch: 26 [2700/3200 (84%)]\tLoss: 0.17671\tAccuracy: 0.54136\n",
            "Epoch: 26 [2750/3200 (86%)]\tLoss: 0.10006\tAccuracy: 0.55931\n",
            "Epoch: 26 [2800/3200 (88%)]\tLoss: 0.03081\tAccuracy: 0.62750\n",
            "Epoch: 26 [2850/3200 (89%)]\tLoss: 0.17918\tAccuracy: 0.58023\n",
            "Epoch: 26 [2900/3200 (91%)]\tLoss: 0.10357\tAccuracy: 0.61586\n",
            "Epoch: 26 [2950/3200 (92%)]\tLoss: 0.17226\tAccuracy: 0.54741\n",
            "Epoch: 26 [3000/3200 (94%)]\tLoss: 0.02842\tAccuracy: 0.64958\n",
            "Epoch: 26 [3050/3200 (95%)]\tLoss: 0.00536\tAccuracy: 0.65461\n",
            "Epoch: 26 [3100/3200 (97%)]\tLoss: -0.06622\tAccuracy: 0.68522\n",
            "Epoch: 26 [3150/3200 (98%)]\tLoss: -0.06904\tAccuracy: 0.68645\n",
            "Epoch: 26 [3200/3200 (100%)]\tLoss: -0.14556\tAccuracy: 0.66460\n",
            "Train Loss: 0.01275 Train Accuracy: 0.63558\n",
            "Validation Loss: 0.71325 Validation Accuracy: 0.65680\n",
            "[0.0001]\n",
            "Epoch: 27 [50/3200 (2%)]\tLoss: 0.12470\tAccuracy: 0.59067\n",
            "Epoch: 27 [100/3200 (3%)]\tLoss: -0.08797\tAccuracy: 0.67831\n",
            "Epoch: 27 [150/3200 (5%)]\tLoss: 0.13411\tAccuracy: 0.56567\n",
            "Epoch: 27 [200/3200 (6%)]\tLoss: 0.19573\tAccuracy: 0.58323\n",
            "Epoch: 27 [250/3200 (8%)]\tLoss: -0.16802\tAccuracy: 0.70853\n",
            "Epoch: 27 [300/3200 (9%)]\tLoss: 0.05916\tAccuracy: 0.63787\n",
            "Epoch: 27 [350/3200 (11%)]\tLoss: 0.01398\tAccuracy: 0.62201\n",
            "Epoch: 27 [400/3200 (12%)]\tLoss: 0.11746\tAccuracy: 0.55967\n",
            "Epoch: 27 [450/3200 (14%)]\tLoss: -0.05467\tAccuracy: 0.71448\n",
            "Epoch: 27 [500/3200 (16%)]\tLoss: -0.16994\tAccuracy: 0.74489\n",
            "Epoch: 27 [550/3200 (17%)]\tLoss: 0.00300\tAccuracy: 0.63649\n",
            "Epoch: 27 [600/3200 (19%)]\tLoss: -0.03991\tAccuracy: 0.67312\n",
            "Epoch: 27 [650/3200 (20%)]\tLoss: 0.05206\tAccuracy: 0.64768\n",
            "Epoch: 27 [700/3200 (22%)]\tLoss: -0.16423\tAccuracy: 0.70423\n",
            "Epoch: 27 [750/3200 (23%)]\tLoss: 0.12965\tAccuracy: 0.56617\n",
            "Epoch: 27 [800/3200 (25%)]\tLoss: 0.17727\tAccuracy: 0.56208\n",
            "Epoch: 27 [850/3200 (27%)]\tLoss: 0.11246\tAccuracy: 0.58723\n",
            "Epoch: 27 [900/3200 (28%)]\tLoss: -0.07451\tAccuracy: 0.73289\n",
            "Epoch: 27 [950/3200 (30%)]\tLoss: 0.12405\tAccuracy: 0.57483\n",
            "Epoch: 27 [1000/3200 (31%)]\tLoss: -0.02890\tAccuracy: 0.68877\n",
            "Epoch: 27 [1050/3200 (33%)]\tLoss: -0.02080\tAccuracy: 0.64171\n",
            "Epoch: 27 [1100/3200 (34%)]\tLoss: -0.04568\tAccuracy: 0.68486\n",
            "Epoch: 27 [1150/3200 (36%)]\tLoss: 0.07909\tAccuracy: 0.62078\n",
            "Epoch: 27 [1200/3200 (38%)]\tLoss: 0.16684\tAccuracy: 0.57162\n",
            "Epoch: 27 [1250/3200 (39%)]\tLoss: -0.03613\tAccuracy: 0.63522\n",
            "Epoch: 27 [1300/3200 (41%)]\tLoss: 0.05767\tAccuracy: 0.65686\n",
            "Epoch: 27 [1350/3200 (42%)]\tLoss: 0.07310\tAccuracy: 0.62617\n",
            "Epoch: 27 [1400/3200 (44%)]\tLoss: -0.20696\tAccuracy: 0.74361\n",
            "Epoch: 27 [1450/3200 (45%)]\tLoss: 0.00129\tAccuracy: 0.61889\n",
            "Epoch: 27 [1500/3200 (47%)]\tLoss: -0.19836\tAccuracy: 0.73740\n",
            "Epoch: 27 [1550/3200 (48%)]\tLoss: 0.01810\tAccuracy: 0.62134\n",
            "Epoch: 27 [1600/3200 (50%)]\tLoss: 0.03825\tAccuracy: 0.62632\n",
            "Epoch: 27 [1650/3200 (52%)]\tLoss: -0.03725\tAccuracy: 0.67666\n",
            "Epoch: 27 [1700/3200 (53%)]\tLoss: 0.01084\tAccuracy: 0.62812\n",
            "Epoch: 27 [1750/3200 (55%)]\tLoss: 0.00767\tAccuracy: 0.69208\n",
            "Epoch: 27 [1800/3200 (56%)]\tLoss: 0.28934\tAccuracy: 0.51149\n",
            "Epoch: 27 [1850/3200 (58%)]\tLoss: 0.16196\tAccuracy: 0.53728\n",
            "Epoch: 27 [1900/3200 (59%)]\tLoss: -0.14723\tAccuracy: 0.66660\n",
            "Epoch: 27 [1950/3200 (61%)]\tLoss: -0.04991\tAccuracy: 0.62951\n",
            "Epoch: 27 [2000/3200 (62%)]\tLoss: -0.02205\tAccuracy: 0.64161\n",
            "Epoch: 27 [2050/3200 (64%)]\tLoss: 0.09876\tAccuracy: 0.59948\n",
            "Epoch: 27 [2100/3200 (66%)]\tLoss: 0.05696\tAccuracy: 0.61984\n",
            "Epoch: 27 [2150/3200 (67%)]\tLoss: 0.11492\tAccuracy: 0.53980\n",
            "Epoch: 27 [2200/3200 (69%)]\tLoss: -0.09111\tAccuracy: 0.65113\n",
            "Epoch: 27 [2250/3200 (70%)]\tLoss: 0.12653\tAccuracy: 0.55066\n",
            "Epoch: 27 [2300/3200 (72%)]\tLoss: -0.05812\tAccuracy: 0.65772\n",
            "Epoch: 27 [2350/3200 (73%)]\tLoss: 0.07328\tAccuracy: 0.56516\n",
            "Epoch: 27 [2400/3200 (75%)]\tLoss: 0.05475\tAccuracy: 0.61018\n",
            "Epoch: 27 [2450/3200 (77%)]\tLoss: 0.06737\tAccuracy: 0.65125\n",
            "Epoch: 27 [2500/3200 (78%)]\tLoss: -0.02022\tAccuracy: 0.66010\n",
            "Epoch: 27 [2550/3200 (80%)]\tLoss: 0.07322\tAccuracy: 0.60667\n",
            "Epoch: 27 [2600/3200 (81%)]\tLoss: -0.02463\tAccuracy: 0.64211\n",
            "Epoch: 27 [2650/3200 (83%)]\tLoss: 0.01538\tAccuracy: 0.67238\n",
            "Epoch: 27 [2700/3200 (84%)]\tLoss: 0.04176\tAccuracy: 0.61831\n",
            "Epoch: 27 [2750/3200 (86%)]\tLoss: -0.25491\tAccuracy: 0.75010\n",
            "Epoch: 27 [2800/3200 (88%)]\tLoss: 0.01165\tAccuracy: 0.68478\n",
            "Epoch: 27 [2850/3200 (89%)]\tLoss: -0.09626\tAccuracy: 0.65707\n",
            "Epoch: 27 [2900/3200 (91%)]\tLoss: 0.05328\tAccuracy: 0.60279\n",
            "Epoch: 27 [2950/3200 (92%)]\tLoss: 0.07274\tAccuracy: 0.60684\n",
            "Epoch: 27 [3000/3200 (94%)]\tLoss: -0.23634\tAccuracy: 0.71694\n",
            "Epoch: 27 [3050/3200 (95%)]\tLoss: -0.10250\tAccuracy: 0.70223\n",
            "Epoch: 27 [3100/3200 (97%)]\tLoss: 0.11348\tAccuracy: 0.61751\n",
            "Epoch: 27 [3150/3200 (98%)]\tLoss: -0.09612\tAccuracy: 0.69569\n",
            "Epoch: 27 [3200/3200 (100%)]\tLoss: 0.33802\tAccuracy: 0.43954\n",
            "Train Loss: 0.01449 Train Accuracy: 0.63539\n",
            "Validation Loss: 0.71282 Validation Accuracy: 0.65784\n",
            "[0.0001]\n",
            "Epoch: 28 [50/3200 (2%)]\tLoss: 0.20539\tAccuracy: 0.53391\n",
            "Epoch: 28 [100/3200 (3%)]\tLoss: 0.13577\tAccuracy: 0.57725\n",
            "Epoch: 28 [150/3200 (5%)]\tLoss: -0.08870\tAccuracy: 0.64837\n",
            "Epoch: 28 [200/3200 (6%)]\tLoss: 0.29144\tAccuracy: 0.52160\n",
            "Epoch: 28 [250/3200 (8%)]\tLoss: 0.08707\tAccuracy: 0.64550\n",
            "Epoch: 28 [300/3200 (9%)]\tLoss: 0.24313\tAccuracy: 0.49600\n",
            "Epoch: 28 [350/3200 (11%)]\tLoss: 0.22111\tAccuracy: 0.49614\n",
            "Epoch: 28 [400/3200 (12%)]\tLoss: 0.11280\tAccuracy: 0.60685\n",
            "Epoch: 28 [450/3200 (14%)]\tLoss: 0.10319\tAccuracy: 0.57370\n",
            "Epoch: 28 [500/3200 (16%)]\tLoss: -0.06593\tAccuracy: 0.68551\n",
            "Epoch: 28 [550/3200 (17%)]\tLoss: 0.03788\tAccuracy: 0.57902\n",
            "Epoch: 28 [600/3200 (19%)]\tLoss: -0.05602\tAccuracy: 0.70540\n",
            "Epoch: 28 [650/3200 (20%)]\tLoss: 0.08721\tAccuracy: 0.59186\n",
            "Epoch: 28 [700/3200 (22%)]\tLoss: -0.14828\tAccuracy: 0.72629\n",
            "Epoch: 28 [750/3200 (23%)]\tLoss: -0.18191\tAccuracy: 0.75933\n",
            "Epoch: 28 [800/3200 (25%)]\tLoss: 0.15519\tAccuracy: 0.56029\n",
            "Epoch: 28 [850/3200 (27%)]\tLoss: -0.02808\tAccuracy: 0.66789\n",
            "Epoch: 28 [900/3200 (28%)]\tLoss: -0.11542\tAccuracy: 0.67553\n",
            "Epoch: 28 [950/3200 (30%)]\tLoss: -0.04326\tAccuracy: 0.66184\n",
            "Epoch: 28 [1000/3200 (31%)]\tLoss: -0.00437\tAccuracy: 0.66298\n",
            "Epoch: 28 [1050/3200 (33%)]\tLoss: -0.10288\tAccuracy: 0.64302\n",
            "Epoch: 28 [1100/3200 (34%)]\tLoss: -0.11732\tAccuracy: 0.71504\n",
            "Epoch: 28 [1150/3200 (36%)]\tLoss: 0.00529\tAccuracy: 0.63293\n",
            "Epoch: 28 [1200/3200 (38%)]\tLoss: -0.00626\tAccuracy: 0.64460\n",
            "Epoch: 28 [1250/3200 (39%)]\tLoss: 0.08243\tAccuracy: 0.61520\n",
            "Epoch: 28 [1300/3200 (41%)]\tLoss: -0.07058\tAccuracy: 0.67039\n",
            "Epoch: 28 [1350/3200 (42%)]\tLoss: 0.05482\tAccuracy: 0.61698\n",
            "Epoch: 28 [1400/3200 (44%)]\tLoss: 0.02367\tAccuracy: 0.63559\n",
            "Epoch: 28 [1450/3200 (45%)]\tLoss: -0.17000\tAccuracy: 0.72930\n",
            "Epoch: 28 [1500/3200 (47%)]\tLoss: 0.15764\tAccuracy: 0.56157\n",
            "Epoch: 28 [1550/3200 (48%)]\tLoss: -0.07649\tAccuracy: 0.69413\n",
            "Epoch: 28 [1600/3200 (50%)]\tLoss: -0.17270\tAccuracy: 0.73013\n",
            "Epoch: 28 [1650/3200 (52%)]\tLoss: 0.02803\tAccuracy: 0.65166\n",
            "Epoch: 28 [1700/3200 (53%)]\tLoss: -0.15410\tAccuracy: 0.73399\n",
            "Epoch: 28 [1750/3200 (55%)]\tLoss: 0.09541\tAccuracy: 0.60394\n",
            "Epoch: 28 [1800/3200 (56%)]\tLoss: 0.16730\tAccuracy: 0.55123\n",
            "Epoch: 28 [1850/3200 (58%)]\tLoss: 0.24218\tAccuracy: 0.53638\n",
            "Epoch: 28 [1900/3200 (59%)]\tLoss: -0.01712\tAccuracy: 0.69700\n",
            "Epoch: 28 [1950/3200 (61%)]\tLoss: 0.11398\tAccuracy: 0.60535\n",
            "Epoch: 28 [2000/3200 (62%)]\tLoss: -0.10276\tAccuracy: 0.70293\n",
            "Epoch: 28 [2050/3200 (64%)]\tLoss: -0.02225\tAccuracy: 0.66178\n",
            "Epoch: 28 [2100/3200 (66%)]\tLoss: -0.08103\tAccuracy: 0.66704\n",
            "Epoch: 28 [2150/3200 (67%)]\tLoss: -0.11222\tAccuracy: 0.69177\n",
            "Epoch: 28 [2200/3200 (69%)]\tLoss: -0.09751\tAccuracy: 0.66501\n",
            "Epoch: 28 [2250/3200 (70%)]\tLoss: -0.14453\tAccuracy: 0.74438\n",
            "Epoch: 28 [2300/3200 (72%)]\tLoss: -0.10159\tAccuracy: 0.70131\n",
            "Epoch: 28 [2350/3200 (73%)]\tLoss: -0.18120\tAccuracy: 0.75041\n",
            "Epoch: 28 [2400/3200 (75%)]\tLoss: 0.06471\tAccuracy: 0.58511\n",
            "Epoch: 28 [2450/3200 (77%)]\tLoss: 0.03237\tAccuracy: 0.61150\n",
            "Epoch: 28 [2500/3200 (78%)]\tLoss: -0.01431\tAccuracy: 0.67308\n",
            "Epoch: 28 [2550/3200 (80%)]\tLoss: 0.05533\tAccuracy: 0.62709\n",
            "Epoch: 28 [2600/3200 (81%)]\tLoss: -0.16907\tAccuracy: 0.74581\n",
            "Epoch: 28 [2650/3200 (83%)]\tLoss: 0.07900\tAccuracy: 0.59968\n",
            "Epoch: 28 [2700/3200 (84%)]\tLoss: 0.02463\tAccuracy: 0.61526\n",
            "Epoch: 28 [2750/3200 (86%)]\tLoss: -0.17352\tAccuracy: 0.73344\n",
            "Epoch: 28 [2800/3200 (88%)]\tLoss: 0.11708\tAccuracy: 0.60230\n",
            "Epoch: 28 [2850/3200 (89%)]\tLoss: -0.01645\tAccuracy: 0.67557\n",
            "Epoch: 28 [2900/3200 (91%)]\tLoss: -0.03303\tAccuracy: 0.65077\n",
            "Epoch: 28 [2950/3200 (92%)]\tLoss: -0.01121\tAccuracy: 0.64903\n",
            "Epoch: 28 [3000/3200 (94%)]\tLoss: -0.01670\tAccuracy: 0.71529\n",
            "Epoch: 28 [3050/3200 (95%)]\tLoss: 0.00624\tAccuracy: 0.68694\n",
            "Epoch: 28 [3100/3200 (97%)]\tLoss: -0.10477\tAccuracy: 0.68490\n",
            "Epoch: 28 [3150/3200 (98%)]\tLoss: 0.08132\tAccuracy: 0.57198\n",
            "Epoch: 28 [3200/3200 (100%)]\tLoss: 0.20133\tAccuracy: 0.49592\n",
            "Train Loss: 0.00487 Train Accuracy: 0.64300\n",
            "Validation Loss: 0.71294 Validation Accuracy: 0.65673\n",
            "[0.0001]\n",
            "Epoch: 29 [50/3200 (2%)]\tLoss: 0.01811\tAccuracy: 0.64171\n",
            "Epoch: 29 [100/3200 (3%)]\tLoss: 0.04550\tAccuracy: 0.60674\n",
            "Epoch: 29 [150/3200 (5%)]\tLoss: -0.07093\tAccuracy: 0.67082\n",
            "Epoch: 29 [200/3200 (6%)]\tLoss: 0.33641\tAccuracy: 0.45990\n",
            "Epoch: 29 [250/3200 (8%)]\tLoss: 0.01810\tAccuracy: 0.66173\n",
            "Epoch: 29 [300/3200 (9%)]\tLoss: -0.01130\tAccuracy: 0.64328\n",
            "Epoch: 29 [350/3200 (11%)]\tLoss: -0.06404\tAccuracy: 0.68364\n",
            "Epoch: 29 [400/3200 (12%)]\tLoss: 0.24259\tAccuracy: 0.49015\n",
            "Epoch: 29 [450/3200 (14%)]\tLoss: -0.03159\tAccuracy: 0.67095\n",
            "Epoch: 29 [500/3200 (16%)]\tLoss: -0.17530\tAccuracy: 0.71222\n",
            "Epoch: 29 [550/3200 (17%)]\tLoss: -0.02861\tAccuracy: 0.64561\n",
            "Epoch: 29 [600/3200 (19%)]\tLoss: -0.09206\tAccuracy: 0.69172\n",
            "Epoch: 29 [650/3200 (20%)]\tLoss: 0.09003\tAccuracy: 0.60909\n",
            "Epoch: 29 [700/3200 (22%)]\tLoss: 0.03848\tAccuracy: 0.61794\n",
            "Epoch: 29 [750/3200 (23%)]\tLoss: 0.08848\tAccuracy: 0.63133\n",
            "Epoch: 29 [800/3200 (25%)]\tLoss: -0.10348\tAccuracy: 0.71791\n",
            "Epoch: 29 [850/3200 (27%)]\tLoss: -0.24206\tAccuracy: 0.74136\n",
            "Epoch: 29 [900/3200 (28%)]\tLoss: 0.10489\tAccuracy: 0.57395\n",
            "Epoch: 29 [950/3200 (30%)]\tLoss: 0.14930\tAccuracy: 0.53835\n",
            "Epoch: 29 [1000/3200 (31%)]\tLoss: 0.02738\tAccuracy: 0.67214\n",
            "Epoch: 29 [1050/3200 (33%)]\tLoss: 0.04165\tAccuracy: 0.59747\n",
            "Epoch: 29 [1100/3200 (34%)]\tLoss: 0.08109\tAccuracy: 0.57789\n",
            "Epoch: 29 [1150/3200 (36%)]\tLoss: -0.04050\tAccuracy: 0.67016\n",
            "Epoch: 29 [1200/3200 (38%)]\tLoss: -0.10851\tAccuracy: 0.68805\n",
            "Epoch: 29 [1250/3200 (39%)]\tLoss: 0.00339\tAccuracy: 0.63258\n",
            "Epoch: 29 [1300/3200 (41%)]\tLoss: 0.07047\tAccuracy: 0.56889\n",
            "Epoch: 29 [1350/3200 (42%)]\tLoss: 0.00907\tAccuracy: 0.64977\n",
            "Epoch: 29 [1400/3200 (44%)]\tLoss: 0.08321\tAccuracy: 0.59378\n",
            "Epoch: 29 [1450/3200 (45%)]\tLoss: 0.14252\tAccuracy: 0.57701\n",
            "Epoch: 29 [1500/3200 (47%)]\tLoss: -0.09045\tAccuracy: 0.64544\n",
            "Epoch: 29 [1550/3200 (48%)]\tLoss: -0.01403\tAccuracy: 0.69407\n",
            "Epoch: 29 [1600/3200 (50%)]\tLoss: 0.08710\tAccuracy: 0.57245\n",
            "Epoch: 29 [1650/3200 (52%)]\tLoss: -0.05139\tAccuracy: 0.64845\n",
            "Epoch: 29 [1700/3200 (53%)]\tLoss: 0.03807\tAccuracy: 0.62160\n",
            "Epoch: 29 [1750/3200 (55%)]\tLoss: 0.18482\tAccuracy: 0.55284\n",
            "Epoch: 29 [1800/3200 (56%)]\tLoss: -0.01542\tAccuracy: 0.62233\n",
            "Epoch: 29 [1850/3200 (58%)]\tLoss: 0.02422\tAccuracy: 0.62699\n",
            "Epoch: 29 [1900/3200 (59%)]\tLoss: -0.23383\tAccuracy: 0.75390\n",
            "Epoch: 29 [1950/3200 (61%)]\tLoss: -0.02811\tAccuracy: 0.68811\n",
            "Epoch: 29 [2000/3200 (62%)]\tLoss: 0.17412\tAccuracy: 0.60471\n",
            "Epoch: 29 [2050/3200 (64%)]\tLoss: -0.03445\tAccuracy: 0.67319\n",
            "Epoch: 29 [2100/3200 (66%)]\tLoss: 0.03662\tAccuracy: 0.60286\n",
            "Epoch: 29 [2150/3200 (67%)]\tLoss: -0.07790\tAccuracy: 0.71594\n",
            "Epoch: 29 [2200/3200 (69%)]\tLoss: -0.01040\tAccuracy: 0.62955\n",
            "Epoch: 29 [2250/3200 (70%)]\tLoss: 0.21553\tAccuracy: 0.54008\n",
            "Epoch: 29 [2300/3200 (72%)]\tLoss: 0.07629\tAccuracy: 0.60348\n",
            "Epoch: 29 [2350/3200 (73%)]\tLoss: -0.09990\tAccuracy: 0.69982\n",
            "Epoch: 29 [2400/3200 (75%)]\tLoss: -0.04306\tAccuracy: 0.66262\n",
            "Epoch: 29 [2450/3200 (77%)]\tLoss: -0.00659\tAccuracy: 0.66169\n",
            "Epoch: 29 [2500/3200 (78%)]\tLoss: -0.08785\tAccuracy: 0.66382\n",
            "Epoch: 29 [2550/3200 (80%)]\tLoss: 0.11614\tAccuracy: 0.62293\n",
            "Epoch: 29 [2600/3200 (81%)]\tLoss: 0.16543\tAccuracy: 0.55430\n",
            "Epoch: 29 [2650/3200 (83%)]\tLoss: -0.07575\tAccuracy: 0.65433\n",
            "Epoch: 29 [2700/3200 (84%)]\tLoss: -0.13894\tAccuracy: 0.71878\n",
            "Epoch: 29 [2750/3200 (86%)]\tLoss: -0.04851\tAccuracy: 0.66678\n",
            "Epoch: 29 [2800/3200 (88%)]\tLoss: 0.02213\tAccuracy: 0.61293\n",
            "Epoch: 29 [2850/3200 (89%)]\tLoss: 0.04409\tAccuracy: 0.63563\n",
            "Epoch: 29 [2900/3200 (91%)]\tLoss: -0.15183\tAccuracy: 0.69072\n",
            "Epoch: 29 [2950/3200 (92%)]\tLoss: -0.07280\tAccuracy: 0.71139\n",
            "Epoch: 29 [3000/3200 (94%)]\tLoss: 0.05853\tAccuracy: 0.58147\n",
            "Epoch: 29 [3050/3200 (95%)]\tLoss: -0.05334\tAccuracy: 0.70262\n",
            "Epoch: 29 [3100/3200 (97%)]\tLoss: 0.13306\tAccuracy: 0.55343\n",
            "Epoch: 29 [3150/3200 (98%)]\tLoss: 0.14184\tAccuracy: 0.55781\n",
            "Epoch: 29 [3200/3200 (100%)]\tLoss: 0.05248\tAccuracy: 0.62675\n",
            "Train Loss: 0.01341 Train Accuracy: 0.63453\n",
            "Validation Loss: 0.71299 Validation Accuracy: 0.65882\n",
            "[0.0001]\n",
            "Epoch: 30 [50/3200 (2%)]\tLoss: -0.14877\tAccuracy: 0.70855\n",
            "Epoch: 30 [100/3200 (3%)]\tLoss: 0.02993\tAccuracy: 0.62927\n",
            "Epoch: 30 [150/3200 (5%)]\tLoss: 0.13371\tAccuracy: 0.53597\n",
            "Epoch: 30 [200/3200 (6%)]\tLoss: 0.02363\tAccuracy: 0.63547\n",
            "Epoch: 30 [250/3200 (8%)]\tLoss: 0.08393\tAccuracy: 0.57342\n",
            "Epoch: 30 [300/3200 (9%)]\tLoss: -0.04722\tAccuracy: 0.68375\n",
            "Epoch: 30 [350/3200 (11%)]\tLoss: -0.09582\tAccuracy: 0.71576\n",
            "Epoch: 30 [400/3200 (12%)]\tLoss: 0.09042\tAccuracy: 0.58938\n",
            "Epoch: 30 [450/3200 (14%)]\tLoss: 0.09898\tAccuracy: 0.61936\n",
            "Epoch: 30 [500/3200 (16%)]\tLoss: -0.00921\tAccuracy: 0.62642\n",
            "Epoch: 30 [550/3200 (17%)]\tLoss: 0.19423\tAccuracy: 0.54522\n",
            "Epoch: 30 [600/3200 (19%)]\tLoss: -0.05696\tAccuracy: 0.69586\n",
            "Epoch: 30 [650/3200 (20%)]\tLoss: 0.06079\tAccuracy: 0.61819\n",
            "Epoch: 30 [700/3200 (22%)]\tLoss: 0.25578\tAccuracy: 0.52175\n",
            "Epoch: 30 [750/3200 (23%)]\tLoss: 0.00528\tAccuracy: 0.57464\n",
            "Epoch: 30 [800/3200 (25%)]\tLoss: 0.04077\tAccuracy: 0.63753\n",
            "Epoch: 30 [850/3200 (27%)]\tLoss: 0.03802\tAccuracy: 0.62156\n",
            "Epoch: 30 [900/3200 (28%)]\tLoss: -0.11842\tAccuracy: 0.69653\n",
            "Epoch: 30 [950/3200 (30%)]\tLoss: 0.07441\tAccuracy: 0.60487\n",
            "Epoch: 30 [1000/3200 (31%)]\tLoss: -0.04213\tAccuracy: 0.64174\n",
            "Epoch: 30 [1050/3200 (33%)]\tLoss: -0.01949\tAccuracy: 0.69342\n",
            "Epoch: 30 [1100/3200 (34%)]\tLoss: 0.21957\tAccuracy: 0.55184\n",
            "Epoch: 30 [1150/3200 (36%)]\tLoss: -0.14370\tAccuracy: 0.72245\n",
            "Epoch: 30 [1200/3200 (38%)]\tLoss: 0.07436\tAccuracy: 0.58342\n",
            "Epoch: 30 [1250/3200 (39%)]\tLoss: -0.02233\tAccuracy: 0.68177\n",
            "Epoch: 30 [1300/3200 (41%)]\tLoss: -0.00989\tAccuracy: 0.62828\n",
            "Epoch: 30 [1350/3200 (42%)]\tLoss: 0.15133\tAccuracy: 0.56624\n",
            "Epoch: 30 [1400/3200 (44%)]\tLoss: 0.12197\tAccuracy: 0.57767\n",
            "Epoch: 30 [1450/3200 (45%)]\tLoss: 0.10333\tAccuracy: 0.57016\n",
            "Epoch: 30 [1500/3200 (47%)]\tLoss: 0.10940\tAccuracy: 0.60947\n",
            "Epoch: 30 [1550/3200 (48%)]\tLoss: 0.02204\tAccuracy: 0.61727\n",
            "Epoch: 30 [1600/3200 (50%)]\tLoss: -0.05212\tAccuracy: 0.68946\n",
            "Epoch: 30 [1650/3200 (52%)]\tLoss: -0.04990\tAccuracy: 0.66924\n",
            "Epoch: 30 [1700/3200 (53%)]\tLoss: 0.11884\tAccuracy: 0.59757\n",
            "Epoch: 30 [1750/3200 (55%)]\tLoss: 0.08588\tAccuracy: 0.59350\n",
            "Epoch: 30 [1800/3200 (56%)]\tLoss: -0.12059\tAccuracy: 0.67749\n",
            "Epoch: 30 [1850/3200 (58%)]\tLoss: -0.21213\tAccuracy: 0.75209\n",
            "Epoch: 30 [1900/3200 (59%)]\tLoss: 0.06316\tAccuracy: 0.59629\n",
            "Epoch: 30 [1950/3200 (61%)]\tLoss: 0.17829\tAccuracy: 0.59087\n",
            "Epoch: 30 [2000/3200 (62%)]\tLoss: -0.04802\tAccuracy: 0.66791\n",
            "Epoch: 30 [2050/3200 (64%)]\tLoss: 0.00898\tAccuracy: 0.67099\n",
            "Epoch: 30 [2100/3200 (66%)]\tLoss: 0.09611\tAccuracy: 0.62197\n",
            "Epoch: 30 [2150/3200 (67%)]\tLoss: -0.20405\tAccuracy: 0.72132\n",
            "Epoch: 30 [2200/3200 (69%)]\tLoss: 0.09633\tAccuracy: 0.59087\n",
            "Epoch: 30 [2250/3200 (70%)]\tLoss: 0.16779\tAccuracy: 0.53181\n",
            "Epoch: 30 [2300/3200 (72%)]\tLoss: -0.05385\tAccuracy: 0.70354\n",
            "Epoch: 30 [2350/3200 (73%)]\tLoss: 0.11992\tAccuracy: 0.56859\n",
            "Epoch: 30 [2400/3200 (75%)]\tLoss: -0.01173\tAccuracy: 0.66895\n",
            "Epoch: 30 [2450/3200 (77%)]\tLoss: 0.00075\tAccuracy: 0.65908\n",
            "Epoch: 30 [2500/3200 (78%)]\tLoss: -0.12975\tAccuracy: 0.72242\n",
            "Epoch: 30 [2550/3200 (80%)]\tLoss: 0.00560\tAccuracy: 0.67289\n",
            "Epoch: 30 [2600/3200 (81%)]\tLoss: -0.21895\tAccuracy: 0.72276\n",
            "Epoch: 30 [2650/3200 (83%)]\tLoss: 0.05591\tAccuracy: 0.60238\n",
            "Epoch: 30 [2700/3200 (84%)]\tLoss: -0.04854\tAccuracy: 0.64328\n",
            "Epoch: 30 [2750/3200 (86%)]\tLoss: -0.03198\tAccuracy: 0.67223\n",
            "Epoch: 30 [2800/3200 (88%)]\tLoss: -0.16557\tAccuracy: 0.72556\n",
            "Epoch: 30 [2850/3200 (89%)]\tLoss: -0.06809\tAccuracy: 0.64637\n",
            "Epoch: 30 [2900/3200 (91%)]\tLoss: 0.14562\tAccuracy: 0.53295\n",
            "Epoch: 30 [2950/3200 (92%)]\tLoss: 0.03910\tAccuracy: 0.57866\n",
            "Epoch: 30 [3000/3200 (94%)]\tLoss: -0.11831\tAccuracy: 0.67815\n",
            "Epoch: 30 [3050/3200 (95%)]\tLoss: 0.00828\tAccuracy: 0.67083\n",
            "Epoch: 30 [3100/3200 (97%)]\tLoss: 0.07640\tAccuracy: 0.60284\n",
            "Epoch: 30 [3150/3200 (98%)]\tLoss: -0.28053\tAccuracy: 0.78064\n",
            "Epoch: 30 [3200/3200 (100%)]\tLoss: -0.01023\tAccuracy: 0.62739\n",
            "Train Loss: 0.01032 Train Accuracy: 0.63638\n",
            "Validation Loss: 0.71259 Validation Accuracy: 0.65970\n",
            "[0.0001]\n",
            "Epoch: 31 [50/3200 (2%)]\tLoss: -0.05355\tAccuracy: 0.69319\n",
            "Epoch: 31 [100/3200 (3%)]\tLoss: 0.04074\tAccuracy: 0.65198\n",
            "Epoch: 31 [150/3200 (5%)]\tLoss: -0.19258\tAccuracy: 0.70606\n",
            "Epoch: 31 [200/3200 (6%)]\tLoss: -0.00120\tAccuracy: 0.65839\n",
            "Epoch: 31 [250/3200 (8%)]\tLoss: 0.16503\tAccuracy: 0.55006\n",
            "Epoch: 31 [300/3200 (9%)]\tLoss: -0.00063\tAccuracy: 0.61849\n",
            "Epoch: 31 [350/3200 (11%)]\tLoss: -0.06262\tAccuracy: 0.70095\n",
            "Epoch: 31 [400/3200 (12%)]\tLoss: 0.33207\tAccuracy: 0.50713\n",
            "Epoch: 31 [450/3200 (14%)]\tLoss: 0.11538\tAccuracy: 0.62076\n",
            "Epoch: 31 [500/3200 (16%)]\tLoss: -0.10714\tAccuracy: 0.66600\n",
            "Epoch: 31 [550/3200 (17%)]\tLoss: -0.01636\tAccuracy: 0.65464\n",
            "Epoch: 31 [600/3200 (19%)]\tLoss: 0.10279\tAccuracy: 0.59613\n",
            "Epoch: 31 [650/3200 (20%)]\tLoss: 0.02211\tAccuracy: 0.62743\n",
            "Epoch: 31 [700/3200 (22%)]\tLoss: -0.03637\tAccuracy: 0.67416\n",
            "Epoch: 31 [750/3200 (23%)]\tLoss: -0.01457\tAccuracy: 0.64405\n",
            "Epoch: 31 [800/3200 (25%)]\tLoss: 0.07554\tAccuracy: 0.58319\n",
            "Epoch: 31 [850/3200 (27%)]\tLoss: -0.01670\tAccuracy: 0.63627\n",
            "Epoch: 31 [900/3200 (28%)]\tLoss: 0.10165\tAccuracy: 0.63761\n",
            "Epoch: 31 [950/3200 (30%)]\tLoss: 0.08564\tAccuracy: 0.59402\n",
            "Epoch: 31 [1000/3200 (31%)]\tLoss: 0.09756\tAccuracy: 0.58256\n",
            "Epoch: 31 [1050/3200 (33%)]\tLoss: -0.01464\tAccuracy: 0.61409\n",
            "Epoch: 31 [1100/3200 (34%)]\tLoss: 0.01204\tAccuracy: 0.60686\n",
            "Epoch: 31 [1150/3200 (36%)]\tLoss: -0.08355\tAccuracy: 0.69070\n",
            "Epoch: 31 [1200/3200 (38%)]\tLoss: -0.19364\tAccuracy: 0.75235\n",
            "Epoch: 31 [1250/3200 (39%)]\tLoss: -0.13659\tAccuracy: 0.67327\n",
            "Epoch: 31 [1300/3200 (41%)]\tLoss: 0.01997\tAccuracy: 0.67977\n",
            "Epoch: 31 [1350/3200 (42%)]\tLoss: -0.12721\tAccuracy: 0.72646\n",
            "Epoch: 31 [1400/3200 (44%)]\tLoss: 0.03302\tAccuracy: 0.62413\n",
            "Epoch: 31 [1450/3200 (45%)]\tLoss: 0.07619\tAccuracy: 0.60349\n",
            "Epoch: 31 [1500/3200 (47%)]\tLoss: -0.05219\tAccuracy: 0.71208\n",
            "Epoch: 31 [1550/3200 (48%)]\tLoss: -0.14291\tAccuracy: 0.72258\n",
            "Epoch: 31 [1600/3200 (50%)]\tLoss: 0.06629\tAccuracy: 0.59282\n",
            "Epoch: 31 [1650/3200 (52%)]\tLoss: 0.01948\tAccuracy: 0.61574\n",
            "Epoch: 31 [1700/3200 (53%)]\tLoss: 0.00810\tAccuracy: 0.61956\n",
            "Epoch: 31 [1750/3200 (55%)]\tLoss: 0.06106\tAccuracy: 0.65873\n",
            "Epoch: 31 [1800/3200 (56%)]\tLoss: 0.16217\tAccuracy: 0.53752\n",
            "Epoch: 31 [1850/3200 (58%)]\tLoss: 0.01643\tAccuracy: 0.64270\n",
            "Epoch: 31 [1900/3200 (59%)]\tLoss: 0.14331\tAccuracy: 0.57384\n",
            "Epoch: 31 [1950/3200 (61%)]\tLoss: 0.05253\tAccuracy: 0.60648\n",
            "Epoch: 31 [2000/3200 (62%)]\tLoss: 0.07906\tAccuracy: 0.63834\n",
            "Epoch: 31 [2050/3200 (64%)]\tLoss: -0.02469\tAccuracy: 0.70314\n",
            "Epoch: 31 [2100/3200 (66%)]\tLoss: 0.02648\tAccuracy: 0.62293\n",
            "Epoch: 31 [2150/3200 (67%)]\tLoss: -0.03587\tAccuracy: 0.67338\n",
            "Epoch: 31 [2200/3200 (69%)]\tLoss: 0.11824\tAccuracy: 0.63951\n",
            "Epoch: 31 [2250/3200 (70%)]\tLoss: 0.15757\tAccuracy: 0.58243\n",
            "Epoch: 31 [2300/3200 (72%)]\tLoss: 0.21844\tAccuracy: 0.54081\n",
            "Epoch: 31 [2350/3200 (73%)]\tLoss: -0.12586\tAccuracy: 0.70332\n",
            "Epoch: 31 [2400/3200 (75%)]\tLoss: -0.27108\tAccuracy: 0.77008\n",
            "Epoch: 31 [2450/3200 (77%)]\tLoss: -0.08739\tAccuracy: 0.68676\n",
            "Epoch: 31 [2500/3200 (78%)]\tLoss: 0.19396\tAccuracy: 0.52335\n",
            "Epoch: 31 [2550/3200 (80%)]\tLoss: 0.12669\tAccuracy: 0.55217\n",
            "Epoch: 31 [2600/3200 (81%)]\tLoss: -0.01160\tAccuracy: 0.64767\n",
            "Epoch: 31 [2650/3200 (83%)]\tLoss: 0.06464\tAccuracy: 0.61500\n",
            "Epoch: 31 [2700/3200 (84%)]\tLoss: -0.11777\tAccuracy: 0.69790\n",
            "Epoch: 31 [2750/3200 (86%)]\tLoss: 0.21076\tAccuracy: 0.48447\n",
            "Epoch: 31 [2800/3200 (88%)]\tLoss: -0.13731\tAccuracy: 0.73725\n",
            "Epoch: 31 [2850/3200 (89%)]\tLoss: 0.27300\tAccuracy: 0.48557\n",
            "Epoch: 31 [2900/3200 (91%)]\tLoss: -0.16237\tAccuracy: 0.72232\n",
            "Epoch: 31 [2950/3200 (92%)]\tLoss: -0.16127\tAccuracy: 0.73729\n",
            "Epoch: 31 [3000/3200 (94%)]\tLoss: -0.22486\tAccuracy: 0.72235\n",
            "Epoch: 31 [3050/3200 (95%)]\tLoss: -0.24242\tAccuracy: 0.78215\n",
            "Epoch: 31 [3100/3200 (97%)]\tLoss: 0.04522\tAccuracy: 0.61057\n",
            "Epoch: 31 [3150/3200 (98%)]\tLoss: 0.14629\tAccuracy: 0.55840\n",
            "Epoch: 31 [3200/3200 (100%)]\tLoss: -0.07472\tAccuracy: 0.65468\n",
            "Train Loss: 0.00843 Train Accuracy: 0.63981\n",
            "Validation Loss: 0.71235 Validation Accuracy: 0.66036\n",
            "[0.0001]\n",
            "Epoch: 32 [50/3200 (2%)]\tLoss: -0.17887\tAccuracy: 0.68915\n",
            "Epoch: 32 [100/3200 (3%)]\tLoss: 0.10956\tAccuracy: 0.62517\n",
            "Epoch: 32 [150/3200 (5%)]\tLoss: 0.00390\tAccuracy: 0.63590\n",
            "Epoch: 32 [200/3200 (6%)]\tLoss: 0.15539\tAccuracy: 0.52089\n",
            "Epoch: 32 [250/3200 (8%)]\tLoss: -0.06096\tAccuracy: 0.68724\n",
            "Epoch: 32 [300/3200 (9%)]\tLoss: 0.08651\tAccuracy: 0.63270\n",
            "Epoch: 32 [350/3200 (11%)]\tLoss: 0.27602\tAccuracy: 0.42772\n",
            "Epoch: 32 [400/3200 (12%)]\tLoss: 0.04816\tAccuracy: 0.61006\n",
            "Epoch: 32 [450/3200 (14%)]\tLoss: -0.06512\tAccuracy: 0.68347\n",
            "Epoch: 32 [500/3200 (16%)]\tLoss: -0.03380\tAccuracy: 0.65233\n",
            "Epoch: 32 [550/3200 (17%)]\tLoss: -0.03994\tAccuracy: 0.65898\n",
            "Epoch: 32 [600/3200 (19%)]\tLoss: 0.02752\tAccuracy: 0.61945\n",
            "Epoch: 32 [650/3200 (20%)]\tLoss: 0.09368\tAccuracy: 0.60531\n",
            "Epoch: 32 [700/3200 (22%)]\tLoss: -0.01467\tAccuracy: 0.65653\n",
            "Epoch: 32 [750/3200 (23%)]\tLoss: 0.00640\tAccuracy: 0.63258\n",
            "Epoch: 32 [800/3200 (25%)]\tLoss: 0.02454\tAccuracy: 0.63187\n",
            "Epoch: 32 [850/3200 (27%)]\tLoss: -0.21163\tAccuracy: 0.81163\n",
            "Epoch: 32 [900/3200 (28%)]\tLoss: 0.14558\tAccuracy: 0.59414\n",
            "Epoch: 32 [950/3200 (30%)]\tLoss: 0.08877\tAccuracy: 0.61119\n",
            "Epoch: 32 [1000/3200 (31%)]\tLoss: 0.07511\tAccuracy: 0.64396\n",
            "Epoch: 32 [1050/3200 (33%)]\tLoss: -0.14308\tAccuracy: 0.70277\n",
            "Epoch: 32 [1100/3200 (34%)]\tLoss: -0.15350\tAccuracy: 0.69404\n",
            "Epoch: 32 [1150/3200 (36%)]\tLoss: -0.06608\tAccuracy: 0.70596\n",
            "Epoch: 32 [1200/3200 (38%)]\tLoss: -0.02366\tAccuracy: 0.66232\n",
            "Epoch: 32 [1250/3200 (39%)]\tLoss: -0.10502\tAccuracy: 0.72391\n",
            "Epoch: 32 [1300/3200 (41%)]\tLoss: -0.11033\tAccuracy: 0.73021\n",
            "Epoch: 32 [1350/3200 (42%)]\tLoss: -0.00182\tAccuracy: 0.66050\n",
            "Epoch: 32 [1400/3200 (44%)]\tLoss: -0.09754\tAccuracy: 0.69580\n",
            "Epoch: 32 [1450/3200 (45%)]\tLoss: -0.01864\tAccuracy: 0.59826\n",
            "Epoch: 32 [1500/3200 (47%)]\tLoss: 0.10630\tAccuracy: 0.61336\n",
            "Epoch: 32 [1550/3200 (48%)]\tLoss: -0.25259\tAccuracy: 0.77264\n",
            "Epoch: 32 [1600/3200 (50%)]\tLoss: -0.02824\tAccuracy: 0.66729\n",
            "Epoch: 32 [1650/3200 (52%)]\tLoss: 0.16113\tAccuracy: 0.51880\n",
            "Epoch: 32 [1700/3200 (53%)]\tLoss: -0.16593\tAccuracy: 0.72469\n",
            "Epoch: 32 [1750/3200 (55%)]\tLoss: -0.18838\tAccuracy: 0.72824\n",
            "Epoch: 32 [1800/3200 (56%)]\tLoss: -0.04210\tAccuracy: 0.66143\n",
            "Epoch: 32 [1850/3200 (58%)]\tLoss: 0.10890\tAccuracy: 0.56632\n",
            "Epoch: 32 [1900/3200 (59%)]\tLoss: -0.02298\tAccuracy: 0.65852\n",
            "Epoch: 32 [1950/3200 (61%)]\tLoss: 0.17231\tAccuracy: 0.54056\n",
            "Epoch: 32 [2000/3200 (62%)]\tLoss: 0.08560\tAccuracy: 0.59381\n",
            "Epoch: 32 [2050/3200 (64%)]\tLoss: -0.07652\tAccuracy: 0.71314\n",
            "Epoch: 32 [2100/3200 (66%)]\tLoss: -0.01277\tAccuracy: 0.65001\n",
            "Epoch: 32 [2150/3200 (67%)]\tLoss: 0.27318\tAccuracy: 0.50625\n",
            "Epoch: 32 [2200/3200 (69%)]\tLoss: 0.08360\tAccuracy: 0.53664\n",
            "Epoch: 32 [2250/3200 (70%)]\tLoss: -0.16422\tAccuracy: 0.72090\n",
            "Epoch: 32 [2300/3200 (72%)]\tLoss: 0.01288\tAccuracy: 0.60539\n",
            "Epoch: 32 [2350/3200 (73%)]\tLoss: 0.26832\tAccuracy: 0.56738\n",
            "Epoch: 32 [2400/3200 (75%)]\tLoss: 0.05779\tAccuracy: 0.66153\n",
            "Epoch: 32 [2450/3200 (77%)]\tLoss: -0.15500\tAccuracy: 0.75483\n",
            "Epoch: 32 [2500/3200 (78%)]\tLoss: 0.03374\tAccuracy: 0.65005\n",
            "Epoch: 32 [2550/3200 (80%)]\tLoss: 0.07843\tAccuracy: 0.62141\n",
            "Epoch: 32 [2600/3200 (81%)]\tLoss: -0.02351\tAccuracy: 0.64068\n",
            "Epoch: 32 [2650/3200 (83%)]\tLoss: 0.19393\tAccuracy: 0.62202\n",
            "Epoch: 32 [2700/3200 (84%)]\tLoss: -0.07626\tAccuracy: 0.69075\n",
            "Epoch: 32 [2750/3200 (86%)]\tLoss: -0.03039\tAccuracy: 0.65040\n",
            "Epoch: 32 [2800/3200 (88%)]\tLoss: 0.25178\tAccuracy: 0.50537\n",
            "Epoch: 32 [2850/3200 (89%)]\tLoss: -0.01921\tAccuracy: 0.63017\n",
            "Epoch: 32 [2900/3200 (91%)]\tLoss: -0.04854\tAccuracy: 0.66713\n",
            "Epoch: 32 [2950/3200 (92%)]\tLoss: 0.02000\tAccuracy: 0.63892\n",
            "Epoch: 32 [3000/3200 (94%)]\tLoss: 0.10238\tAccuracy: 0.59717\n",
            "Epoch: 32 [3050/3200 (95%)]\tLoss: 0.10873\tAccuracy: 0.57026\n",
            "Epoch: 32 [3100/3200 (97%)]\tLoss: 0.00366\tAccuracy: 0.63618\n",
            "Epoch: 32 [3150/3200 (98%)]\tLoss: 0.16826\tAccuracy: 0.54822\n",
            "Epoch: 32 [3200/3200 (100%)]\tLoss: 0.05726\tAccuracy: 0.60141\n",
            "Train Loss: 0.01341 Train Accuracy: 0.63806\n",
            "Validation Loss: 0.71138 Validation Accuracy: 0.66125\n",
            "[0.0001]\n",
            "Epoch: 33 [50/3200 (2%)]\tLoss: -0.00797\tAccuracy: 0.62426\n",
            "Epoch: 33 [100/3200 (3%)]\tLoss: 0.08359\tAccuracy: 0.58616\n",
            "Epoch: 33 [150/3200 (5%)]\tLoss: 0.03181\tAccuracy: 0.64761\n",
            "Epoch: 33 [200/3200 (6%)]\tLoss: 0.02745\tAccuracy: 0.63936\n",
            "Epoch: 33 [250/3200 (8%)]\tLoss: 0.09906\tAccuracy: 0.59007\n",
            "Epoch: 33 [300/3200 (9%)]\tLoss: -0.07593\tAccuracy: 0.70970\n",
            "Epoch: 33 [350/3200 (11%)]\tLoss: 0.01517\tAccuracy: 0.64368\n",
            "Epoch: 33 [400/3200 (12%)]\tLoss: -0.00051\tAccuracy: 0.67973\n",
            "Epoch: 33 [450/3200 (14%)]\tLoss: 0.02511\tAccuracy: 0.61446\n",
            "Epoch: 33 [500/3200 (16%)]\tLoss: -0.00331\tAccuracy: 0.64098\n",
            "Epoch: 33 [550/3200 (17%)]\tLoss: -0.16501\tAccuracy: 0.72239\n",
            "Epoch: 33 [600/3200 (19%)]\tLoss: 0.07753\tAccuracy: 0.58180\n",
            "Epoch: 33 [650/3200 (20%)]\tLoss: -0.02940\tAccuracy: 0.64874\n",
            "Epoch: 33 [700/3200 (22%)]\tLoss: -0.03781\tAccuracy: 0.67703\n",
            "Epoch: 33 [750/3200 (23%)]\tLoss: -0.00960\tAccuracy: 0.64875\n",
            "Epoch: 33 [800/3200 (25%)]\tLoss: 0.07334\tAccuracy: 0.62585\n",
            "Epoch: 33 [850/3200 (27%)]\tLoss: -0.08525\tAccuracy: 0.68489\n",
            "Epoch: 33 [900/3200 (28%)]\tLoss: 0.10547\tAccuracy: 0.59378\n",
            "Epoch: 33 [950/3200 (30%)]\tLoss: 0.15611\tAccuracy: 0.55526\n",
            "Epoch: 33 [1000/3200 (31%)]\tLoss: 0.05794\tAccuracy: 0.61096\n",
            "Epoch: 33 [1050/3200 (33%)]\tLoss: 0.02319\tAccuracy: 0.61692\n",
            "Epoch: 33 [1100/3200 (34%)]\tLoss: -0.07267\tAccuracy: 0.71264\n",
            "Epoch: 33 [1150/3200 (36%)]\tLoss: 0.12246\tAccuracy: 0.57572\n",
            "Epoch: 33 [1200/3200 (38%)]\tLoss: 0.03402\tAccuracy: 0.64287\n",
            "Epoch: 33 [1250/3200 (39%)]\tLoss: 0.05820\tAccuracy: 0.59936\n",
            "Epoch: 33 [1300/3200 (41%)]\tLoss: 0.08073\tAccuracy: 0.57916\n",
            "Epoch: 33 [1350/3200 (42%)]\tLoss: 0.26303\tAccuracy: 0.53616\n",
            "Epoch: 33 [1400/3200 (44%)]\tLoss: 0.26554\tAccuracy: 0.51274\n",
            "Epoch: 33 [1450/3200 (45%)]\tLoss: 0.13727\tAccuracy: 0.55955\n",
            "Epoch: 33 [1500/3200 (47%)]\tLoss: -0.16997\tAccuracy: 0.70483\n",
            "Epoch: 33 [1550/3200 (48%)]\tLoss: -0.07725\tAccuracy: 0.69638\n",
            "Epoch: 33 [1600/3200 (50%)]\tLoss: -0.13502\tAccuracy: 0.70444\n",
            "Epoch: 33 [1650/3200 (52%)]\tLoss: 0.09232\tAccuracy: 0.58671\n",
            "Epoch: 33 [1700/3200 (53%)]\tLoss: 0.13162\tAccuracy: 0.56614\n",
            "Epoch: 33 [1750/3200 (55%)]\tLoss: 0.07855\tAccuracy: 0.60126\n",
            "Epoch: 33 [1800/3200 (56%)]\tLoss: 0.03782\tAccuracy: 0.64066\n",
            "Epoch: 33 [1850/3200 (58%)]\tLoss: 0.03901\tAccuracy: 0.61865\n",
            "Epoch: 33 [1900/3200 (59%)]\tLoss: 0.07977\tAccuracy: 0.57984\n",
            "Epoch: 33 [1950/3200 (61%)]\tLoss: 0.05270\tAccuracy: 0.60320\n",
            "Epoch: 33 [2000/3200 (62%)]\tLoss: -0.03509\tAccuracy: 0.63254\n",
            "Epoch: 33 [2050/3200 (64%)]\tLoss: 0.01349\tAccuracy: 0.64591\n",
            "Epoch: 33 [2100/3200 (66%)]\tLoss: -0.06530\tAccuracy: 0.66418\n",
            "Epoch: 33 [2150/3200 (67%)]\tLoss: 0.06476\tAccuracy: 0.59149\n",
            "Epoch: 33 [2200/3200 (69%)]\tLoss: 0.14084\tAccuracy: 0.59839\n",
            "Epoch: 33 [2250/3200 (70%)]\tLoss: -0.00141\tAccuracy: 0.62157\n",
            "Epoch: 33 [2300/3200 (72%)]\tLoss: 0.02709\tAccuracy: 0.63094\n",
            "Epoch: 33 [2350/3200 (73%)]\tLoss: 0.05344\tAccuracy: 0.56614\n",
            "Epoch: 33 [2400/3200 (75%)]\tLoss: -0.11937\tAccuracy: 0.71347\n",
            "Epoch: 33 [2450/3200 (77%)]\tLoss: -0.17033\tAccuracy: 0.74854\n",
            "Epoch: 33 [2500/3200 (78%)]\tLoss: -0.15369\tAccuracy: 0.73344\n",
            "Epoch: 33 [2550/3200 (80%)]\tLoss: 0.04495\tAccuracy: 0.65248\n",
            "Epoch: 33 [2600/3200 (81%)]\tLoss: 0.07326\tAccuracy: 0.60942\n",
            "Epoch: 33 [2650/3200 (83%)]\tLoss: 0.00403\tAccuracy: 0.63586\n",
            "Epoch: 33 [2700/3200 (84%)]\tLoss: -0.13094\tAccuracy: 0.68997\n",
            "Epoch: 33 [2750/3200 (86%)]\tLoss: -0.05097\tAccuracy: 0.65040\n",
            "Epoch: 33 [2800/3200 (88%)]\tLoss: 0.08830\tAccuracy: 0.56612\n",
            "Epoch: 33 [2850/3200 (89%)]\tLoss: -0.11587\tAccuracy: 0.69416\n",
            "Epoch: 33 [2900/3200 (91%)]\tLoss: -0.17054\tAccuracy: 0.72602\n",
            "Epoch: 33 [2950/3200 (92%)]\tLoss: -0.03684\tAccuracy: 0.67595\n",
            "Epoch: 33 [3000/3200 (94%)]\tLoss: -0.12736\tAccuracy: 0.71883\n",
            "Epoch: 33 [3050/3200 (95%)]\tLoss: -0.01460\tAccuracy: 0.62111\n",
            "Epoch: 33 [3100/3200 (97%)]\tLoss: -0.14356\tAccuracy: 0.66331\n",
            "Epoch: 33 [3150/3200 (98%)]\tLoss: -0.01577\tAccuracy: 0.63329\n",
            "Epoch: 33 [3200/3200 (100%)]\tLoss: -0.02609\tAccuracy: 0.62556\n",
            "Train Loss: 0.00799 Train Accuracy: 0.63550\n",
            "Validation Loss: 0.71412 Validation Accuracy: 0.64992\n",
            "[0.0001]\n",
            "Epoch: 34 [50/3200 (2%)]\tLoss: 0.02876\tAccuracy: 0.67070\n",
            "Epoch: 34 [100/3200 (3%)]\tLoss: 0.00491\tAccuracy: 0.67152\n",
            "Epoch: 34 [150/3200 (5%)]\tLoss: 0.15518\tAccuracy: 0.54382\n",
            "Epoch: 34 [200/3200 (6%)]\tLoss: 0.19662\tAccuracy: 0.50257\n",
            "Epoch: 34 [250/3200 (8%)]\tLoss: -0.15510\tAccuracy: 0.71525\n",
            "Epoch: 34 [300/3200 (9%)]\tLoss: 0.05241\tAccuracy: 0.62738\n",
            "Epoch: 34 [350/3200 (11%)]\tLoss: -0.04601\tAccuracy: 0.66604\n",
            "Epoch: 34 [400/3200 (12%)]\tLoss: -0.08632\tAccuracy: 0.64445\n",
            "Epoch: 34 [450/3200 (14%)]\tLoss: -0.00166\tAccuracy: 0.64033\n",
            "Epoch: 34 [500/3200 (16%)]\tLoss: -0.05431\tAccuracy: 0.61409\n",
            "Epoch: 34 [550/3200 (17%)]\tLoss: 0.20276\tAccuracy: 0.51540\n",
            "Epoch: 34 [600/3200 (19%)]\tLoss: 0.27086\tAccuracy: 0.49818\n",
            "Epoch: 34 [650/3200 (20%)]\tLoss: 0.01101\tAccuracy: 0.60801\n",
            "Epoch: 34 [700/3200 (22%)]\tLoss: 0.02716\tAccuracy: 0.60159\n",
            "Epoch: 34 [750/3200 (23%)]\tLoss: -0.09125\tAccuracy: 0.73023\n",
            "Epoch: 34 [800/3200 (25%)]\tLoss: 0.02925\tAccuracy: 0.66027\n",
            "Epoch: 34 [850/3200 (27%)]\tLoss: -0.02324\tAccuracy: 0.69813\n",
            "Epoch: 34 [900/3200 (28%)]\tLoss: 0.10248\tAccuracy: 0.55498\n",
            "Epoch: 34 [950/3200 (30%)]\tLoss: 0.14968\tAccuracy: 0.54774\n",
            "Epoch: 34 [1000/3200 (31%)]\tLoss: -0.04302\tAccuracy: 0.63980\n",
            "Epoch: 34 [1050/3200 (33%)]\tLoss: -0.07801\tAccuracy: 0.69551\n",
            "Epoch: 34 [1100/3200 (34%)]\tLoss: 0.20080\tAccuracy: 0.47837\n",
            "Epoch: 34 [1150/3200 (36%)]\tLoss: 0.09428\tAccuracy: 0.56362\n",
            "Epoch: 34 [1200/3200 (38%)]\tLoss: -0.12911\tAccuracy: 0.74789\n",
            "Epoch: 34 [1250/3200 (39%)]\tLoss: -0.12195\tAccuracy: 0.68157\n",
            "Epoch: 34 [1300/3200 (41%)]\tLoss: -0.10645\tAccuracy: 0.70579\n",
            "Epoch: 34 [1350/3200 (42%)]\tLoss: -0.16437\tAccuracy: 0.70342\n",
            "Epoch: 34 [1400/3200 (44%)]\tLoss: 0.09379\tAccuracy: 0.60587\n",
            "Epoch: 34 [1450/3200 (45%)]\tLoss: -0.05750\tAccuracy: 0.67420\n",
            "Epoch: 34 [1500/3200 (47%)]\tLoss: 0.08909\tAccuracy: 0.59001\n",
            "Epoch: 34 [1550/3200 (48%)]\tLoss: 0.01949\tAccuracy: 0.61755\n",
            "Epoch: 34 [1600/3200 (50%)]\tLoss: -0.02072\tAccuracy: 0.67967\n",
            "Epoch: 34 [1650/3200 (52%)]\tLoss: -0.08087\tAccuracy: 0.64095\n",
            "Epoch: 34 [1700/3200 (53%)]\tLoss: 0.05620\tAccuracy: 0.62083\n",
            "Epoch: 34 [1750/3200 (55%)]\tLoss: -0.04876\tAccuracy: 0.66581\n",
            "Epoch: 34 [1800/3200 (56%)]\tLoss: -0.19015\tAccuracy: 0.74803\n",
            "Epoch: 34 [1850/3200 (58%)]\tLoss: 0.14003\tAccuracy: 0.55800\n",
            "Epoch: 34 [1900/3200 (59%)]\tLoss: 0.01046\tAccuracy: 0.64702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cROYfWFQivC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.cpu()\n",
        "fig, axeslist = plt.subplots(ncols=5,nrows=1)\n",
        "\n",
        "x,y =train_dataset[100]\n",
        "axeslist.ravel()[4].imshow(x.detach().numpy().reshape(101,101,3))\n",
        "axeslist.ravel()[0].imshow(x.detach().numpy()[0],cmap='gray')\n",
        "print(x.shape)\n",
        "z = model(x.view(1,3,101,101))\n",
        "axeslist.ravel()[1].imshow(z.squeeze(0).detach().numpy(),cmap='gray')\n",
        "print(z.shape)\n",
        "def getImg(x):\n",
        "    x = x.view(1,3,101,101)\n",
        "    x = model(x).detach().squeeze(0).numpy()[0]\n",
        "    x = (x-x.mean()/(x.max()-x.min())) +1\n",
        "    a = np.expand_dims(x, axis = 2)\n",
        "    a = np.concatenate((a, a, a), axis = 2)\n",
        "    return a\n",
        "print(y.shape)\n",
        "predict = (F.sigmoid(z) > 0.5).detach().numpy().squeeze(0)\n",
        "axeslist.ravel()[3].imshow(predict,cmap='gray')\n",
        "\n",
        "\n",
        "# axeslist.ravel()[1].imshow(getImg(y),cmap='gray')\n",
        "\n",
        "axeslist.ravel()[2].imshow(y.detach().numpy(),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vro1Wre1jVSy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "|x = torch.randn(1,3,101,101)\n",
        "plt.imshow(x.numpy().squeeze(0)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EoJqaaExKjE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model,'TGSUNetModel.pt')\n",
        "uploaded = drive.CreateFile({'title': 'TGSUNetModel.pt'})\n",
        "uploaded.SetContentFile('TGSUNetModel.pt')\n",
        "uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EPGsTKVsxXwm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id': '14ivrIyqyeL5oFzQ-yLBN2F1JrSOeA-fY'})\n",
        "downloaded.GetContentFile('test.zip')\n",
        "with ZipFile(\"test.zip\", 'r') as z:\n",
        "  z.extractall()\n",
        "os.remove(\"test.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1YRChhpixaZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TGSSaltTestDataset(Dataset):\n",
        "    def __init__(self, image_dir,depth_csv,test_csv):\n",
        "        self.image_dir=image_dir\n",
        "        \n",
        "        depth=pd.read_csv(depth_csv)\n",
        "        depth[\"z\"]=(depth[\"z\"]-depth[\"z\"].min())/(depth[\"z\"].max()-depth[\"z\"].min())\n",
        "        \n",
        "        self.input = pd.read_csv(test_csv)\n",
        "        self.input = self.input.merge(depth,how=\"left\",on=\"id\")\n",
        "        \n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir,self.input.iloc[idx,0]+\".png\")\n",
        "        image = self.transform(Image.open(img_name))*self.input.iloc[idx,2]\n",
        "        return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1CoZ2ZFZyFFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dataset = TGSSaltTestDataset(\"test/images\",\"depths.csv\",\"test.csv\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Cyx-txnwXum",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict():\n",
        "    test_pred=torch.IntTensor(\n",
        "    model.eval()\n",
        "    for batch_idx, data in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        # forward\n",
        "        output = model(data)\n",
        "        predict = (F.sigmoid(output) > threshold).int()\n",
        "        test_pred=torch.cat((test_pred,pred.view(batch_size,101,101)),dim=0)\n",
        "        return test_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3bNyLN02yLn2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict=prediciton(test_loader)\n",
        "predict=predict.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xRC4rYuYySkY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rle_encode(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels = img.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Nq9-6hHyV-t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dataset.input.drop(\"z\",axis=1,inplace=True)\n",
        "for i in range(len(test_dataset)):\n",
        "    test_dataset.input[\"rle_mask\"][i]=rle_encode(predict[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ScpRh0ukyYyM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dataset.input.to_csv(\"submission.csv\",index=False)\n",
        "uploaded = drive.CreateFile({'title': 'submission.csv'})\n",
        "uploaded.SetContentFile('submission.csv')\n",
        "uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GvAlb7sjspQu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "from https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_model.py"
      ]
    },
    {
      "metadata": {
        "id": "6ZJgJYAKsoiy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            double_conv(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True,up_size=None):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        #  would be a nice idea if the upsampling could be learned too,\n",
        "        #  but my machine do not have enough memory to handle all those weights\n",
        "        if bilinear:\n",
        "            if up_size:\n",
        "                self.up = nn.Upsample(size= up_size, mode='bilinear', align_corners=True)\n",
        "            else:\n",
        "                self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffX = x1.size()[2] - x2.size()[2]\n",
        "        diffY = x1.size()[3] - x2.size()[3]\n",
        "        x2 = F.pad(x2, (diffX // 2 , int(diffX / 2),\n",
        "                        diffY // 2, int(diffY / 2)))\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aa1Q2zJBsyan",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes,debug=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.debug = debug\n",
        "        self.mix = nn.Conv3d(1, 10, 3, stride=1,padding=1)\n",
        "        self.inc = inconv(n_channels, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256,up_size = (12,12))\n",
        "        self.up2 = up(512, 128,up_size = (25,25))\n",
        "        self.up3 = up(256, 64,up_size = (50,50))\n",
        "        self.up4 = up(128, 64,up_size = (101,101))\n",
        "        self.outc = outconv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x.unsqueeze_(1)\n",
        "        if self.debug: print(x.shape)\n",
        "        x = self.mix(x)\n",
        "        if self.debug: print(x.shape)\n",
        "        x = x.view(-1,30,101,101)\n",
        "        x1 = self.inc(x)\n",
        "        if self.debug: print(x1.shape)\n",
        "        x2 = self.down1(x1)\n",
        "        if self.debug: print(x2.shape)\n",
        "        x3 = self.down2(x2)\n",
        "        if self.debug: print(x3.shape)\n",
        "        x4 = self.down3(x3)\n",
        "        if self.debug: print(x4.shape)\n",
        "        x5 = self.down4(x4)\n",
        "        if self.debug: print(x5.shape)\n",
        "        x = self.up1(x5, x4)\n",
        "        if self.debug: print(x.shape)\n",
        "        x = self.up2(x, x3)\n",
        "        if self.debug: print(x.shape)\n",
        "        x = self.up3(x, x2)\n",
        "        if self.debug: print(x.shape)\n",
        "        x = self.up4(x, x1)\n",
        "        if self.debug: print(x.shape)\n",
        "        x = self.outc(x)\n",
        "        if self.debug: print(x.shape)\n",
        "        return x.squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G68GNir2tAbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "81d5abc9-cb06-4a80-c755-6ac591547c5c"
      },
      "cell_type": "code",
      "source": [
        "model = UNet(30,1,debug=True)\n",
        "x = torch.randn(10,3,101,101)\n",
        "print(model(x).shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 1, 3, 101, 101])\n",
            "torch.Size([10, 10, 3, 101, 101])\n",
            "torch.Size([10, 64, 101, 101])\n",
            "torch.Size([10, 128, 50, 50])\n",
            "torch.Size([10, 256, 25, 25])\n",
            "torch.Size([10, 512, 12, 12])\n",
            "torch.Size([10, 512, 6, 6])\n",
            "torch.Size([10, 256, 12, 12])\n",
            "torch.Size([10, 128, 25, 25])\n",
            "torch.Size([10, 64, 50, 50])\n",
            "torch.Size([10, 64, 101, 101])\n",
            "torch.Size([10, 1, 101, 101])\n",
            "torch.Size([10, 101, 101])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9VTtLhXttOnv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}