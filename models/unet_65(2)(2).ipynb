{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet_65(2).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kKCZKCvxwcdH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install Pillow==4.0.0\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Opyd_G9mwXs4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from zipfile import ZipFile\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4vz255ihwoCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bVr6JddnBsG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "listed = drive.ListFile().GetList()\n",
        "for file in listed:\n",
        "    print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LW0AEY1twrbl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id': '11j1LyGLuq-HIHEgPNlzcxg0pO57rBA2y'})\n",
        "downloaded.GetContentFile('train.zip')\n",
        "with ZipFile(\"train.zip\", 'r') as z:\n",
        "    z.extractall()\n",
        "os.remove(\"train.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T05EtlovwXtF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TGSSaltTrainDataset(Dataset):\n",
        "    def __init__(self, image_dir,mask_dir,depth_csv,train_csv):\n",
        "        self.image_dir=image_dir\n",
        "        self.mask_dir=mask_dir\n",
        "        \n",
        "#         depth=pd.read_csv(depth_csv)\n",
        "#         depth[\"z\"]=(depth[\"z\"]-depth[\"z\"].min())/(depth[\"z\"].max()-depth[\"z\"].min())\n",
        "        self.filter = np.array([(0,-1,-1,-1),(1,0,0,0),(1,0,1,0),(0,1,0,1)])/8\n",
        "        self.input = pd.read_csv(train_csv)\n",
        "        self.input['z'] = (self.input['z']-self.input['z'].min())/(self.input['z'].max()-self.input['z'].min())\n",
        "        self.input.drop(['rle_mask'],axis=1,inplace=True)\n",
        "#         self.input = self.input.merge(depth,how=\"left\",on=\"id\")\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir,self.input.iloc[idx,0]+\".png\")\n",
        "        img = cv2.imread(img_name)\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        img = torch.tensor(img).view(101,101).float()\n",
        "      \n",
        "        mask_name = os.path.join(self.mask_dir,self.input.iloc[idx,0]+\".png\")\n",
        "        mask = cv2.imread(mask_name)\n",
        "        mask = cv2.cvtColor(mask,cv2.COLOR_BGR2GRAY)\n",
        "        mask = torch.tensor(mask).float()/255\n",
        "        depth = self.input.iloc[idx,1].reshape(1)\n",
        "        return img,mask,depth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bgQNyCiXwXtM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = TGSSaltTrainDataset(\"train/images\",\"train/masks\",\"depths.csv\",\"train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_nXF2HvVoig",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset.input = train_dataset.input[:200]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FgeizLO8VxbD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    uploaded = drive.CreateFile({'title': 'TGSUNet_epoch'+str(state['epoch'])+'.pt'})\n",
        "    uploaded.SetContentFile(filename)\n",
        "    uploaded.Upload()\n",
        "def load_checkpoint(args):\n",
        "     \n",
        "    if os.path.isfile(args):\n",
        "        print(\"=> loading checkpoint '{}'\".format(args))\n",
        "        checkpoint = torch.load(args)\n",
        "        epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "              .format(args, checkpoint['epoch']))\n",
        "    else:\n",
        "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZJgJYAKsoiy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            double_conv(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class up(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, bilinear=True,up_size=None,padding=None):\n",
        "        super(up, self).__init__()\n",
        "\n",
        "        #  would be a nice idea if the upsampling could be learned too,\n",
        "        #  but my machine do not have enough memory to handle all those weights\n",
        "        if bilinear:\n",
        "            if up_size:\n",
        "                self.up = nn.Upsample(size= up_size, mode='bilinear', align_corners=True)\n",
        "            else:\n",
        "                self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            if padding:\n",
        "                self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2,output_padding=padding)\n",
        "            else:\n",
        "                self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
        "\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffX = x1.size()[2] - x2.size()[2]\n",
        "        diffY = x1.size()[3] - x2.size()[3]\n",
        "        x2 = F.pad(x2, (diffX // 2 , int(diffX / 2),\n",
        "                        diffY // 2, int(diffY / 2)))\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class outconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(outconv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "class conv3d(nn.Module):\n",
        "    '''\n",
        "    Takes a image with given number of channels and performs 3d convolution and then returns the image as 2d\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(conv3d, self).__init__()\n",
        "        self.conv1 = nn.Conv3d(1, 4, 2,stride=2,padding=1)\n",
        "        self.conv2 = nn.Conv3d(4, 16 ,4,stride=2,padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x.unsqueeze_(1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(-1,512,6,6)\n",
        "        return x\n",
        "\n",
        "class DN(nn.Module):\n",
        "    '''\n",
        "    @IN\n",
        "    img: A tensor representing the grayscaled image; shape:[batch_size,1,101,101]\n",
        "    d: The z index of the image\n",
        "    \n",
        "    @OUT\n",
        "    shape:[batch_size,1,101,101] tensor representing the features found by kernel(3*3) created from depth value\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(DN,self).__init__()\n",
        "        self.layer1 = nn.Sequential(nn.Linear(4,9,bias=False),\n",
        "                                   nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(nn.Linear(9,9,bias=True),\n",
        "                                   nn.Sigmoid())\n",
        "        self.conv1 = nn.Conv2d(1,1,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "        self.non_linear1 = nn.ReLU()\n",
        "    def forward(self,x,d):\n",
        "        d= d.view(1)\n",
        "        ker = torch.tensor([d,d**2,d**3,1]).float().cuda()\n",
        "#         print(ker)\n",
        "        ker = self.layer1(ker)\n",
        "        ker = self.layer2(ker).view(1,1,3,3)\n",
        "        self.conv1.weight = nn.Parameter(ker)\n",
        "        x = self.non_linear1(self.conv1(x))\n",
        "        return x\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self,debug=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.debug = debug\n",
        "        self.inc = inconv(1, 64)\n",
        "        self.down1 = down(64, 128)\n",
        "        self.down2 = down(128, 256)\n",
        "        self.down3 = down(256, 512)\n",
        "        self.down4 = down(512, 512)\n",
        "        self.up1 = up(1024, 256,up_size = (12,12),bilinear=False)\n",
        "        self.up2 = up(512, 128,up_size = (25,25))\n",
        "        self.up3 = up(256, 64,up_size = (50,50),bilinear=False)\n",
        "        self.up4 = up(128, 64,up_size = (101,101))\n",
        "        self.outc = outconv(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x.unsqueeze_(1)\n",
        "        if self.debug: print(x.shape)\n",
        "        x1 = self.inc(x)\n",
        "        if self.debug: print(x1.shape)\n",
        "        x2 = self.down1(x1)\n",
        "        if self.debug: print(x2.shape)\n",
        "        x3 = self.down2(x2)\n",
        "        if self.debug: print(x3.shape)\n",
        "        x4 = self.down3(x3)\n",
        "        if self.debug: print(x4.shape)\n",
        "        x5 = self.down4(x4)\n",
        "        if self.debug: print(x5.shape)\n",
        "        if self.debug: print('before up')\n",
        "        x = self.up1(x5, x4)\n",
        "        if self.debug: print(x.shape)\n",
        "        x = self.up2(x, x3)\n",
        "        if self.debug: print(x.shape)\n",
        "        x = self.up3(x, x2)\n",
        "        if self.debug: print(x.shape)\n",
        "        x = self.up4(x, x1)\n",
        "        if self.debug: print(x.shape)\n",
        "        x = self.outc(x)\n",
        "        if self.debug: print(x.shape)\n",
        "        return x.squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aa1Q2zJBsyan",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class UDNet(nn.Module):\n",
        "    def __init__(self,debug=False):\n",
        "        super(UDNet,self).__init__()\n",
        "#         self.dn = DN()\n",
        "        self.un1 = UNet(debug=debug)\n",
        "        self.un2 = UNet(debug=debug)\n",
        "    def forward(self,x,d):\n",
        "        x = self.un1(x)\n",
        "#         x.unsqueeze_(1)\n",
        "#         x = self.dn(x,d)\n",
        "#         x.squeeze_(1)\n",
        "        x = self.un2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G68GNir2tAbI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = UDNet(debug=False).cuda()\n",
        "x = torch.randn(10,101,101).cuda()\n",
        "print(model(x,torch.tensor(train_dataset[1][2][0])).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhmehDI4V56C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size)\n",
        "validation_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HPrgWtu2wXtU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "validation_split = 0.1\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "validation_sampler = SubsetRandomSampler(val_indices)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ILpmwaDtwXth",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BinaryCrossEntropyLoss2d(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        \"\"\"\n",
        "        Binary cross entropy loss 2D\n",
        "        Args:\n",
        "            weight:\n",
        "            size_average:\n",
        "        \"\"\"\n",
        "        super(BinaryCrossEntropyLoss2d, self).__init__()\n",
        "        self.bce_loss = nn.BCELoss(weight, size_average)\n",
        "        if torch.cuda.is_available():\n",
        "            self.bce_loss = self.bce_loss.cuda()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = F.sigmoid(pred)\n",
        "        pred = pred.view(-1)  # Flatten\n",
        "        target = target.view(-1)  # Flatten\n",
        "        return self.bce_loss(pred, target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cLvCr3IQwXtm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "    def forward(self, pred, target):\n",
        "        smooth = 1\n",
        "        num = target.size(0)\n",
        "        pred = F.sigmoid(pred)\n",
        "        pred = pred.view(num, -1)\n",
        "        target = target.view(num, -1)\n",
        "        intersection = (pred * target)\n",
        "        score = 2. * (intersection.sum(1) + smooth) / (pred.sum(1) + target.sum(1) + smooth)\n",
        "        score = 1 - score.sum() / num\n",
        "        return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9CU7PcdGwXtt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_coeff(pred, target):\n",
        "    smooth = 1.\n",
        "    num = target.size(0)\n",
        "    pred = pred.view(num, -1)  # Flatten\n",
        "    target = target.view(num, -1)  # Flatten\n",
        "    intersection = (pred * target)\n",
        "    score = (2. * intersection.sum(1) + smooth).float() / (pred.sum(1) + target.sum(1) + smooth).float()\n",
        "    return score.sum()/num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcxIxXq5wXtz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return 0.5*BinaryCrossEntropyLoss2d()(y_true, y_pred)-dice_coeff(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OL9OQNTawXt-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=UDNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "# exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "krdeJDd5wXuL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate(threshold):\n",
        "    total_loss = 0\n",
        "    accuracy = 0\n",
        "    model.eval()\n",
        "    for batch_idx, (data,target,d) in enumerate(validation_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        # forward\n",
        "        output = model(data,d)\n",
        "        predict = ((output) > threshold).float()\n",
        "        # backward + optimize\n",
        "        loss = criterion(predict, target)\n",
        "        # print statistics\n",
        "        accuracy += dice_coeff(predict, target).item()\n",
        "        total_loss+=loss.item()\n",
        "    print('Validation Loss: {:.5f} Validation Accuracy: {:.5f}'.format(total_loss*batch_size/len(val_indices),accuracy*batch_size/len(val_indices)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ci5neK7wXuU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def train(threshold):\n",
        "    epoch=11\n",
        "    \n",
        "#     yyy = []\n",
        "#     h1, = plt.plot(range(len(yyy)), yyy)\n",
        "#     plt.rcParams[\"figure.figsize\"] = [20,8]\n",
        "#     plt.show()\n",
        "    while True:\n",
        "        if epoch%10==1:\n",
        "            save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer' : optimizer.state_dict(),\n",
        "            },filename='model_state'+str(epoch)+'.tar')\n",
        "        total_loss = 0\n",
        "        total_accuracy = 0\n",
        "        model.train()\n",
        "        if epoch == 40:\n",
        "            adjust_learning_rate(optimizer,0.01)\n",
        "        if epoch == 100:\n",
        "            adjust_learning_rate(optimizer,0.001)\n",
        "        if epoch == 150:\n",
        "            torch.save(model,'TGSUNetsimple231.pt')\n",
        "            uploaded = drive.CreateFile({'title': 'TGSUNetsimple231.pt'})\n",
        "            uploaded.SetContentFile('TGSUNetsimple231.pt')\n",
        "            uploaded.Upload()\n",
        "#         adjust_learning_rate(optimizer,0.01)\n",
        "#         exp_lr_scheduler.step()\n",
        "#         print(exp_lr_scheduler.get_lr())\n",
        "        for batch_idx, (data,target,d) in enumerate(train_loader):\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "                target = target.cuda()\n",
        "            # forward\n",
        "            output = model(data,d)\n",
        "            predict = ((output>(1-threshold)) * (output<(1+threshold))).float()\n",
        "            # backward + optimize\n",
        "            loss = criterion(output, target)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # print statistics\n",
        "            accuracy = dice_coeff(predict, target)\n",
        "            \n",
        "#             plt.show()\n",
        "            total_accuracy+=accuracy\n",
        "            total_loss+=loss\n",
        "            if batch_idx%5 == 0:\n",
        "#                 yyy.append(accuracy)\n",
        "#                 clear_output(wait=False)\n",
        "#                 h1, = plt.plot(range(len(yyy)), yyy)\n",
        "#                 plt.show()\n",
        "                print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.5f}\\tAccuracy: {:.5f}'.format(epoch, (batch_idx + 1) * len(data), len(train_indices),100*(batch_idx + 1)* len(data) / len(train_indices), loss.item(),accuracy))\n",
        "#                 print(str(batch_idx/len(train_indices)*100)+'% completed')\n",
        "    \n",
        "#              print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.5f}\\tAccuracy: {:.5f}'.format(epoch, (batch_idx + 1) * len(data), len(train_indices),100*(batch_idx + 1)* len(data) / len(train_indices), total_loss.item(),accuracy))\n",
        "        print('Epoch: {} Train Loss: {:.5f} Train Accuracy: {:.5f}'.format(epoch,total_loss.item()*batch_size/len(train_dataset),total_accuracy.item()*batch_size/len(train_dataset)))\n",
        "        validate(threshold)\n",
        "        epoch+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1XQF7jq5wXud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 10137
        },
        "outputId": "d5e888ad-b410-4bb7-d8e9-8cf1fd780ae5"
      },
      "cell_type": "code",
      "source": [
        "model.cuda()\n",
        "train(0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11 [20/14400 (0%)]\tLoss: 0.06404\tAccuracy: 0.78136\n",
            "Epoch: 11 [120/14400 (1%)]\tLoss: 0.05085\tAccuracy: 0.79027\n",
            "Epoch: 11 [220/14400 (2%)]\tLoss: 0.05020\tAccuracy: 0.73139\n",
            "Epoch: 11 [320/14400 (2%)]\tLoss: 0.05929\tAccuracy: 0.75505\n",
            "Epoch: 11 [420/14400 (3%)]\tLoss: 0.04565\tAccuracy: 0.78064\n",
            "Epoch: 11 [520/14400 (4%)]\tLoss: 0.09935\tAccuracy: 0.76203\n",
            "Epoch: 11 [620/14400 (4%)]\tLoss: 0.08322\tAccuracy: 0.75906\n",
            "Epoch: 11 [720/14400 (5%)]\tLoss: 0.08159\tAccuracy: 0.55677\n",
            "Epoch: 11 [820/14400 (6%)]\tLoss: 0.06906\tAccuracy: 0.65195\n",
            "Epoch: 11 [920/14400 (6%)]\tLoss: 0.04206\tAccuracy: 0.63890\n",
            "Epoch: 11 [1020/14400 (7%)]\tLoss: 0.02397\tAccuracy: 0.87199\n",
            "Epoch: 11 [1120/14400 (8%)]\tLoss: 0.07183\tAccuracy: 0.74393\n",
            "Epoch: 11 [1220/14400 (8%)]\tLoss: 0.02681\tAccuracy: 0.70762\n",
            "Epoch: 11 [1320/14400 (9%)]\tLoss: 0.04694\tAccuracy: 0.83213\n",
            "Epoch: 11 [1420/14400 (10%)]\tLoss: 0.07269\tAccuracy: 0.67347\n",
            "Epoch: 11 [1520/14400 (11%)]\tLoss: 0.02582\tAccuracy: 0.85388\n",
            "Epoch: 11 [1620/14400 (11%)]\tLoss: 0.08800\tAccuracy: 0.53320\n",
            "Epoch: 11 [1720/14400 (12%)]\tLoss: 0.04780\tAccuracy: 0.89462\n",
            "Epoch: 11 [1820/14400 (13%)]\tLoss: 0.08792\tAccuracy: 0.55618\n",
            "Epoch: 11 [1920/14400 (13%)]\tLoss: 0.05757\tAccuracy: 0.68027\n",
            "Epoch: 11 [2020/14400 (14%)]\tLoss: 0.04669\tAccuracy: 0.79471\n",
            "Epoch: 11 [2120/14400 (15%)]\tLoss: 0.04388\tAccuracy: 0.77678\n",
            "Epoch: 11 [2220/14400 (15%)]\tLoss: 0.03618\tAccuracy: 0.81510\n",
            "Epoch: 11 [2320/14400 (16%)]\tLoss: 0.12996\tAccuracy: 0.67267\n",
            "Epoch: 11 [2420/14400 (17%)]\tLoss: 0.09462\tAccuracy: 0.70603\n",
            "Epoch: 11 [2520/14400 (18%)]\tLoss: 0.04680\tAccuracy: 0.82108\n",
            "Epoch: 11 [2620/14400 (18%)]\tLoss: 0.04652\tAccuracy: 0.75726\n",
            "Epoch: 11 [2720/14400 (19%)]\tLoss: 0.02488\tAccuracy: 0.85220\n",
            "Epoch: 11 [2820/14400 (20%)]\tLoss: 0.05720\tAccuracy: 0.76707\n",
            "Epoch: 11 [2920/14400 (20%)]\tLoss: 0.02878\tAccuracy: 0.83936\n",
            "Epoch: 11 [3020/14400 (21%)]\tLoss: 0.07954\tAccuracy: 0.78190\n",
            "Epoch: 11 [3120/14400 (22%)]\tLoss: 0.04337\tAccuracy: 0.80853\n",
            "Epoch: 11 [3220/14400 (22%)]\tLoss: 0.09170\tAccuracy: 0.76912\n",
            "Epoch: 11 [3320/14400 (23%)]\tLoss: 0.04001\tAccuracy: 0.89822\n",
            "Epoch: 11 [3420/14400 (24%)]\tLoss: 0.09109\tAccuracy: 0.59931\n",
            "Epoch: 11 [3520/14400 (24%)]\tLoss: 0.02890\tAccuracy: 0.82043\n",
            "Epoch: 11 [3620/14400 (25%)]\tLoss: 0.02225\tAccuracy: 0.82065\n",
            "Epoch: 11 [3720/14400 (26%)]\tLoss: 0.07984\tAccuracy: 0.67449\n",
            "Epoch: 11 [3820/14400 (27%)]\tLoss: 0.07098\tAccuracy: 0.66225\n",
            "Epoch: 11 [3920/14400 (27%)]\tLoss: 0.03707\tAccuracy: 0.81947\n",
            "Epoch: 11 [4020/14400 (28%)]\tLoss: 0.07527\tAccuracy: 0.65339\n",
            "Epoch: 11 [4120/14400 (29%)]\tLoss: 0.07451\tAccuracy: 0.81013\n",
            "Epoch: 11 [4220/14400 (29%)]\tLoss: 0.05820\tAccuracy: 0.73250\n",
            "Epoch: 11 [4320/14400 (30%)]\tLoss: 0.06756\tAccuracy: 0.31105\n",
            "Epoch: 11 [4420/14400 (31%)]\tLoss: 0.04335\tAccuracy: 0.77691\n",
            "Epoch: 11 [4520/14400 (31%)]\tLoss: 0.01995\tAccuracy: 0.74726\n",
            "Epoch: 11 [4620/14400 (32%)]\tLoss: 0.13132\tAccuracy: 0.63143\n",
            "Epoch: 11 [4720/14400 (33%)]\tLoss: 0.02170\tAccuracy: 0.91404\n",
            "Epoch: 11 [4820/14400 (33%)]\tLoss: 0.04451\tAccuracy: 0.79699\n",
            "Epoch: 11 [4920/14400 (34%)]\tLoss: 0.03715\tAccuracy: 0.65399\n",
            "Epoch: 11 [5020/14400 (35%)]\tLoss: 0.01946\tAccuracy: 0.86798\n",
            "Epoch: 11 [5120/14400 (36%)]\tLoss: 0.09100\tAccuracy: 0.56332\n",
            "Epoch: 11 [5220/14400 (36%)]\tLoss: 0.02608\tAccuracy: 0.71609\n",
            "Epoch: 11 [5320/14400 (37%)]\tLoss: 0.08302\tAccuracy: 0.60570\n",
            "Epoch: 11 [5420/14400 (38%)]\tLoss: 0.06708\tAccuracy: 0.73083\n",
            "Epoch: 11 [5520/14400 (38%)]\tLoss: 0.06881\tAccuracy: 0.65335\n",
            "Epoch: 11 [5620/14400 (39%)]\tLoss: 0.04412\tAccuracy: 0.72109\n",
            "Epoch: 11 [5720/14400 (40%)]\tLoss: 0.04597\tAccuracy: 0.65515\n",
            "Epoch: 11 [5820/14400 (40%)]\tLoss: 0.06722\tAccuracy: 0.53963\n",
            "Epoch: 11 [5920/14400 (41%)]\tLoss: 0.05157\tAccuracy: 0.70061\n",
            "Epoch: 11 [6020/14400 (42%)]\tLoss: 0.06513\tAccuracy: 0.81854\n",
            "Epoch: 11 [6120/14400 (42%)]\tLoss: 0.03705\tAccuracy: 0.78426\n",
            "Epoch: 11 [6220/14400 (43%)]\tLoss: 0.05277\tAccuracy: 0.76418\n",
            "Epoch: 11 [6320/14400 (44%)]\tLoss: 0.07249\tAccuracy: 0.75883\n",
            "Epoch: 11 [6420/14400 (45%)]\tLoss: 0.03369\tAccuracy: 0.76381\n",
            "Epoch: 11 [6520/14400 (45%)]\tLoss: 0.02017\tAccuracy: 0.81398\n",
            "Epoch: 11 [6620/14400 (46%)]\tLoss: 0.07321\tAccuracy: 0.74360\n",
            "Epoch: 11 [6720/14400 (47%)]\tLoss: 0.03937\tAccuracy: 0.71903\n",
            "Epoch: 11 [6820/14400 (47%)]\tLoss: 0.01066\tAccuracy: 0.87531\n",
            "Epoch: 11 [6920/14400 (48%)]\tLoss: 0.05316\tAccuracy: 0.75194\n",
            "Epoch: 11 [7020/14400 (49%)]\tLoss: 0.04636\tAccuracy: 0.77766\n",
            "Epoch: 11 [7120/14400 (49%)]\tLoss: 0.04613\tAccuracy: 0.84271\n",
            "Epoch: 11 [7220/14400 (50%)]\tLoss: 0.10653\tAccuracy: 0.70551\n",
            "Epoch: 11 [7320/14400 (51%)]\tLoss: 0.03012\tAccuracy: 0.85215\n",
            "Epoch: 11 [7420/14400 (52%)]\tLoss: 0.03008\tAccuracy: 0.70066\n",
            "Epoch: 11 [7520/14400 (52%)]\tLoss: 0.02242\tAccuracy: 0.79997\n",
            "Epoch: 11 [7620/14400 (53%)]\tLoss: 0.06744\tAccuracy: 0.64565\n",
            "Epoch: 11 [7720/14400 (54%)]\tLoss: 0.02973\tAccuracy: 0.84074\n",
            "Epoch: 11 [7820/14400 (54%)]\tLoss: 0.01905\tAccuracy: 0.82567\n",
            "Epoch: 11 [7920/14400 (55%)]\tLoss: 0.03497\tAccuracy: 0.83339\n",
            "Epoch: 11 [8020/14400 (56%)]\tLoss: 0.10357\tAccuracy: 0.60295\n",
            "Epoch: 11 [8120/14400 (56%)]\tLoss: 0.07033\tAccuracy: 0.62479\n",
            "Epoch: 11 [8220/14400 (57%)]\tLoss: 0.07049\tAccuracy: 0.77553\n",
            "Epoch: 11 [8320/14400 (58%)]\tLoss: 0.08458\tAccuracy: 0.66932\n",
            "Epoch: 11 [8420/14400 (58%)]\tLoss: 0.05611\tAccuracy: 0.34712\n",
            "Epoch: 11 [8520/14400 (59%)]\tLoss: 0.03477\tAccuracy: 0.61159\n",
            "Epoch: 11 [8620/14400 (60%)]\tLoss: 0.05213\tAccuracy: 0.83357\n",
            "Epoch: 11 [8720/14400 (61%)]\tLoss: 0.04335\tAccuracy: 0.57132\n",
            "Epoch: 11 [8820/14400 (61%)]\tLoss: 0.02960\tAccuracy: 0.75813\n",
            "Epoch: 11 [8920/14400 (62%)]\tLoss: 0.04409\tAccuracy: 0.65707\n",
            "Epoch: 11 [9020/14400 (63%)]\tLoss: 0.08066\tAccuracy: 0.82349\n",
            "Epoch: 11 [9120/14400 (63%)]\tLoss: 0.02168\tAccuracy: 0.81671\n",
            "Epoch: 11 [9220/14400 (64%)]\tLoss: 0.02964\tAccuracy: 0.45102\n",
            "Epoch: 11 [9320/14400 (65%)]\tLoss: 0.06025\tAccuracy: 0.65594\n",
            "Epoch: 11 [9420/14400 (65%)]\tLoss: 0.07280\tAccuracy: 0.25073\n",
            "Epoch: 11 [9520/14400 (66%)]\tLoss: 0.07743\tAccuracy: 0.56312\n",
            "Epoch: 11 [9620/14400 (67%)]\tLoss: 0.04159\tAccuracy: 0.67949\n",
            "Epoch: 11 [9720/14400 (68%)]\tLoss: 0.04204\tAccuracy: 0.86983\n",
            "Epoch: 11 [9820/14400 (68%)]\tLoss: 0.09421\tAccuracy: 0.68193\n",
            "Epoch: 11 [9920/14400 (69%)]\tLoss: 0.02362\tAccuracy: 0.79508\n",
            "Epoch: 11 [10020/14400 (70%)]\tLoss: 0.04359\tAccuracy: 0.70441\n",
            "Epoch: 11 [10120/14400 (70%)]\tLoss: 0.02877\tAccuracy: 0.89022\n",
            "Epoch: 11 [10220/14400 (71%)]\tLoss: 0.04780\tAccuracy: 0.71437\n",
            "Epoch: 11 [10320/14400 (72%)]\tLoss: 0.08260\tAccuracy: 0.70396\n",
            "Epoch: 11 [10420/14400 (72%)]\tLoss: 0.01902\tAccuracy: 0.67064\n",
            "Epoch: 11 [10520/14400 (73%)]\tLoss: 0.02104\tAccuracy: 0.84067\n",
            "Epoch: 11 [10620/14400 (74%)]\tLoss: 0.07618\tAccuracy: 0.63275\n",
            "Epoch: 11 [10720/14400 (74%)]\tLoss: 0.04010\tAccuracy: 0.50963\n",
            "Epoch: 11 [10820/14400 (75%)]\tLoss: 0.06939\tAccuracy: 0.67492\n",
            "Epoch: 11 [10920/14400 (76%)]\tLoss: 0.04905\tAccuracy: 0.71453\n",
            "Epoch: 11 [11020/14400 (77%)]\tLoss: 0.07135\tAccuracy: 0.70314\n",
            "Epoch: 11 [11120/14400 (77%)]\tLoss: 0.04421\tAccuracy: 0.65270\n",
            "Epoch: 11 [11220/14400 (78%)]\tLoss: 0.07629\tAccuracy: 0.61065\n",
            "Epoch: 11 [11320/14400 (79%)]\tLoss: 0.05855\tAccuracy: 0.78351\n",
            "Epoch: 11 [11420/14400 (79%)]\tLoss: 0.17170\tAccuracy: 0.60539\n",
            "Epoch: 11 [11520/14400 (80%)]\tLoss: 0.04041\tAccuracy: 0.75806\n",
            "Epoch: 11 [11620/14400 (81%)]\tLoss: 0.05540\tAccuracy: 0.62194\n",
            "Epoch: 11 [11720/14400 (81%)]\tLoss: 0.08660\tAccuracy: 0.67772\n",
            "Epoch: 11 [11820/14400 (82%)]\tLoss: 0.03203\tAccuracy: 0.83647\n",
            "Epoch: 11 [11920/14400 (83%)]\tLoss: 0.07284\tAccuracy: 0.75532\n",
            "Epoch: 11 [12020/14400 (83%)]\tLoss: 0.01986\tAccuracy: 0.93889\n",
            "Epoch: 11 [12120/14400 (84%)]\tLoss: 0.01573\tAccuracy: 0.82955\n",
            "Epoch: 11 [12220/14400 (85%)]\tLoss: 0.01780\tAccuracy: 0.77007\n",
            "Epoch: 11 [12320/14400 (86%)]\tLoss: 0.03520\tAccuracy: 0.71747\n",
            "Epoch: 11 [12420/14400 (86%)]\tLoss: 0.03280\tAccuracy: 0.76175\n",
            "Epoch: 11 [12520/14400 (87%)]\tLoss: 0.03720\tAccuracy: 0.74215\n",
            "Epoch: 11 [12620/14400 (88%)]\tLoss: 0.08645\tAccuracy: 0.67567\n",
            "Epoch: 11 [12720/14400 (88%)]\tLoss: 0.05644\tAccuracy: 0.79165\n",
            "Epoch: 11 [12820/14400 (89%)]\tLoss: 0.03460\tAccuracy: 0.42304\n",
            "Epoch: 11 [12920/14400 (90%)]\tLoss: 0.08388\tAccuracy: 0.51905\n",
            "Epoch: 11 [13020/14400 (90%)]\tLoss: 0.08391\tAccuracy: 0.35114\n",
            "Epoch: 11 [13120/14400 (91%)]\tLoss: 0.11136\tAccuracy: 0.39686\n",
            "Epoch: 11 [13220/14400 (92%)]\tLoss: 0.09861\tAccuracy: 0.34621\n",
            "Epoch: 11 [13320/14400 (92%)]\tLoss: 0.04990\tAccuracy: 0.78584\n",
            "Epoch: 11 [13420/14400 (93%)]\tLoss: 0.06455\tAccuracy: 0.68352\n",
            "Epoch: 11 [13520/14400 (94%)]\tLoss: 0.03209\tAccuracy: 0.73130\n",
            "Epoch: 11 [13620/14400 (95%)]\tLoss: 0.06323\tAccuracy: 0.79472\n",
            "Epoch: 11 [13720/14400 (95%)]\tLoss: 0.03177\tAccuracy: 0.60991\n",
            "Epoch: 11 [13820/14400 (96%)]\tLoss: 0.10567\tAccuracy: 0.61782\n",
            "Epoch: 11 [13920/14400 (97%)]\tLoss: 0.15359\tAccuracy: 0.44843\n",
            "Epoch: 11 [14020/14400 (97%)]\tLoss: 0.06736\tAccuracy: 0.45174\n",
            "Epoch: 11 [14120/14400 (98%)]\tLoss: 0.02311\tAccuracy: 0.87265\n",
            "Epoch: 11 [14220/14400 (99%)]\tLoss: 0.02221\tAccuracy: 0.75491\n",
            "Epoch: 11 [14320/14400 (99%)]\tLoss: 0.01879\tAccuracy: 0.85175\n",
            "Epoch: 11 Train Loss: 0.04700 Train Accuracy: 0.64892\n",
            "Validation Loss: 0.07031 Validation Accuracy: 0.73477\n",
            "Epoch: 12 [20/14400 (0%)]\tLoss: 0.08675\tAccuracy: 0.84884\n",
            "Epoch: 12 [120/14400 (1%)]\tLoss: 0.05316\tAccuracy: 0.70394\n",
            "Epoch: 12 [220/14400 (2%)]\tLoss: 0.03662\tAccuracy: 0.81340\n",
            "Epoch: 12 [320/14400 (2%)]\tLoss: 0.06462\tAccuracy: 0.83094\n",
            "Epoch: 12 [420/14400 (3%)]\tLoss: 0.02729\tAccuracy: 0.79227\n",
            "Epoch: 12 [520/14400 (4%)]\tLoss: 0.02402\tAccuracy: 0.74437\n",
            "Epoch: 12 [620/14400 (4%)]\tLoss: 0.01802\tAccuracy: 0.85028\n",
            "Epoch: 12 [720/14400 (5%)]\tLoss: 0.02916\tAccuracy: 0.72911\n",
            "Epoch: 12 [820/14400 (6%)]\tLoss: 0.08922\tAccuracy: 0.73150\n",
            "Epoch: 12 [920/14400 (6%)]\tLoss: 0.02667\tAccuracy: 0.72372\n",
            "Epoch: 12 [1020/14400 (7%)]\tLoss: 0.07174\tAccuracy: 0.75004\n",
            "Epoch: 12 [1120/14400 (8%)]\tLoss: 0.06982\tAccuracy: 0.50250\n",
            "Epoch: 12 [1220/14400 (8%)]\tLoss: 0.06590\tAccuracy: 0.73045\n",
            "Epoch: 12 [1320/14400 (9%)]\tLoss: 0.09038\tAccuracy: 0.67539\n",
            "Epoch: 12 [1420/14400 (10%)]\tLoss: 0.01949\tAccuracy: 0.81526\n",
            "Epoch: 12 [1520/14400 (11%)]\tLoss: 0.04146\tAccuracy: 0.59246\n",
            "Epoch: 12 [1620/14400 (11%)]\tLoss: 0.01882\tAccuracy: 0.66603\n",
            "Epoch: 12 [1720/14400 (12%)]\tLoss: 0.03386\tAccuracy: 0.91928\n",
            "Epoch: 12 [1820/14400 (13%)]\tLoss: 0.02830\tAccuracy: 0.87931\n",
            "Epoch: 12 [1920/14400 (13%)]\tLoss: 0.03409\tAccuracy: 0.68679\n",
            "Epoch: 12 [2020/14400 (14%)]\tLoss: 0.08770\tAccuracy: 0.53698\n",
            "Epoch: 12 [2120/14400 (15%)]\tLoss: 0.03293\tAccuracy: 0.71544\n",
            "Epoch: 12 [2220/14400 (15%)]\tLoss: 0.02960\tAccuracy: 0.84339\n",
            "Epoch: 12 [2320/14400 (16%)]\tLoss: 0.03479\tAccuracy: 0.77605\n",
            "Epoch: 12 [2420/14400 (17%)]\tLoss: 0.06779\tAccuracy: 0.72961\n",
            "Epoch: 12 [2520/14400 (18%)]\tLoss: 0.04554\tAccuracy: 0.84850\n",
            "Epoch: 12 [2620/14400 (18%)]\tLoss: 0.04952\tAccuracy: 0.74711\n",
            "Epoch: 12 [2720/14400 (19%)]\tLoss: 0.05414\tAccuracy: 0.63038\n",
            "Epoch: 12 [2820/14400 (20%)]\tLoss: 0.10158\tAccuracy: 0.50024\n",
            "Epoch: 12 [2920/14400 (20%)]\tLoss: 0.06430\tAccuracy: 0.78475\n",
            "Epoch: 12 [3020/14400 (21%)]\tLoss: 0.06087\tAccuracy: 0.74418\n",
            "Epoch: 12 [3120/14400 (22%)]\tLoss: 0.02010\tAccuracy: 0.71688\n",
            "Epoch: 12 [3220/14400 (22%)]\tLoss: 0.01614\tAccuracy: 0.87594\n",
            "Epoch: 12 [3320/14400 (23%)]\tLoss: 0.06110\tAccuracy: 0.75269\n",
            "Epoch: 12 [3420/14400 (24%)]\tLoss: 0.03284\tAccuracy: 0.87539\n",
            "Epoch: 12 [3520/14400 (24%)]\tLoss: 0.05446\tAccuracy: 0.30227\n",
            "Epoch: 12 [3620/14400 (25%)]\tLoss: 0.11467\tAccuracy: 0.66502\n",
            "Epoch: 12 [3720/14400 (26%)]\tLoss: 0.10631\tAccuracy: 0.25054\n",
            "Epoch: 12 [3820/14400 (27%)]\tLoss: 0.06391\tAccuracy: 0.79131\n",
            "Epoch: 12 [3920/14400 (27%)]\tLoss: 0.02025\tAccuracy: 0.77838\n",
            "Epoch: 12 [4020/14400 (28%)]\tLoss: 0.02099\tAccuracy: 0.77705\n",
            "Epoch: 12 [4120/14400 (29%)]\tLoss: 0.08899\tAccuracy: 0.80607\n",
            "Epoch: 12 [4220/14400 (29%)]\tLoss: 0.03482\tAccuracy: 0.80300\n",
            "Epoch: 12 [4320/14400 (30%)]\tLoss: 0.04869\tAccuracy: 0.80050\n",
            "Epoch: 12 [4420/14400 (31%)]\tLoss: 0.07196\tAccuracy: 0.74206\n",
            "Epoch: 12 [4520/14400 (31%)]\tLoss: 0.03538\tAccuracy: 0.83600\n",
            "Epoch: 12 [4620/14400 (32%)]\tLoss: 0.02201\tAccuracy: 0.79180\n",
            "Epoch: 12 [4720/14400 (33%)]\tLoss: 0.04105\tAccuracy: 0.85177\n",
            "Epoch: 12 [4820/14400 (33%)]\tLoss: 0.05337\tAccuracy: 0.82829\n",
            "Epoch: 12 [4920/14400 (34%)]\tLoss: 0.08929\tAccuracy: 0.67603\n",
            "Epoch: 12 [5020/14400 (35%)]\tLoss: 0.06087\tAccuracy: 0.81443\n",
            "Epoch: 12 [5120/14400 (36%)]\tLoss: 0.04027\tAccuracy: 0.71666\n",
            "Epoch: 12 [5220/14400 (36%)]\tLoss: 0.04878\tAccuracy: 0.73078\n",
            "Epoch: 12 [5320/14400 (37%)]\tLoss: 0.03738\tAccuracy: 0.85874\n",
            "Epoch: 12 [5420/14400 (38%)]\tLoss: 0.04482\tAccuracy: 0.74232\n",
            "Epoch: 12 [5520/14400 (38%)]\tLoss: 0.04481\tAccuracy: 0.82433\n",
            "Epoch: 12 [5620/14400 (39%)]\tLoss: 0.07186\tAccuracy: 0.78093\n",
            "Epoch: 12 [5720/14400 (40%)]\tLoss: 0.03829\tAccuracy: 0.82370\n",
            "Epoch: 12 [5820/14400 (40%)]\tLoss: 0.04772\tAccuracy: 0.78864\n",
            "Epoch: 12 [5920/14400 (41%)]\tLoss: 0.03306\tAccuracy: 0.70080\n",
            "Epoch: 12 [6020/14400 (42%)]\tLoss: 0.10743\tAccuracy: 0.62753\n",
            "Epoch: 12 [6120/14400 (42%)]\tLoss: 0.04256\tAccuracy: 0.64863\n",
            "Epoch: 12 [6220/14400 (43%)]\tLoss: 0.05414\tAccuracy: 0.35048\n",
            "Epoch: 12 [6320/14400 (44%)]\tLoss: 0.04758\tAccuracy: 0.84514\n",
            "Epoch: 12 [6420/14400 (45%)]\tLoss: 0.04950\tAccuracy: 0.77042\n",
            "Epoch: 12 [6520/14400 (45%)]\tLoss: 0.04152\tAccuracy: 0.75288\n",
            "Epoch: 12 [6620/14400 (46%)]\tLoss: 0.06627\tAccuracy: 0.75789\n",
            "Epoch: 12 [6720/14400 (47%)]\tLoss: 0.02924\tAccuracy: 0.73827\n",
            "Epoch: 12 [6820/14400 (47%)]\tLoss: 0.05691\tAccuracy: 0.63585\n",
            "Epoch: 12 [6920/14400 (48%)]\tLoss: 0.05948\tAccuracy: 0.70149\n",
            "Epoch: 12 [7020/14400 (49%)]\tLoss: 0.07119\tAccuracy: 0.48888\n",
            "Epoch: 12 [7120/14400 (49%)]\tLoss: 0.06445\tAccuracy: 0.68555\n",
            "Epoch: 12 [7220/14400 (50%)]\tLoss: 0.09596\tAccuracy: 0.66736\n",
            "Epoch: 12 [7320/14400 (51%)]\tLoss: 0.02173\tAccuracy: 0.82659\n",
            "Epoch: 12 [7420/14400 (52%)]\tLoss: 0.05082\tAccuracy: 0.51739\n",
            "Epoch: 12 [7520/14400 (52%)]\tLoss: 0.06484\tAccuracy: 0.72226\n",
            "Epoch: 12 [7620/14400 (53%)]\tLoss: 0.12594\tAccuracy: 0.28356\n",
            "Epoch: 12 [7720/14400 (54%)]\tLoss: 0.06835\tAccuracy: 0.66885\n",
            "Epoch: 12 [7820/14400 (54%)]\tLoss: 0.08686\tAccuracy: 0.65366\n",
            "Epoch: 12 [7920/14400 (55%)]\tLoss: 0.05537\tAccuracy: 0.74967\n",
            "Epoch: 12 [8020/14400 (56%)]\tLoss: 0.05780\tAccuracy: 0.71766\n",
            "Epoch: 12 [8120/14400 (56%)]\tLoss: 0.05526\tAccuracy: 0.69728\n",
            "Epoch: 12 [8220/14400 (57%)]\tLoss: 0.02392\tAccuracy: 0.76068\n",
            "Epoch: 12 [8320/14400 (58%)]\tLoss: 0.02308\tAccuracy: 0.79237\n",
            "Epoch: 12 [8420/14400 (58%)]\tLoss: 0.08830\tAccuracy: 0.65258\n",
            "Epoch: 12 [8520/14400 (59%)]\tLoss: 0.03005\tAccuracy: 0.85001\n",
            "Epoch: 12 [8620/14400 (60%)]\tLoss: 0.11736\tAccuracy: 0.30037\n",
            "Epoch: 12 [8720/14400 (61%)]\tLoss: 0.07169\tAccuracy: 0.68592\n",
            "Epoch: 12 [8820/14400 (61%)]\tLoss: 0.13081\tAccuracy: 0.41682\n",
            "Epoch: 12 [8920/14400 (62%)]\tLoss: 0.05441\tAccuracy: 0.55924\n",
            "Epoch: 12 [9020/14400 (63%)]\tLoss: 0.05271\tAccuracy: 0.63116\n",
            "Epoch: 12 [9120/14400 (63%)]\tLoss: 0.08666\tAccuracy: 0.55260\n",
            "Epoch: 12 [9220/14400 (64%)]\tLoss: 0.03572\tAccuracy: 0.81733\n",
            "Epoch: 12 [9320/14400 (65%)]\tLoss: 0.08521\tAccuracy: 0.68785\n",
            "Epoch: 12 [9420/14400 (65%)]\tLoss: 0.04933\tAccuracy: 0.77138\n",
            "Epoch: 12 [9520/14400 (66%)]\tLoss: 0.09595\tAccuracy: 0.30069\n",
            "Epoch: 12 [9620/14400 (67%)]\tLoss: 0.06112\tAccuracy: 0.75794\n",
            "Epoch: 12 [9720/14400 (68%)]\tLoss: 0.03783\tAccuracy: 0.78966\n",
            "Epoch: 12 [9820/14400 (68%)]\tLoss: 0.02485\tAccuracy: 0.77552\n",
            "Epoch: 12 [9920/14400 (69%)]\tLoss: 0.04758\tAccuracy: 0.68384\n",
            "Epoch: 12 [10020/14400 (70%)]\tLoss: 0.04420\tAccuracy: 0.85234\n",
            "Epoch: 12 [10120/14400 (70%)]\tLoss: 0.02205\tAccuracy: 0.86432\n",
            "Epoch: 12 [10220/14400 (71%)]\tLoss: 0.02015\tAccuracy: 0.95521\n",
            "Epoch: 12 [10320/14400 (72%)]\tLoss: 0.10217\tAccuracy: 0.70298\n",
            "Epoch: 12 [10420/14400 (72%)]\tLoss: 0.02861\tAccuracy: 0.74387\n",
            "Epoch: 12 [10520/14400 (73%)]\tLoss: 0.01899\tAccuracy: 0.81788\n",
            "Epoch: 12 [10620/14400 (74%)]\tLoss: 0.07810\tAccuracy: 0.80209\n",
            "Epoch: 12 [10720/14400 (74%)]\tLoss: 0.04681\tAccuracy: 0.75272\n",
            "Epoch: 12 [10820/14400 (75%)]\tLoss: 0.03322\tAccuracy: 0.86977\n",
            "Epoch: 12 [10920/14400 (76%)]\tLoss: 0.04214\tAccuracy: 0.79664\n",
            "Epoch: 12 [11020/14400 (77%)]\tLoss: 0.04520\tAccuracy: 0.68178\n",
            "Epoch: 12 [11120/14400 (77%)]\tLoss: 0.01468\tAccuracy: 0.83896\n",
            "Epoch: 12 [11220/14400 (78%)]\tLoss: 0.01562\tAccuracy: 0.87593\n",
            "Epoch: 12 [11320/14400 (79%)]\tLoss: 0.05466\tAccuracy: 0.85345\n",
            "Epoch: 12 [11420/14400 (79%)]\tLoss: 0.04616\tAccuracy: 0.55160\n",
            "Epoch: 12 [11520/14400 (80%)]\tLoss: 0.08069\tAccuracy: 0.80631\n",
            "Epoch: 12 [11620/14400 (81%)]\tLoss: 0.03413\tAccuracy: 0.56895\n",
            "Epoch: 12 [11720/14400 (81%)]\tLoss: 0.04424\tAccuracy: 0.82530\n",
            "Epoch: 12 [11820/14400 (82%)]\tLoss: 0.08688\tAccuracy: 0.71679\n",
            "Epoch: 12 [11920/14400 (83%)]\tLoss: 0.05549\tAccuracy: 0.71762\n",
            "Epoch: 12 [12020/14400 (83%)]\tLoss: 0.03707\tAccuracy: 0.68496\n",
            "Epoch: 12 [12120/14400 (84%)]\tLoss: 0.04742\tAccuracy: 0.65815\n",
            "Epoch: 12 [12220/14400 (85%)]\tLoss: 0.02569\tAccuracy: 0.66019\n",
            "Epoch: 12 [12320/14400 (86%)]\tLoss: 0.02406\tAccuracy: 0.79904\n",
            "Epoch: 12 [12420/14400 (86%)]\tLoss: 0.08517\tAccuracy: 0.64857\n",
            "Epoch: 12 [12520/14400 (87%)]\tLoss: 0.03042\tAccuracy: 0.78333\n",
            "Epoch: 12 [12620/14400 (88%)]\tLoss: 0.02409\tAccuracy: 0.92202\n",
            "Epoch: 12 [12720/14400 (88%)]\tLoss: 0.06823\tAccuracy: 0.71618\n",
            "Epoch: 12 [12820/14400 (89%)]\tLoss: 0.03019\tAccuracy: 0.88316\n",
            "Epoch: 12 [12920/14400 (90%)]\tLoss: 0.05556\tAccuracy: 0.82550\n",
            "Epoch: 12 [13020/14400 (90%)]\tLoss: 0.03065\tAccuracy: 0.74985\n",
            "Epoch: 12 [13120/14400 (91%)]\tLoss: 0.02941\tAccuracy: 0.78922\n",
            "Epoch: 12 [13220/14400 (92%)]\tLoss: 0.10239\tAccuracy: 0.60192\n",
            "Epoch: 12 [13320/14400 (92%)]\tLoss: 0.01726\tAccuracy: 0.91652\n",
            "Epoch: 12 [13420/14400 (93%)]\tLoss: 0.05179\tAccuracy: 0.71150\n",
            "Epoch: 12 [13520/14400 (94%)]\tLoss: 0.02437\tAccuracy: 0.86071\n",
            "Epoch: 12 [13620/14400 (95%)]\tLoss: 0.06200\tAccuracy: 0.76715\n",
            "Epoch: 12 [13720/14400 (95%)]\tLoss: 0.03972\tAccuracy: 0.74202\n",
            "Epoch: 12 [13820/14400 (96%)]\tLoss: 0.09855\tAccuracy: 0.61739\n",
            "Epoch: 12 [13920/14400 (97%)]\tLoss: 0.05734\tAccuracy: 0.75815\n",
            "Epoch: 12 [14020/14400 (97%)]\tLoss: 0.07395\tAccuracy: 0.77496\n",
            "Epoch: 12 [14120/14400 (98%)]\tLoss: 0.04763\tAccuracy: 0.76790\n",
            "Epoch: 12 [14220/14400 (99%)]\tLoss: 0.07627\tAccuracy: 0.75365\n",
            "Epoch: 12 [14320/14400 (99%)]\tLoss: 0.06414\tAccuracy: 0.70910\n",
            "Epoch: 12 Train Loss: 0.04756 Train Accuracy: 0.64142\n",
            "Validation Loss: 0.10131 Validation Accuracy: 0.60847\n",
            "Epoch: 13 [20/14400 (0%)]\tLoss: 0.01786\tAccuracy: 0.96105\n",
            "Epoch: 13 [120/14400 (1%)]\tLoss: 0.07721\tAccuracy: 0.68771\n",
            "Epoch: 13 [220/14400 (2%)]\tLoss: 0.05361\tAccuracy: 0.73864\n",
            "Epoch: 13 [320/14400 (2%)]\tLoss: 0.08607\tAccuracy: 0.31617\n",
            "Epoch: 13 [420/14400 (3%)]\tLoss: 0.04091\tAccuracy: 0.42430\n",
            "Epoch: 13 [520/14400 (4%)]\tLoss: 0.08497\tAccuracy: 0.50709\n",
            "Epoch: 13 [620/14400 (4%)]\tLoss: 0.02646\tAccuracy: 0.80257\n",
            "Epoch: 13 [720/14400 (5%)]\tLoss: 0.03054\tAccuracy: 0.76998\n",
            "Epoch: 13 [820/14400 (6%)]\tLoss: 0.07633\tAccuracy: 0.72170\n",
            "Epoch: 13 [920/14400 (6%)]\tLoss: 0.01167\tAccuracy: 0.81387\n",
            "Epoch: 13 [1020/14400 (7%)]\tLoss: 0.05653\tAccuracy: 0.77242\n",
            "Epoch: 13 [1120/14400 (8%)]\tLoss: 0.02264\tAccuracy: 0.70334\n",
            "Epoch: 13 [1220/14400 (8%)]\tLoss: 0.01882\tAccuracy: 0.87184\n",
            "Epoch: 13 [1320/14400 (9%)]\tLoss: 0.04116\tAccuracy: 0.58156\n",
            "Epoch: 13 [1420/14400 (10%)]\tLoss: 0.08184\tAccuracy: 0.56423\n",
            "Epoch: 13 [1520/14400 (11%)]\tLoss: 0.05210\tAccuracy: 0.66925\n",
            "Epoch: 13 [1620/14400 (11%)]\tLoss: 0.06033\tAccuracy: 0.55494\n",
            "Epoch: 13 [1720/14400 (12%)]\tLoss: 0.03181\tAccuracy: 0.45088\n",
            "Epoch: 13 [1820/14400 (13%)]\tLoss: 0.05582\tAccuracy: 0.83501\n",
            "Epoch: 13 [1920/14400 (13%)]\tLoss: 0.04445\tAccuracy: 0.65721\n",
            "Epoch: 13 [2020/14400 (14%)]\tLoss: 0.06153\tAccuracy: 0.78991\n",
            "Epoch: 13 [2120/14400 (15%)]\tLoss: 0.03938\tAccuracy: 0.77519\n",
            "Epoch: 13 [2220/14400 (15%)]\tLoss: 0.10997\tAccuracy: 0.62081\n",
            "Epoch: 13 [2320/14400 (16%)]\tLoss: 0.04357\tAccuracy: 0.78019\n",
            "Epoch: 13 [2420/14400 (17%)]\tLoss: 0.03314\tAccuracy: 0.85544\n",
            "Epoch: 13 [2520/14400 (18%)]\tLoss: 0.08637\tAccuracy: 0.65378\n",
            "Epoch: 13 [2620/14400 (18%)]\tLoss: 0.03036\tAccuracy: 0.73244\n",
            "Epoch: 13 [2720/14400 (19%)]\tLoss: 0.02124\tAccuracy: 0.82421\n",
            "Epoch: 13 [2820/14400 (20%)]\tLoss: 0.04459\tAccuracy: 0.81191\n",
            "Epoch: 13 [2920/14400 (20%)]\tLoss: 0.04441\tAccuracy: 0.71985\n",
            "Epoch: 13 [3020/14400 (21%)]\tLoss: 0.01699\tAccuracy: 0.79755\n",
            "Epoch: 13 [3120/14400 (22%)]\tLoss: 0.03658\tAccuracy: 0.89648\n",
            "Epoch: 13 [3220/14400 (22%)]\tLoss: 0.02647\tAccuracy: 0.83035\n",
            "Epoch: 13 [3320/14400 (23%)]\tLoss: 0.09163\tAccuracy: 0.67344\n",
            "Epoch: 13 [3420/14400 (24%)]\tLoss: 0.05237\tAccuracy: 0.73085\n",
            "Epoch: 13 [3520/14400 (24%)]\tLoss: 0.03732\tAccuracy: 0.71155\n",
            "Epoch: 13 [3620/14400 (25%)]\tLoss: 0.03553\tAccuracy: 0.69839\n",
            "Epoch: 13 [3720/14400 (26%)]\tLoss: 0.09134\tAccuracy: 0.46476\n",
            "Epoch: 13 [3820/14400 (27%)]\tLoss: 0.02627\tAccuracy: 0.67321\n",
            "Epoch: 13 [3920/14400 (27%)]\tLoss: 0.02534\tAccuracy: 0.81365\n",
            "Epoch: 13 [4020/14400 (28%)]\tLoss: 0.01846\tAccuracy: 0.88959\n",
            "Epoch: 13 [4120/14400 (29%)]\tLoss: 0.02537\tAccuracy: 0.73400\n",
            "Epoch: 13 [4220/14400 (29%)]\tLoss: 0.02470\tAccuracy: 0.76718\n",
            "Epoch: 13 [4320/14400 (30%)]\tLoss: 0.04100\tAccuracy: 0.81295\n",
            "Epoch: 13 [4420/14400 (31%)]\tLoss: 0.02574\tAccuracy: 0.75158\n",
            "Epoch: 13 [4520/14400 (31%)]\tLoss: 0.13690\tAccuracy: 0.63564\n",
            "Epoch: 13 [4620/14400 (32%)]\tLoss: 0.07331\tAccuracy: 0.74034\n",
            "Epoch: 13 [4720/14400 (33%)]\tLoss: 0.02858\tAccuracy: 0.77304\n",
            "Epoch: 13 [4820/14400 (33%)]\tLoss: 0.09782\tAccuracy: 0.59444\n",
            "Epoch: 13 [4920/14400 (34%)]\tLoss: 0.02548\tAccuracy: 0.77023\n",
            "Epoch: 13 [5020/14400 (35%)]\tLoss: 0.02598\tAccuracy: 0.83349\n",
            "Epoch: 13 [5120/14400 (36%)]\tLoss: 0.06567\tAccuracy: 0.65642\n",
            "Epoch: 13 [5220/14400 (36%)]\tLoss: 0.05982\tAccuracy: 0.52656\n",
            "Epoch: 13 [5320/14400 (37%)]\tLoss: 0.07894\tAccuracy: 0.62768\n",
            "Epoch: 13 [5420/14400 (38%)]\tLoss: 0.01436\tAccuracy: 0.95141\n",
            "Epoch: 13 [5520/14400 (38%)]\tLoss: 0.02854\tAccuracy: 0.91240\n",
            "Epoch: 13 [5620/14400 (39%)]\tLoss: 0.07593\tAccuracy: 0.74750\n",
            "Epoch: 13 [5720/14400 (40%)]\tLoss: 0.09682\tAccuracy: 0.79248\n",
            "Epoch: 13 [5820/14400 (40%)]\tLoss: 0.10335\tAccuracy: 0.82311\n",
            "Epoch: 13 [5920/14400 (41%)]\tLoss: 0.05128\tAccuracy: 0.86879\n",
            "Epoch: 13 [6020/14400 (42%)]\tLoss: 0.05516\tAccuracy: 0.74802\n",
            "Epoch: 13 [6120/14400 (42%)]\tLoss: 0.05724\tAccuracy: 0.78809\n",
            "Epoch: 13 [6220/14400 (43%)]\tLoss: 0.06718\tAccuracy: 0.65327\n",
            "Epoch: 13 [6320/14400 (44%)]\tLoss: 0.10474\tAccuracy: 0.30120\n",
            "Epoch: 13 [6420/14400 (45%)]\tLoss: 0.05089\tAccuracy: 0.82716\n",
            "Epoch: 13 [6520/14400 (45%)]\tLoss: 0.11189\tAccuracy: 0.58934\n",
            "Epoch: 13 [6620/14400 (46%)]\tLoss: 0.12430\tAccuracy: 0.59047\n",
            "Epoch: 13 [6720/14400 (47%)]\tLoss: 0.03771\tAccuracy: 0.35773\n",
            "Epoch: 13 [6820/14400 (47%)]\tLoss: 0.03598\tAccuracy: 0.84431\n",
            "Epoch: 13 [6920/14400 (48%)]\tLoss: 0.07451\tAccuracy: 0.67671\n",
            "Epoch: 13 [7020/14400 (49%)]\tLoss: 0.04429\tAccuracy: 0.79070\n",
            "Epoch: 13 [7120/14400 (49%)]\tLoss: 0.03922\tAccuracy: 0.86336\n",
            "Epoch: 13 [7220/14400 (50%)]\tLoss: 0.08440\tAccuracy: 0.35056\n",
            "Epoch: 13 [7320/14400 (51%)]\tLoss: 0.05181\tAccuracy: 0.66095\n",
            "Epoch: 13 [7420/14400 (52%)]\tLoss: 0.05257\tAccuracy: 0.68093\n",
            "Epoch: 13 [7520/14400 (52%)]\tLoss: 0.03356\tAccuracy: 0.78662\n",
            "Epoch: 13 [7620/14400 (53%)]\tLoss: 0.06477\tAccuracy: 0.69981\n",
            "Epoch: 13 [7720/14400 (54%)]\tLoss: 0.07563\tAccuracy: 0.69861\n",
            "Epoch: 13 [7820/14400 (54%)]\tLoss: 0.10646\tAccuracy: 0.55952\n",
            "Epoch: 13 [7920/14400 (55%)]\tLoss: 0.04548\tAccuracy: 0.72198\n",
            "Epoch: 13 [8020/14400 (56%)]\tLoss: 0.02582\tAccuracy: 0.67526\n",
            "Epoch: 13 [8120/14400 (56%)]\tLoss: 0.09532\tAccuracy: 0.69739\n",
            "Epoch: 13 [8220/14400 (57%)]\tLoss: 0.12927\tAccuracy: 0.61947\n",
            "Epoch: 13 [8320/14400 (58%)]\tLoss: 0.09255\tAccuracy: 0.45204\n",
            "Epoch: 13 [8420/14400 (58%)]\tLoss: 0.05239\tAccuracy: 0.79791\n",
            "Epoch: 13 [8520/14400 (59%)]\tLoss: 0.03462\tAccuracy: 0.36433\n",
            "Epoch: 13 [8620/14400 (60%)]\tLoss: 0.08221\tAccuracy: 0.68267\n",
            "Epoch: 13 [8720/14400 (61%)]\tLoss: 0.02140\tAccuracy: 0.75071\n",
            "Epoch: 13 [8820/14400 (61%)]\tLoss: 0.02382\tAccuracy: 0.87179\n",
            "Epoch: 13 [8920/14400 (62%)]\tLoss: 0.05938\tAccuracy: 0.74362\n",
            "Epoch: 13 [9020/14400 (63%)]\tLoss: 0.04497\tAccuracy: 0.81863\n",
            "Epoch: 13 [9120/14400 (63%)]\tLoss: 0.02928\tAccuracy: 0.76339\n",
            "Epoch: 13 [9220/14400 (64%)]\tLoss: 0.03941\tAccuracy: 0.64148\n",
            "Epoch: 13 [9320/14400 (65%)]\tLoss: 0.03528\tAccuracy: 0.67981\n",
            "Epoch: 13 [9420/14400 (65%)]\tLoss: 0.03795\tAccuracy: 0.85035\n",
            "Epoch: 13 [9520/14400 (66%)]\tLoss: 0.06449\tAccuracy: 0.73960\n",
            "Epoch: 13 [9620/14400 (67%)]\tLoss: 0.03832\tAccuracy: 0.75927\n",
            "Epoch: 13 [9720/14400 (68%)]\tLoss: 0.02640\tAccuracy: 0.83911\n",
            "Epoch: 13 [9820/14400 (68%)]\tLoss: 0.11244\tAccuracy: 0.59392\n",
            "Epoch: 13 [9920/14400 (69%)]\tLoss: 0.04518\tAccuracy: 0.68317\n",
            "Epoch: 13 [10020/14400 (70%)]\tLoss: 0.02484\tAccuracy: 0.77877\n",
            "Epoch: 13 [10120/14400 (70%)]\tLoss: 0.02559\tAccuracy: 0.77696\n",
            "Epoch: 13 [10220/14400 (71%)]\tLoss: 0.07895\tAccuracy: 0.69544\n",
            "Epoch: 13 [10320/14400 (72%)]\tLoss: 0.04114\tAccuracy: 0.67036\n",
            "Epoch: 13 [10420/14400 (72%)]\tLoss: 0.03446\tAccuracy: 0.82702\n",
            "Epoch: 13 [10520/14400 (73%)]\tLoss: 0.02568\tAccuracy: 0.85379\n",
            "Epoch: 13 [10620/14400 (74%)]\tLoss: 0.03511\tAccuracy: 0.69854\n",
            "Epoch: 13 [10720/14400 (74%)]\tLoss: 0.02090\tAccuracy: 0.80220\n",
            "Epoch: 13 [10820/14400 (75%)]\tLoss: 0.02855\tAccuracy: 0.88222\n",
            "Epoch: 13 [10920/14400 (76%)]\tLoss: 0.07093\tAccuracy: 0.66651\n",
            "Epoch: 13 [11020/14400 (77%)]\tLoss: 0.05156\tAccuracy: 0.72064\n",
            "Epoch: 13 [11120/14400 (77%)]\tLoss: 0.05495\tAccuracy: 0.73428\n",
            "Epoch: 13 [11220/14400 (78%)]\tLoss: 0.02860\tAccuracy: 0.82132\n",
            "Epoch: 13 [11320/14400 (79%)]\tLoss: 0.03317\tAccuracy: 0.67586\n",
            "Epoch: 13 [11420/14400 (79%)]\tLoss: 0.02800\tAccuracy: 0.72019\n",
            "Epoch: 13 [11520/14400 (80%)]\tLoss: 0.06178\tAccuracy: 0.72593\n",
            "Epoch: 13 [11620/14400 (81%)]\tLoss: 0.03672\tAccuracy: 0.86733\n",
            "Epoch: 13 [11720/14400 (81%)]\tLoss: 0.03307\tAccuracy: 0.81560\n",
            "Epoch: 13 [11820/14400 (82%)]\tLoss: 0.02377\tAccuracy: 0.64164\n",
            "Epoch: 13 [11920/14400 (83%)]\tLoss: 0.04496\tAccuracy: 0.60268\n",
            "Epoch: 13 [12020/14400 (83%)]\tLoss: 0.07200\tAccuracy: 0.80851\n",
            "Epoch: 13 [12120/14400 (84%)]\tLoss: 0.07483\tAccuracy: 0.31797\n",
            "Epoch: 13 [12220/14400 (85%)]\tLoss: 0.07245\tAccuracy: 0.49316\n",
            "Epoch: 13 [12320/14400 (86%)]\tLoss: 0.04014\tAccuracy: 0.71937\n",
            "Epoch: 13 [12420/14400 (86%)]\tLoss: 0.06834\tAccuracy: 0.70336\n",
            "Epoch: 13 [12520/14400 (87%)]\tLoss: 0.04885\tAccuracy: 0.80186\n",
            "Epoch: 13 [12620/14400 (88%)]\tLoss: 0.02722\tAccuracy: 0.72061\n",
            "Epoch: 13 [12720/14400 (88%)]\tLoss: 0.05663\tAccuracy: 0.77934\n",
            "Epoch: 13 [12820/14400 (89%)]\tLoss: 0.03330\tAccuracy: 0.73008\n",
            "Epoch: 13 [12920/14400 (90%)]\tLoss: 0.05463\tAccuracy: 0.81439\n",
            "Epoch: 13 [13020/14400 (90%)]\tLoss: 0.04125\tAccuracy: 0.71706\n",
            "Epoch: 13 [13120/14400 (91%)]\tLoss: 0.05975\tAccuracy: 0.81092\n",
            "Epoch: 13 [13220/14400 (92%)]\tLoss: 0.13144\tAccuracy: 0.65169\n",
            "Epoch: 13 [13320/14400 (92%)]\tLoss: 0.01616\tAccuracy: 0.69793\n",
            "Epoch: 13 [13420/14400 (93%)]\tLoss: 0.02900\tAccuracy: 0.71466\n",
            "Epoch: 13 [13520/14400 (94%)]\tLoss: 0.01237\tAccuracy: 0.87224\n",
            "Epoch: 13 [13620/14400 (95%)]\tLoss: 0.04015\tAccuracy: 0.70807\n",
            "Epoch: 13 [13720/14400 (95%)]\tLoss: 0.05739\tAccuracy: 0.77478\n",
            "Epoch: 13 [13820/14400 (96%)]\tLoss: 0.07305\tAccuracy: 0.85884\n",
            "Epoch: 13 [13920/14400 (97%)]\tLoss: 0.05441\tAccuracy: 0.56715\n",
            "Epoch: 13 [14020/14400 (97%)]\tLoss: 0.06447\tAccuracy: 0.66916\n",
            "Epoch: 13 [14120/14400 (98%)]\tLoss: 0.04519\tAccuracy: 0.55264\n",
            "Epoch: 13 [14220/14400 (99%)]\tLoss: 0.07420\tAccuracy: 0.69364\n",
            "Epoch: 13 [14320/14400 (99%)]\tLoss: 0.03557\tAccuracy: 0.83076\n",
            "Epoch: 13 Train Loss: 0.04578 Train Accuracy: 0.64613\n",
            "Validation Loss: 0.09490 Validation Accuracy: 0.67142\n",
            "Epoch: 14 [20/14400 (0%)]\tLoss: 0.04701\tAccuracy: 0.71424\n",
            "Epoch: 14 [120/14400 (1%)]\tLoss: 0.04893\tAccuracy: 0.78640\n",
            "Epoch: 14 [220/14400 (2%)]\tLoss: 0.04064\tAccuracy: 0.87701\n",
            "Epoch: 14 [320/14400 (2%)]\tLoss: 0.03390\tAccuracy: 0.73725\n",
            "Epoch: 14 [420/14400 (3%)]\tLoss: 0.01868\tAccuracy: 0.91906\n",
            "Epoch: 14 [520/14400 (4%)]\tLoss: 0.03064\tAccuracy: 0.90308\n",
            "Epoch: 14 [620/14400 (4%)]\tLoss: 0.07043\tAccuracy: 0.78664\n",
            "Epoch: 14 [720/14400 (5%)]\tLoss: 0.04836\tAccuracy: 0.79638\n",
            "Epoch: 14 [820/14400 (6%)]\tLoss: 0.01607\tAccuracy: 0.78772\n",
            "Epoch: 14 [920/14400 (6%)]\tLoss: 0.06660\tAccuracy: 0.66064\n",
            "Epoch: 14 [1020/14400 (7%)]\tLoss: 0.04194\tAccuracy: 0.72636\n",
            "Epoch: 14 [1120/14400 (8%)]\tLoss: 0.10840\tAccuracy: 0.66974\n",
            "Epoch: 14 [1220/14400 (8%)]\tLoss: 0.02357\tAccuracy: 0.76865\n",
            "Epoch: 14 [1320/14400 (9%)]\tLoss: 0.03489\tAccuracy: 0.87148\n",
            "Epoch: 14 [1420/14400 (10%)]\tLoss: 0.03215\tAccuracy: 0.59300\n",
            "Epoch: 14 [1520/14400 (11%)]\tLoss: 0.03267\tAccuracy: 0.64021\n",
            "Epoch: 14 [1620/14400 (11%)]\tLoss: 0.03633\tAccuracy: 0.73163\n",
            "Epoch: 14 [1720/14400 (12%)]\tLoss: 0.02485\tAccuracy: 0.76356\n",
            "Epoch: 14 [1820/14400 (13%)]\tLoss: 0.04366\tAccuracy: 0.84482\n",
            "Epoch: 14 [1920/14400 (13%)]\tLoss: 0.07533\tAccuracy: 0.78079\n",
            "Epoch: 14 [2020/14400 (14%)]\tLoss: 0.03475\tAccuracy: 0.77776\n",
            "Epoch: 14 [2120/14400 (15%)]\tLoss: 0.07167\tAccuracy: 0.70256\n",
            "Epoch: 14 [2220/14400 (15%)]\tLoss: 0.01886\tAccuracy: 0.82433\n",
            "Epoch: 14 [2320/14400 (16%)]\tLoss: 0.03614\tAccuracy: 0.88219\n",
            "Epoch: 14 [2420/14400 (17%)]\tLoss: 0.07398\tAccuracy: 0.65475\n",
            "Epoch: 14 [2520/14400 (18%)]\tLoss: 0.03533\tAccuracy: 0.69856\n",
            "Epoch: 14 [2620/14400 (18%)]\tLoss: 0.04073\tAccuracy: 0.66794\n",
            "Epoch: 14 [2720/14400 (19%)]\tLoss: 0.03699\tAccuracy: 0.75349\n",
            "Epoch: 14 [2820/14400 (20%)]\tLoss: 0.02262\tAccuracy: 0.74901\n",
            "Epoch: 14 [2920/14400 (20%)]\tLoss: 0.06232\tAccuracy: 0.45783\n",
            "Epoch: 14 [3020/14400 (21%)]\tLoss: 0.07383\tAccuracy: 0.69734\n",
            "Epoch: 14 [3120/14400 (22%)]\tLoss: 0.03956\tAccuracy: 0.64363\n",
            "Epoch: 14 [3220/14400 (22%)]\tLoss: 0.02527\tAccuracy: 0.75776\n",
            "Epoch: 14 [3320/14400 (23%)]\tLoss: 0.01042\tAccuracy: 0.95877\n",
            "Epoch: 14 [3420/14400 (24%)]\tLoss: 0.02806\tAccuracy: 0.76490\n",
            "Epoch: 14 [3520/14400 (24%)]\tLoss: 0.03409\tAccuracy: 0.83216\n",
            "Epoch: 14 [3620/14400 (25%)]\tLoss: 0.02078\tAccuracy: 0.75955\n",
            "Epoch: 14 [3720/14400 (26%)]\tLoss: 0.04640\tAccuracy: 0.71477\n",
            "Epoch: 14 [3820/14400 (27%)]\tLoss: 0.02971\tAccuracy: 0.63848\n",
            "Epoch: 14 [3920/14400 (27%)]\tLoss: 0.02030\tAccuracy: 0.89558\n",
            "Epoch: 14 [4020/14400 (28%)]\tLoss: 0.05970\tAccuracy: 0.78085\n",
            "Epoch: 14 [4120/14400 (29%)]\tLoss: 0.09661\tAccuracy: 0.36473\n",
            "Epoch: 14 [4220/14400 (29%)]\tLoss: 0.05000\tAccuracy: 0.70585\n",
            "Epoch: 14 [4320/14400 (30%)]\tLoss: 0.05928\tAccuracy: 0.87036\n",
            "Epoch: 14 [4420/14400 (31%)]\tLoss: 0.06294\tAccuracy: 0.83998\n",
            "Epoch: 14 [4520/14400 (31%)]\tLoss: 0.06839\tAccuracy: 0.76148\n",
            "Epoch: 14 [4620/14400 (32%)]\tLoss: 0.10174\tAccuracy: 0.58727\n",
            "Epoch: 14 [4720/14400 (33%)]\tLoss: 0.01539\tAccuracy: 0.75372\n",
            "Epoch: 14 [4820/14400 (33%)]\tLoss: 0.06605\tAccuracy: 0.82247\n",
            "Epoch: 14 [4920/14400 (34%)]\tLoss: 0.01931\tAccuracy: 0.84696\n",
            "Epoch: 14 [5020/14400 (35%)]\tLoss: 0.03243\tAccuracy: 0.70295\n",
            "Epoch: 14 [5120/14400 (36%)]\tLoss: 0.01389\tAccuracy: 0.77028\n",
            "Epoch: 14 [5220/14400 (36%)]\tLoss: 0.06773\tAccuracy: 0.85569\n",
            "Epoch: 14 [5320/14400 (37%)]\tLoss: 0.02054\tAccuracy: 0.77349\n",
            "Epoch: 14 [5420/14400 (38%)]\tLoss: 0.04250\tAccuracy: 0.76130\n",
            "Epoch: 14 [5520/14400 (38%)]\tLoss: 0.07566\tAccuracy: 0.49684\n",
            "Epoch: 14 [5620/14400 (39%)]\tLoss: 0.05283\tAccuracy: 0.73558\n",
            "Epoch: 14 [5720/14400 (40%)]\tLoss: 0.03065\tAccuracy: 0.37727\n",
            "Epoch: 14 [5820/14400 (40%)]\tLoss: 0.03075\tAccuracy: 0.78181\n",
            "Epoch: 14 [5920/14400 (41%)]\tLoss: 0.01303\tAccuracy: 0.84285\n",
            "Epoch: 14 [6020/14400 (42%)]\tLoss: 0.04052\tAccuracy: 0.68934\n",
            "Epoch: 14 [6120/14400 (42%)]\tLoss: 0.03634\tAccuracy: 0.84724\n",
            "Epoch: 14 [6220/14400 (43%)]\tLoss: 0.12226\tAccuracy: 0.71958\n",
            "Epoch: 14 [6320/14400 (44%)]\tLoss: 0.03549\tAccuracy: 0.92508\n",
            "Epoch: 14 [6420/14400 (45%)]\tLoss: 0.01489\tAccuracy: 0.82579\n",
            "Epoch: 14 [6520/14400 (45%)]\tLoss: 0.06139\tAccuracy: 0.81087\n",
            "Epoch: 14 [6620/14400 (46%)]\tLoss: 0.04452\tAccuracy: 0.78897\n",
            "Epoch: 14 [6720/14400 (47%)]\tLoss: 0.01675\tAccuracy: 0.88810\n",
            "Epoch: 14 [6820/14400 (47%)]\tLoss: 0.04754\tAccuracy: 0.73771\n",
            "Epoch: 14 [6920/14400 (48%)]\tLoss: 0.02048\tAccuracy: 0.88300\n",
            "Epoch: 14 [7020/14400 (49%)]\tLoss: 0.04607\tAccuracy: 0.62098\n",
            "Epoch: 14 [7120/14400 (49%)]\tLoss: 0.01927\tAccuracy: 0.86605\n",
            "Epoch: 14 [7220/14400 (50%)]\tLoss: 0.03218\tAccuracy: 0.75253\n",
            "Epoch: 14 [7320/14400 (51%)]\tLoss: 0.06718\tAccuracy: 0.66918\n",
            "Epoch: 14 [7420/14400 (52%)]\tLoss: 0.05660\tAccuracy: 0.71066\n",
            "Epoch: 14 [7520/14400 (52%)]\tLoss: 0.08412\tAccuracy: 0.67116\n",
            "Epoch: 14 [7620/14400 (53%)]\tLoss: 0.05273\tAccuracy: 0.67735\n",
            "Epoch: 14 [7720/14400 (54%)]\tLoss: 0.08704\tAccuracy: 0.55965\n",
            "Epoch: 14 [7820/14400 (54%)]\tLoss: 0.04168\tAccuracy: 0.85839\n",
            "Epoch: 14 [7920/14400 (55%)]\tLoss: 0.03072\tAccuracy: 0.69622\n",
            "Epoch: 14 [8020/14400 (56%)]\tLoss: 0.02912\tAccuracy: 0.93086\n",
            "Epoch: 14 [8120/14400 (56%)]\tLoss: 0.01430\tAccuracy: 0.80624\n",
            "Epoch: 14 [8220/14400 (57%)]\tLoss: 0.06708\tAccuracy: 0.75477\n",
            "Epoch: 14 [8320/14400 (58%)]\tLoss: 0.05709\tAccuracy: 0.85658\n",
            "Epoch: 14 [8420/14400 (58%)]\tLoss: 0.03201\tAccuracy: 0.45305\n",
            "Epoch: 14 [8520/14400 (59%)]\tLoss: 0.04142\tAccuracy: 0.72326\n",
            "Epoch: 14 [8620/14400 (60%)]\tLoss: 0.07053\tAccuracy: 0.71155\n",
            "Epoch: 14 [8720/14400 (61%)]\tLoss: 0.06481\tAccuracy: 0.79772\n",
            "Epoch: 14 [8820/14400 (61%)]\tLoss: 0.08215\tAccuracy: 0.45258\n",
            "Epoch: 14 [8920/14400 (62%)]\tLoss: 0.09611\tAccuracy: 0.55194\n",
            "Epoch: 14 [9020/14400 (63%)]\tLoss: 0.06949\tAccuracy: 0.66601\n",
            "Epoch: 14 [9120/14400 (63%)]\tLoss: 0.03626\tAccuracy: 0.68618\n",
            "Epoch: 14 [9220/14400 (64%)]\tLoss: 0.01885\tAccuracy: 0.89974\n",
            "Epoch: 14 [9320/14400 (65%)]\tLoss: 0.02771\tAccuracy: 0.87965\n",
            "Epoch: 14 [9420/14400 (65%)]\tLoss: 0.11741\tAccuracy: 0.50046\n",
            "Epoch: 14 [9520/14400 (66%)]\tLoss: 0.04733\tAccuracy: 0.77278\n",
            "Epoch: 14 [9620/14400 (67%)]\tLoss: 0.02775\tAccuracy: 0.87658\n",
            "Epoch: 14 [9720/14400 (68%)]\tLoss: 0.05392\tAccuracy: 0.76066\n",
            "Epoch: 14 [9820/14400 (68%)]\tLoss: 0.10129\tAccuracy: 0.76215\n",
            "Epoch: 14 [9920/14400 (69%)]\tLoss: 0.03004\tAccuracy: 0.84733\n",
            "Epoch: 14 [10020/14400 (70%)]\tLoss: 0.09008\tAccuracy: 0.67540\n",
            "Epoch: 14 [10120/14400 (70%)]\tLoss: 0.04216\tAccuracy: 0.41249\n",
            "Epoch: 14 [10220/14400 (71%)]\tLoss: 0.09998\tAccuracy: 0.48666\n",
            "Epoch: 14 [10320/14400 (72%)]\tLoss: 0.07778\tAccuracy: 0.65025\n",
            "Epoch: 14 [10420/14400 (72%)]\tLoss: 0.02919\tAccuracy: 0.82532\n",
            "Epoch: 14 [10520/14400 (73%)]\tLoss: 0.03658\tAccuracy: 0.75870\n",
            "Epoch: 14 [10620/14400 (74%)]\tLoss: 0.02513\tAccuracy: 0.85655\n",
            "Epoch: 14 [10720/14400 (74%)]\tLoss: 0.02773\tAccuracy: 0.89665\n",
            "Epoch: 14 [10820/14400 (75%)]\tLoss: 0.03543\tAccuracy: 0.73316\n",
            "Epoch: 14 [10920/14400 (76%)]\tLoss: 0.05311\tAccuracy: 0.58082\n",
            "Epoch: 14 [11020/14400 (77%)]\tLoss: 0.05006\tAccuracy: 0.76171\n",
            "Epoch: 14 [11120/14400 (77%)]\tLoss: 0.11378\tAccuracy: 0.77856\n",
            "Epoch: 14 [11220/14400 (78%)]\tLoss: 0.03636\tAccuracy: 0.77305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9OHaEf5cLvSR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " save_checkpoint({\n",
        "            'epoch': epoch + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer' : optimizer.state_dict(),\n",
        "            })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xoj_mVMG22v1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def adjust_learning_rate(optimizerr,lr):\n",
        "   \n",
        "    for param_group in optimizerr.param_groups:\n",
        "        param_group['lr'] = lr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zi91R9cf3EDK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_checkpoint({\n",
        "            'epoch': 6 + 1,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer' : optimizer.state_dict(),\n",
        "            },filename='model_state'+str(6)+'.tar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "szxSGI4XqYYn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3333beef-2ad4-4515-980f-84b999b30d47"
      },
      "cell_type": "code",
      "source": [
        "load_checkpoint('model_state'+str(6)+'.tar')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> loading checkpoint 'model_state6.tar'\n",
            "=> loaded checkpoint 'model_state6.tar' (epoch 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cROYfWFQivC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "fc67add9-f991-48a7-9435-1f4e028c3951"
      },
      "cell_type": "code",
      "source": [
        "model.cpu()\n",
        "threshold=0.5\n",
        "fig, axeslist = plt.subplots(ncols=3,nrows=1)\n",
        "\n",
        "x,y,d =train_dataset[66]\n",
        "axeslist.ravel()[0].imshow(x.detach().numpy(),cmap='gray')\n",
        "axeslist.ravel()[1].imshow(y.detach().numpy(),cmap='gray')\n",
        "print(x.shape)\n",
        "z = model(x.view(1,101,101),d)\n",
        "z = ((z>(1-threshold)) * (z<(1+threshold))).float()\n",
        "axeslist.ravel()[2].imshow(z.squeeze(0).detach().numpy(),cmap='gray')\n",
        "print(z.shape)\n",
        "# def getImg(x):\n",
        "#     x = x.view(1,3,101,101)\n",
        "#     x = model(x).detach().squeeze(0).numpy()[0]\n",
        "#     x = (x-x.mean()/(x.max()-x.min())) +1\n",
        "#     a = np.expand_dims(x, axis = 2)\n",
        "#     a = np.concatenate((a, a, a), axis = 2)\n",
        "#     return a\n",
        "# print(y.shape)\n",
        "# predict = (F.sigmoid(z) > 0.5).detach().numpy().squeeze(0)\n",
        "# axeslist.ravel()[3].imshow(predict,cmap='gray')\n",
        "\n",
        "\n",
        "# # axeslist.ravel()[1].imshow(getImg(y),cmap='gray')\n",
        "\n",
        "# axeslist.ravel()[2].imshow(y.detach().numpy(),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([101, 101])\n",
            "torch.Size([1, 101, 101])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAFqCAYAAACeWgrTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBPwDwex51uiW5wgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fba2c6f9da0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vro1Wre1jVSy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "|x = torch.randn(1,3,101,101)\n",
        "plt.imshow(x.numpy().squeeze(0)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EoJqaaExKjE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(model,'TGSUNetsimple23.pt')\n",
        "uploaded = drive.CreateFile({'title': 'TGSUNetsimple23.pt'})\n",
        "uploaded.SetContentFile('TGSUNetsimple23.pt')\n",
        "uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JFOZqK-y9dky",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = torch.load('TGSUNetsimple23.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EPGsTKVsxXwm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id': '1Gs1AlcVL9WNlgHQPSpNvbFtSbqNFZIdu'})\n",
        "downloaded.GetContentFile('test.zip')\n",
        "with ZipFile(\"test.zip\", 'r') as z:\n",
        "  z.extractall()\n",
        "os.remove(\"test.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1YRChhpixaZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TGSSaltTestDataset(Dataset):\n",
        "    def __init__(self, image_dir,test_csv):\n",
        "        self.image_dir=image_dir\n",
        "#         self.filter = np.array([(0,-1,-1,-1),(1,0,0,0),(1,0,1,0),(0,1,0,1)])/8\n",
        "        self.input = pd.read_csv(test_csv)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir,self.input.iloc[idx,0]+\".png\")\n",
        "        img = cv2.imread(img_name)\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        img = torch.tensor(img).view(101,101).float()\n",
        "#         depth = self.input.iloc[idx,1].reshape(1)\n",
        "        \n",
        "        return img,0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1CoZ2ZFZyFFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "test_dataset = TGSSaltTestDataset(\"test/images\",\"test.csv\")\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Cyx-txnwXum",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(test_loader):\n",
        "    test_pred=torch.IntTensor().cuda()\n",
        "    model.eval()\n",
        "    for batch_idx,( data,d) in enumerate(test_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "#             target = target.cuda()\n",
        "        # forward\n",
        "        output = model(data,d)\n",
        "        predictx = ((output) > 0.5).int()\n",
        "        test_pred=torch.cat((test_pred,predictx.view(batch_size,101,101)),dim=0)\n",
        "    return test_pred.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3bNyLN02yLn2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predict=prediciton(test_loader)\n",
        "predict=predict.cpu().numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xRC4rYuYySkY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rle_encode(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels = img.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Nq9-6hHyV-t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test_dataset.input.drop(\"z\",axis=1,inplace=True)\n",
        "predicted = predict(test_loader)\n",
        "test_dataset.input['rle_mask']=np.nan\n",
        "for i in range(len(test_dataset)):\n",
        "    test_dataset.input[\"rle_mask\"][i]=rle_encode(predicted[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ScpRh0ukyYyM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# test_dataset.input.drop([\"z\"],axis=1,inplace=True)\n",
        "test_dataset.input.to_csv(\"submission112.csv\",index=False)\n",
        "uploaded = drive.CreateFile({'title': 'submissions_unet2e10x.csv'})\n",
        "uploaded.SetContentFile('submission112.csv')\n",
        "uploaded.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GvAlb7sjspQu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "from https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_model.py"
      ]
    },
    {
      "metadata": {
        "id": "9VTtLhXttOnv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7EbUomFA6KoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dataset[6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3QMWEl_ijAMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=None\n",
        "criterion=None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKRuP3VVVdhH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_dataset.input.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4l-oV77umIS_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}