{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "class TGSSaltTrainDataset(Dataset):\n    def __init__(self, image_dir,mask_dir,depth_csv,train_csv):\n        self.image_dir=image_dir\n        self.mask_dir=mask_dir\n        \n        depth=pd.read_csv(depth_csv)\n        depth[\"z\"]=(depth[\"z\"]-depth[\"z\"].min())/(depth[\"z\"].max()-depth[\"z\"].min())\n        \n        self.input = pd.read_csv(train_csv)\n        self.input.drop(['rle_mask'],axis=1,inplace=True)\n        self.input = self.input.merge(depth,how=\"left\",on=\"id\")\n        \n        self.transform = transforms.Compose([\n            transforms.Grayscale(),\n            transforms.ToTensor(),\n        ])\n        \n    def __len__(self):\n        return len(self.input)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.image_dir,self.input.iloc[idx,0]+\".png\")\n        image = self.transform(Image.open(img_name))\n        msk_name = os.path.join(self.mask_dir,self.input.iloc[idx,0]+\".png\")\n        mask = self.transform(Image.open(msk_name))\n        depth = self.input.iloc[idx,1].reshape(1)\n        return image,depth,mask",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f9c5b35b2111d47404cc72f9e16e381adf24577"
      },
      "cell_type": "code",
      "source": "train_dataset = TGSSaltTrainDataset(\"../input/train/images\",\"../input/train/masks\",\"../input/depths.csv\",\"../input/train.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "304d25a9b0cee9e842f75a37b6a0f508d85663a0"
      },
      "cell_type": "code",
      "source": "batch_size = 50\nvalidation_split = 0.2\nshuffle_dataset = True\nrandom_seed= 42\n# Creating data indices for training and validation splits:\ndataset_size = len(train_dataset)\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset :\n    np.random.seed(random_seed)\n    np.random.shuffle(indices)\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalidation_sampler = SubsetRandomSampler(val_indices)\ntrain_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,sampler=train_sampler)\nvalidation_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,sampler=validation_sampler)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "89873ba95071a2bce3dbe0e76bd1993781f68ea3"
      },
      "cell_type": "code",
      "source": "class TGSUNetModel(nn.Module):        \n    def __init__(self):\n        super(TGSUNetModel,self).__init__()\n        self.down1 = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.Conv2d(64, 64, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU())\n        \n        self.maxpool1 = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n        \n        self.down2 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU())\n        \n        self.maxpool2 = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n        \n        self.down3 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU())\n        \n        self.maxpool3 = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n        \n        self.down4 = nn.Sequential(\n            nn.Conv2d(256, 512, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.Conv2d(512, 512, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        \n        self.maxpool4 = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n        \n        self.center = nn.Sequential(\n            nn.Conv2d(512, 1024, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.ReLU(),\n            nn.Conv2d(1024, 1024, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(1024),\n            nn.ReLU())\n        \n        self.up11 = nn.Sequential(\n            nn.ConvTranspose2d(1024,512,kernel_size=(2, 2), stride=2, padding=0),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n        \n        self.cropcat1 = self.CropCat\n        \n        self.up12 = nn.Sequential(\n            nn.Conv2d(1024, 512, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(512),\n            nn.ReLU())\n\n        self.up21 = nn.Sequential(\n            nn.ConvTranspose2d(512,256,kernel_size=3, stride=2, padding=0),\n            nn.BatchNorm2d(256),\n            nn.ReLU())\n        \n        self.cropcat2 = self.CropCat\n            \n        self.up22 = nn.Sequential(\n            nn.Conv2d(512, 256, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU())\n        \n        self.up31 = nn.Sequential(\n            nn.ConvTranspose2d(256,128,kernel_size=2, stride=2, padding=0),\n            nn.BatchNorm2d(128),\n            nn.ReLU())\n        \n        self.cropcat3 = self.CropCat\n            \n        self.up32 = nn.Sequential(\n            nn.Conv2d(256, 128, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU())\n        \n        self.up41 = nn.Sequential(\n            nn.ConvTranspose2d(128,64,kernel_size=3, stride=2, padding=0),\n            nn.BatchNorm2d(64),\n            nn.ReLU())\n        \n        self.cropcat4 = self.CropCat\n            \n        self.up42 = nn.Sequential(\n            nn.Conv2d(128, 64, kernel_size=(3, 3), stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU())\n            \n        # 1x1 convolution at the last layer\n        # Different from the paper is the output size here\n        self.output_seg_map = nn.Sequential(\n            nn.Conv2d(64,1, kernel_size=(3, 3), padding=1, stride=1),\n            nn.Sigmoid())\n        \n        self.linear = nn.Sequential(\n            nn.BatchNorm1d(101*101),\n            nn.Linear(101*101,101*101),\n            nn.ReLU())\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(64,2),\n            nn.BatchNorm1d(2),\n            nn.Softmax())\n            \n    def CropCat(self, upsampled, bypass):\n        \"\"\"\n         Crop y to the (h, w) of x and concat them.\n         Used for the expansive path.\n        Returns:\n            The concatenated tensor\n        \"\"\"\n        c = (bypass.size()[2] - upsampled.size()[2]) // 2\n        bypass = F.pad(bypass, (-c, -c, -c, -c))\n        return torch.cat((upsampled, bypass), 1)\n        \n    def forward(self,x):\n        down1 = self.down1(x)\n        output = self.maxpool1(down1)\n        down2 = self.down2(output)\n        output = self.maxpool2(down2)\n        down3 = self.down3(output)\n        output = self.maxpool3(down3)\n        down4 = self.down4(output)\n        output = self.maxpool4(down4)\n        output = self.center(output)\n        output = self.up11(output)\n        output = self.cropcat1(output,down4)\n        output = self.up12(output)\n        output = self.up21(output)\n        output = self.cropcat2(output,down3)\n        output = self.up22(output)\n        output = self.up31(output)\n        output = self.cropcat3(output,down2)\n        output = self.up32(output)\n        output = self.up41(output)\n        output = self.cropcat4(output,down1)\n        output = self.up42(output)\n#         output = self.output_seg_map(output)\n        output = output.view(-1,101*101)\n        output = self.linear(output)\n        output = output.view(-1,64)\n        output = self.classifier(output)\n        return output",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02c579edb1da503e4f1e90bb441168391477c5c0"
      },
      "cell_type": "code",
      "source": "class BinaryCrossEntropyLoss2d(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        \"\"\"\n        Binary cross entropy loss 2D\n        Args:\n            weight:\n            size_average:\n        \"\"\"\n        super(BinaryCrossEntropyLoss2d, self).__init__()\n        self.bce_loss = nn.BCELoss(weight, size_average)\n        if torch.cuda.is_available():\n            self.bce_loss = self.bce_loss.cuda()\n\n    def forward(self, pred, target):\n#         pred = F.sigmoid(pred)\n        pred = pred.view(-1)\n        target = target.view(-1)\n        return self.bce_loss(pred, target)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "672f7d6d0c2865697d9a3d0b54b78afb72c6ff3f"
      },
      "cell_type": "code",
      "source": "class SoftDiceLoss(nn.Module):\n    def __init__(self):\n        super(SoftDiceLoss, self).__init__()\n    def forward(self, pred, target):\n        smooth = 1\n        num = target.size(0)\n        pred = pred.max(1,keepdim=True)[1].float()\n        pred = pred.view(num, -1)\n        target = target.view(num, -1)\n        intersection = (pred * target)\n        score = 2. * (intersection.sum(1) + smooth) / (pred.sum(1) + target.sum(1) + smooth)\n        score = 1 - score.sum() / num\n        return score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "99e289eead3b7700aa9c19d9fcf66eb2ec7c98eb"
      },
      "cell_type": "code",
      "source": "def dice_coeff(pred, target):\n    smooth = 1.\n    num = target.size(0)\n    pred = pred.view(num, -1)  # Flatten\n    target = target.view(num, -1)  # Flatten\n    intersection = (pred * target)\n    score = (2. * intersection.sum(1) + smooth).float() / (pred.sum(1) + target.sum(1) + smooth).float()\n    return score.sum()/num",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92823ba579944bb0877e1bed5c2d58444b14c3bf"
      },
      "cell_type": "code",
      "source": "def bce_dice_loss(y_pred,y_true):\n    return nn.CrossEntropyLoss()(y_pred,y_true)+0.5*SoftDiceLoss()(y_pred,y_true.float())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "78c1850ab4eed4beb42919b0c0c8cbcf469e219b"
      },
      "cell_type": "code",
      "source": "model=TGSUNetModel()\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nexp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "255204494e971512ccb3d91d1ae350bb6864db93"
      },
      "cell_type": "code",
      "source": "def validate():\n    total_loss = 0\n    total_accuracy = 0\n    model.eval()\n    for batch_idx, (data,depth,target) in enumerate(validation_loader):\n        target = target.long()\n        if torch.cuda.is_available():\n            data = data.cuda()\n            target = target.cuda()\n        # forward\n        output = model(data)\n        predict = output.max(1,keepdim=True)[1]\n        # backward + optimize\n        loss = criterion(output, target.view(-1))\n        # print statistics\n        accuracy = dice_coeff(predict.view_as(target),target)\n        total_accuracy+=accuracy.item()\n        total_loss+=loss.item()\n    print('Validation Loss: {:.5f} Validation Accuracy: {:.5f}'.format(total_loss*batch_size/len(val_indices),total_accuracy*batch_size/len(val_indices)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "df3260ea1c6ec3a2ad21250b2162634f16b2f6a6"
      },
      "cell_type": "code",
      "source": "def train():\n    epoch=1\n    while True:\n        total_loss = 0\n        total_accuracy = 0\n        model.train()\n        exp_lr_scheduler.step()\n        print(exp_lr_scheduler.get_lr())\n        for batch_idx, (data,depth,target) in enumerate(train_loader):\n            target = target.long()\n            if torch.cuda.is_available():\n                data = data.cuda()\n                depth = depth.cuda()\n                target = target.cuda()\n            # forward\n            output = model(data)\n            predict = output.max(1,keepdim=True)[1]\n            # backward + optimize\n            loss = criterion(output, target.view(-1))\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            # print statistics\n            accuracy = dice_coeff(predict.view_as(target),target)\n            total_accuracy+=accuracy.item()\n            total_loss+=loss.item()\n            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.5f}\\tAccuracy: {:.5f}'.format(epoch, (batch_idx + 1) * len(data), len(train_indices),100*(batch_idx + 1)* len(data) / len(train_indices), loss.item(),accuracy))\n        print('Train Loss: {:.5f} Train Accuracy: {:.5f}'.format(total_loss*batch_size/len(train_indices),total_accuracy*batch_size/len(train_indices)))\n        validate()\n        epoch+=1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bd065d95aeeea488e6466e4e6e11040f5312418e",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "train()",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[0.001]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6be4a8f4ebfcbcb74e2d5b5d20c940cf3edc827a"
      },
      "cell_type": "code",
      "source": "state = {'epoch': 108+1, 'state_dict': model.state_dict(),'optimizer': optimizer.state_dict(), 'losslogger': criterion, }\ntorch.save(state, 'checkpoint.pth.tar')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b415b1b05ddb3912cb6719f6d4e6d310d2ed22e9"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}