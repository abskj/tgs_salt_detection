{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TGSDetection_base.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TGhrHUvK0nzy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Installation and neccessary imports"
      ]
    },
    {
      "metadata": {
        "id": "GU_WaXquzzfK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install Pillow\n",
        "!pip install -U -q PyDrive\n",
        "!pip install pretrainedmodels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4gA-Aj9a0SOu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from zipfile import ZipFile\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "%matplotlib inline\n",
        "from IPython import display\n",
        "import pretrainedmodels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WKAk5dcngG_B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "def register_extension(id, extension): Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "    for extension in extensions: register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XAcI93TX0YCJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ami7WNZc1Erj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## List the files present in the drive and download the dataset"
      ]
    },
    {
      "metadata": {
        "id": "ITABPygY1NSv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "listed = drive.ListFile().GetList()\n",
        "for file in listed[:10]:\n",
        "    print('title {}, id {}'.format(file['title'], file['id']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_w2GF_C1WdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id': '1MwjE6MUY4OnkTytUMTZKa9WskD43_-Al'})\n",
        "downloaded.GetContentFile('train.zip')\n",
        "with ZipFile(\"train.zip\", 'r') as z:\n",
        "    z.extractall()\n",
        "os.remove(\"train.zip\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eeH39q0D5BeN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p51Hkx78Yeon",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Some utility functions"
      ]
    },
    {
      "metadata": {
        "id": "Z4QR3kGWcMSH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(df,cols,dtype = 'float16'):\n",
        "    data = df\n",
        "    for col in cols:\n",
        "        data[col] = ((data[col]-data[col].mean())/(data[col].max()-data[col].min())).astype(dtype)\n",
        "    return data\n",
        "def display_tensor(x):\n",
        "    if type(x) is tuple:\n",
        "        img,msk = x\n",
        "        fig, axes = plt.subplots(ncols=2,nrows=1)\n",
        "        axes.ravel()[0].imshow(img[0,:,:].cpu().numpy(),cmap='gray')\n",
        "        axes.ravel()[0].set_title('Image')\n",
        "        axes.ravel()[1].imshow(msk[0,:,:].numpy(),cmap='gray')\n",
        "        axes.ravel()[1].set_title('Mask')\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.imshow(x[0,:,:].cpu().numpy(),cmap='gray')\n",
        "def adjust_learning_rate(optimizerr,lr):\n",
        "    for param_group in optimizerr.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
        "    auth.authenticate_user()\n",
        "    gauth = GoogleAuth()\n",
        "    gauth.credentials = GoogleCredentials.get_application_default()\n",
        "    drive = GoogleDrive(gauth)\n",
        "    torch.save(state, filename)\n",
        "    uploaded = drive.CreateFile({'title': 'MixNetv1_epoch'+str(state['epoch'])+'.pt'})\n",
        "    uploaded.SetContentFile(filename)\n",
        "    uploaded.Upload()\n",
        "def load_checkpoint(args):\n",
        "     \n",
        "    if os.path.isfile(args):\n",
        "        print(\"=> loading checkpoint '{}'\".format(args))\n",
        "        checkpoint = torch.load(args)\n",
        "        epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
        "              .format(args, checkpoint['epoch']))\n",
        "    else:\n",
        "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WQqHFGhDI3hB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Dataset Class"
      ]
    },
    {
      "metadata": {
        "id": "g7cGzjj-I56S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TGS_dataset(Dataset):\n",
        "    '''\n",
        "    This is the dataset class that feeds the data to the model.\n",
        "    It has been created with a specific file organization in mind as given below:\n",
        "    test.csv\n",
        "    root/\n",
        "      |---train.csv\n",
        "      |---depths.csv\n",
        "      |--train/\n",
        "      |   |---images/\n",
        "      |   |       -images...\n",
        "      |   |---masks/\n",
        "      |          -masks...\n",
        "      |--test/\n",
        "      |   |---images/\n",
        "      |   |       -images...\n",
        "      |   |---masks/\n",
        "      |          -masks...\n",
        "       \n",
        "      The transform method can be made more efficient while running on test by checking is_train=False and then skipping over mask\n",
        "    '''\n",
        "    def __init__(self,root='./',is_train=True):\n",
        "        depths = normalize(pd.read_csv(root+'depths.csv'), ['z'])\n",
        "        if(is_train):\n",
        "            self.input = pd.read_csv(root+'train.csv').merge(depths, on='id', how='left')\n",
        "            self.input.drop(['rle_mask'], axis=1, inplace=True)\n",
        "            self.image_dir = root+'train/images'\n",
        "            self.mask_dir = root+'train/masks'\n",
        "        else:\n",
        "            self.input = pd.read_csv('test.csv').merge(depths, on='id', how='left')\n",
        "            self.image_dir = root+'test/images'\n",
        "        self.is_train = is_train\n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.input)\n",
        "\n",
        "    \n",
        "    def transform(self,image,mask,depth):\n",
        "#         image, mask =  TF.to_grayscale(image), TF.to_grayscale(mask)\n",
        "        mask = TF.to_grayscale(mask)\n",
        "        resize = transforms.Resize((128,128))\n",
        "        image,mask = resize(image), resize(mask)\n",
        "        # Random horizontal flipping\n",
        "        if random.random() > 0.5:\n",
        "            image = TF.hflip(image)\n",
        "            mask = TF.hflip(mask)\n",
        "\n",
        "        # Random vertical flipping\n",
        "        if random.random() > 0.5:\n",
        "            image = TF.vflip(image)\n",
        "            mask = TF.vflip(mask)\n",
        "\n",
        "        # Transform to tensor\n",
        "        image = TF.to_tensor(image)\n",
        "        mask = TF.to_tensor(mask).view(128,128)\n",
        "\n",
        "        # append depth data to image\n",
        "#         d = torch.ones((1)).new_full((1,128,128),depth)\n",
        "#         image = torch.cat((image,d),0)\n",
        "\n",
        "        return image, mask\n",
        "        \n",
        "            \n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir,self.input.iloc[idx,0]+\".png\")\n",
        "        img = Image.open(img_name)\n",
        "        if self.is_train :\n",
        "            msk = Image.open(os.path.join(self.mask_dir,self.input.iloc[idx,0]+\".png\"))\n",
        "        else:\n",
        "            msk = img\n",
        "        depth = self.input.iloc[idx,1]\n",
        "        img,msk = self.transform(img,msk,float(depth))\n",
        "        if self.is_train: return img,msk\n",
        "        else : return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ALv3mSmeXzkT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_dataset = TGS_dataset(is_train = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c77lFWMVXhEC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model Area"
      ]
    },
    {
      "metadata": {
        "id": "HM2uWdH-Xotg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Down(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super(Down, self).__init__()\n",
        "        self.down = nn.Sequential(nn.Conv2d(in_channels,out_channels,(3,3),stride=1, padding=1),\n",
        "                                 nn.AvgPool2d(kernel_size=(2,2)),\n",
        "                                 nn.BatchNorm2d(out_channels),\n",
        "                                  nn.ReLU()\n",
        "                                 )\n",
        "    def forward(self,x):\n",
        "#         print(x.shape)\n",
        "        return self.down(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lZMhEnGQdzoZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Up(nn.Module):\n",
        "    def __init__(self,in_channels, out_channels,size):\n",
        "        super(Up,self).__init__()\n",
        "#         self.upscale = nn.Upsample(scale_factor= 2)\n",
        "        self.upscale = nn.ConvTranspose2d(in_channels = in_channels, out_channels = out_channels, kernel_size = (2,2),stride=2)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.out_channels = out_channels\n",
        "        self.nonlin1 = nn.ReLU()\n",
        "        self.nonlin2 = nn.ReLU()\n",
        "        self.size = size\n",
        "        self.noe = size ** 2\n",
        "        \n",
        "#         self.bilinear = nn.Bilinear(self.noe ,self.noe ,self.noe )\n",
        "                \n",
        "    def forward(self,x1, x2):\n",
        "        x1 = self.upscale(x1)\n",
        "        x1 = self.bn(x1)\n",
        "        x1 = self.nonlin1(x1)\n",
        "#         print(x1.shape)\n",
        "#         print(x2.shape)\n",
        "        x = torch.cat((x1, x2),dim=1)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7eteCM3sd1kR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,no_features=2048,in_size=(4,4),out_size=(128,128),in_channels=3):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.down1 = Down(in_channels,32)\n",
        "        self.down2 = Down(32,128)\n",
        "        self.down3 = Down(128,256)\n",
        "        self.down4 = Down(256,512)\n",
        "        \n",
        "        self.up1 = Up(2048, 512, 8)\n",
        "        self.up2 = Up(1024, 256, 16)\n",
        "        self.up3 = Up(512, 128, 32)\n",
        "        self.up4 = Up(256, 32, 64)\n",
        "        self.up5 = Up(64,5,128)\n",
        "        \n",
        "        \n",
        "    def forward(self,img,feats):\n",
        "        x1 = self.down1(img)\n",
        "        x2 = self.down2(x1)\n",
        "        x3 = self.down3(x2)\n",
        "        x4 = self.down4(x3)\n",
        "        \n",
        "        x = self.up1(feats, x4)\n",
        "        x = self.up2(x,x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x,x1)\n",
        "        x = self.up5(x,img)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-xULd5g7RtYE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### importing Se Resnext 50 trained on imagenet"
      ]
    },
    {
      "metadata": {
        "id": "a23h4ycMQrIc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MixNet(nn.Module):\n",
        "    def __init__(self,in_channels = 3, out_channels=1, base= 'se_resnext50_32x4d'):\n",
        "        super(MixNet, self).__init__()\n",
        "        self.resnet = pretrainedmodels.__dict__[base](num_classes=1000, pretrained='imagenet')\n",
        "        self.decoder = Decoder()\n",
        "        self.conv = nn.Conv3d(1,1,kernel_size=(8,1,1),stride=(8,1,1))\n",
        "        \n",
        "    def forward(self,x):\n",
        "        feats = self.resnet.features(x)\n",
        "        x = self.decoder(x,feats)\n",
        "        x.unsqueeze_(1)\n",
        "        x = self.conv(x)\n",
        "        x = x.view(-1,128,128)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BkJCbC62jp1b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HPrgWtu2wXtU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "validation_split = 0.1\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "validation_sampler = SubsetRandomSampler(val_indices)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size,sampler=train_sampler)\n",
        "validation_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ILpmwaDtwXth",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BinaryCrossEntropyLoss2d(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        \"\"\"\n",
        "        Binary cross entropy loss 2D\n",
        "        Args:\n",
        "            weight:\n",
        "            size_average:\n",
        "        \"\"\"\n",
        "        super(BinaryCrossEntropyLoss2d, self).__init__()\n",
        "        self.bce_loss = nn.BCELoss(weight, size_average)\n",
        "        if torch.cuda.is_available():\n",
        "            self.bce_loss = self.bce_loss.cuda()\n",
        "        self.threshold = torch.tensor(0.3,requires_grad=True).cuda()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "#         pred = F.sigmoid(pred)\n",
        "        threshold=0.3\n",
        "        pred1 = ((pred>(1-self.threshold)) * (pred<(1+self.threshold))).float().cuda()\n",
        "        pred1 = pred1.view(-1)  # Flatten\n",
        "        target = target.view(-1)  # Flatten\n",
        "        return self.bce_loss(pred1, target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cLvCr3IQwXtm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SoftDiceLoss, self).__init__()\n",
        "    def forward(self, pred, target):\n",
        "        smooth = 1\n",
        "        num = target.size(0)\n",
        "        #pred = F.sigmoid(pred)\n",
        "        pred = pred.view(num, -1)\n",
        "        target = target.view(num, -1)\n",
        "        intersection = (pred * target)\n",
        "        score = 2. * (intersection.sum(1) + smooth) / (pred.sum(1) + target.sum(1) + smooth)\n",
        "        score = 1 - score.sum() / num\n",
        "        return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9CU7PcdGwXtt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_coeff(pred, target):\n",
        "    smooth = 1.\n",
        "    num = target.size(0)\n",
        "    pred = pred.view(num, -1)  # Flatten\n",
        "    target = target.view(num, -1)  # Flatten\n",
        "    intersection = (pred * target)\n",
        "    score = (2. * intersection.sum(1) + smooth).float() / (pred.sum(1) + target.sum(1) + smooth).float()\n",
        "    return score.sum()/num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcxIxXq5wXtz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return 0.5*BinaryCrossEntropyLoss2d()(y_true, y_pred)-dice_coeff(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OL9OQNTawXt-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model=MixNet().float()\n",
        "criterion =  SoftDiceLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum=0.9)\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "krdeJDd5wXuL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate():\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    model.eval()\n",
        "    for batch_idx, (data,target) in enumerate(validation_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data = data.cuda()\n",
        "            target = target.cuda()\n",
        "        # forward\n",
        "        output = model(data)\n",
        "        predict = output>0.5\n",
        "        predict = predict.float()\n",
        "        # backward + optimize\n",
        "        loss = criterion(output, target)\n",
        "        # print statistics\n",
        "        accuracy = dice_coeff(predict.view_as(target),target)\n",
        "        total_accuracy+=accuracy.item()\n",
        "        total_loss+=loss.item()\n",
        "    print('Validation Loss: {:.5f} Validation Accuracy: {:.5f}'.format(total_loss*batch_size/len(val_indices),total_accuracy*batch_size/len(val_indices)))\n",
        "    return total_loss,total_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7ci5neK7wXuU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(epoch=1):\n",
        "    loss_train_data = []\n",
        "    accuracy_train_data = []\n",
        "    loss_test_data = []\n",
        "    accuracy_test_data = []\n",
        "    epoch_data=[]\n",
        "    while True:\n",
        "        total_loss = 0\n",
        "        total_accuracy = 0\n",
        "        model.train()\n",
        "#         if epoch%5==0:\n",
        "#             save_checkpoint({\n",
        "#                 'epoch': epoch + 1,\n",
        "#                 'state_dict': model.state_dict(),\n",
        "#                 'optimizer' : optimizer.state_dict(),\n",
        "#                 })\n",
        "        exp_lr_scheduler.step()\n",
        "        print(exp_lr_scheduler.get_lr())\n",
        "        for batch_idx, data in enumerate(train_loader):\n",
        "            X,target = data\n",
        "            \n",
        "            if torch.cuda.is_available():\n",
        "                X = X.cuda()\n",
        "                target = target.cuda()\n",
        "            # forward\n",
        "            output = model(X)\n",
        "            predict = output>0.5\n",
        "            predict = predict.float()\n",
        "            # backward + optimize\n",
        "            loss = criterion(output, target)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # print statistics\n",
        "            accuracy = dice_coeff(predict.view_as(target),target)\n",
        "            total_accuracy+=accuracy.item()\n",
        "            total_loss+=loss.item()\n",
        "            print('Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.5f}\\tAccuracy: {:.5f}'.format(epoch, (batch_idx + 1) * batch_size, len(train_indices),100*(batch_idx + 1)* batch_size / len(train_indices), loss.item(),accuracy))\n",
        "        print('Train Loss: {:.5f} Train Accuracy: {:.5f}'.format(total_loss*batch_size/len(train_indices),total_accuracy*batch_size/len(train_indices)))\n",
        "        loss,accuracy = validate()\n",
        "        # Data append\n",
        "        loss_train_data.append(total_loss*batch_size/len(train_indices))\n",
        "        loss_test_data.append(loss*batch_size/len(val_indices))\n",
        "        accuracy_train_data.append(total_accuracy*batch_size/len(train_indices))\n",
        "        accuracy_test_data.append(accuracy*batch_size/len(val_indices))\n",
        "        epoch_data.append(epoch)\n",
        "        # Visualize\n",
        "        plt.figure(figsize=(10,5))\n",
        "#         plt.plot(epoch_data, loss_train_data,label=\"Train Loss {:.5f}\".format(loss_train_data[-1]))\n",
        "        plt.plot(epoch_data, accuracy_train_data,label=\"Train Accuracy {:.5f}\".format(accuracy_train_data[-1]))\n",
        "#         plt.plot(epoch_data,loss_test_data, label=\"Validation Loss {:.5f}\".format(loss_test_data[-1]))\n",
        "        plt.plot(epoch_data,accuracy_test_data,label=\"Validation Accuracy {:.5f}\".format(accuracy_test_data[-1]))\n",
        "        display.clear_output(wait=False)\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        epoch+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1XQF7jq5wXud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2380
        },
        "outputId": "abd27cd5-d732-4f72-983a-1002998ce2d2"
      },
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAEvCAYAAACQQh9CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIgFT4BIREREJmAKXiIiISMD+H4jvWs2fqRRoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f06d087ecf8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.1]\n",
            "Epoch: 22 [50/3600 (1%)]\tLoss: 0.03049\tAccuracy: 0.30113\n",
            "Epoch: 22 [100/3600 (3%)]\tLoss: 0.03748\tAccuracy: 0.28598\n",
            "Epoch: 22 [150/3600 (4%)]\tLoss: 0.07803\tAccuracy: 0.27039\n",
            "Epoch: 22 [200/3600 (6%)]\tLoss: 0.02234\tAccuracy: 0.31333\n",
            "Epoch: 22 [250/3600 (7%)]\tLoss: 0.06234\tAccuracy: 0.30111\n",
            "Epoch: 22 [300/3600 (8%)]\tLoss: -0.03546\tAccuracy: 0.31531\n",
            "Epoch: 22 [350/3600 (10%)]\tLoss: 0.01290\tAccuracy: 0.30774\n",
            "Epoch: 22 [400/3600 (11%)]\tLoss: -0.01954\tAccuracy: 0.28721\n",
            "Epoch: 22 [450/3600 (12%)]\tLoss: 0.10135\tAccuracy: 0.28015\n",
            "Epoch: 22 [500/3600 (14%)]\tLoss: 0.01172\tAccuracy: 0.26237\n",
            "Epoch: 22 [550/3600 (15%)]\tLoss: 0.03385\tAccuracy: 0.29573\n",
            "Epoch: 22 [600/3600 (17%)]\tLoss: -0.07956\tAccuracy: 0.37219\n",
            "Epoch: 22 [650/3600 (18%)]\tLoss: 0.28723\tAccuracy: 0.23872\n",
            "Epoch: 22 [700/3600 (19%)]\tLoss: -0.03440\tAccuracy: 0.28270\n",
            "Epoch: 22 [750/3600 (21%)]\tLoss: -0.10730\tAccuracy: 0.34510\n",
            "Epoch: 22 [800/3600 (22%)]\tLoss: 0.05022\tAccuracy: 0.30880\n",
            "Epoch: 22 [850/3600 (24%)]\tLoss: 0.43532\tAccuracy: 0.16523\n",
            "Epoch: 22 [900/3600 (25%)]\tLoss: 0.07049\tAccuracy: 0.30409\n",
            "Epoch: 22 [950/3600 (26%)]\tLoss: 0.16856\tAccuracy: 0.22921\n",
            "Epoch: 22 [1000/3600 (28%)]\tLoss: 0.06738\tAccuracy: 0.30124\n",
            "Epoch: 22 [1050/3600 (29%)]\tLoss: -0.26897\tAccuracy: 0.40347\n",
            "Epoch: 22 [1100/3600 (31%)]\tLoss: 0.00756\tAccuracy: 0.30245\n",
            "Epoch: 22 [1150/3600 (32%)]\tLoss: -0.22679\tAccuracy: 0.37543\n",
            "Epoch: 22 [1200/3600 (33%)]\tLoss: 0.01484\tAccuracy: 0.35878\n",
            "Epoch: 22 [1250/3600 (35%)]\tLoss: -0.27969\tAccuracy: 0.43442\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-5a27b39b473e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6ce32612bce2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pretrainedmodels/models/senet.py\u001b[0m in \u001b[0;36mfeatures\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pretrainedmodels/models/senet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1253\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m     )\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Gxraqy4nfoB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c168cbc9-4399-45b1-a224-5cfb3dc9a49a"
      },
      "cell_type": "code",
      "source": [
        "validate()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.76341 Validation Accuracy: 0.11626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qYFODkVXiwGn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tp6hWpoo0Gj_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Review \n",
        "The training was total disaster and the accuracy stooped improving\n",
        "Probable causes:\n",
        "Loss function which was very naive of me to use"
      ]
    }
  ]
}