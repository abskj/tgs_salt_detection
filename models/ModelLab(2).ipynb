{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nUnet based model for detecting salt regions in seismic images\\nInput:\\nImage 101x101 [0,1]\\nTransform:\\nNone(for now)\\nOutput:\\n101x101 matrix with pixel wise confidence values for salt presence\\n\\nStructure:\\nDN: A FC layer to create a kernel that applies on the images\\nUN: A  unet image classifier\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Unet based model for detecting salt regions in seismic images\n",
    "Input:\n",
    "Image 101x101 [0,1]\n",
    "Transform:\n",
    "None(for now)\n",
    "Output:\n",
    "101x101 matrix with pixel wise confidence values for salt presence\n",
    "\n",
    "Structure:\n",
    "DN: A FC layer to create a kernel that applies on the images\n",
    "UN: A  unet image classifier\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DN(nn.Module):\n",
    "    '''\n",
    "    @IN\n",
    "    img: A tensor representing the grayscaled image; shape:[batch_size,1,101,101]\n",
    "    d: The z index of the image\n",
    "    \n",
    "    @OUT\n",
    "    shape:[batch_size,1,101,101] tensor representing the features found by kernel(3*3) created from depth value\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(DN,self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(4,9,bias=False),\n",
    "                                   nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(nn.Linear(9,9,bias=True),\n",
    "                                   nn.Sigmoid())\n",
    "        self.conv1 = nn.Conv2d(1,1,kernel_size=3,stride=1,padding=1,bias=False)\n",
    "        self.non_linear1 = nn.ReLU()\n",
    "    def forward(self,x,d):\n",
    "        ker = torch.from_numpy(np.array([d,d**2,d**3,1])).float()\n",
    "        ker = self.layer1(ker)\n",
    "        ker = self.layer2(ker).view(1,1,3,3)\n",
    "        self.conv1.weight = nn.Parameter(ker)\n",
    "        x = self.non_linear1(self.conv1(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 101, 101])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10,1,101,101)\n",
    "y = torch.randn(10,1)\n",
    "model =DN()\n",
    "model(x,45).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class inconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(inconv, self).__init__()\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(down, self).__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mpconv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, bilinear=True,up_size=None):\n",
    "        super(up, self).__init__()\n",
    "\n",
    "        #  would be a nice idea if the upsampling could be learned too,\n",
    "        #  but my machine do not have enough memory to handle all those weights\n",
    "        if bilinear:\n",
    "            if up_size:\n",
    "                self.up = nn.Upsample(size= up_size, mode='bilinear', align_corners=True)\n",
    "            else:\n",
    "                self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
    "\n",
    "        self.conv = double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffX = x1.size()[2] - x2.size()[2]\n",
    "        diffY = x1.size()[3] - x2.size()[3]\n",
    "        x2 = F.pad(x2, (diffX // 2 , int(diffX / 2),\n",
    "                        diffY // 2, int(diffY / 2)))\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class outconv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(outconv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "class conv3d(nn.Module):\n",
    "    '''\n",
    "    Takes a image with given number of channels and performs 3d convolution and then returns the image as 2d\n",
    "    '''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(conv3d, self).__init__()\n",
    "        self.conv = nn.Conv3d(1, 10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self,debug=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.debug = debug\n",
    "        self.inc = inconv(1, 64)\n",
    "        self.down1 = down(64, 128)\n",
    "        self.down2 = down(128, 256)\n",
    "        self.down3 = down(256, 512)\n",
    "        self.down4 = down(512, 512)\n",
    "        self.up1 = up(1024, 256,up_size = (12,12))\n",
    "        self.up2 = up(512, 128,up_size = (25,25))\n",
    "        self.up3 = up(256, 64,up_size = (50,50))\n",
    "        self.up4 = up(128, 64,up_size = (101,101))\n",
    "        self.outc = outconv(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x.unsqueeze_(1)\n",
    "        if self.debug: print(x.shape)\n",
    "        x1 = self.inc(x)\n",
    "        if self.debug: print(x1.shape)\n",
    "        x2 = self.down1(x1)\n",
    "        if self.debug: print(x2.shape)\n",
    "        x3 = self.down2(x2)\n",
    "        if self.debug: print(x3.shape)\n",
    "        x4 = self.down3(x3)\n",
    "        if self.debug: print(x4.shape)\n",
    "        x5 = self.down4(x4)\n",
    "        if self.debug: print(x5.shape)\n",
    "        if self.debug: print('before up')\n",
    "        x = self.up1(x5, x4)\n",
    "        if self.debug: print(x.shape)\n",
    "        x = self.up2(x, x3)\n",
    "        if self.debug: print(x.shape)\n",
    "        x = self.up3(x, x2)\n",
    "        if self.debug: print(x.shape)\n",
    "        x = self.up4(x, x1)\n",
    "        if self.debug: print(x.shape)\n",
    "        x = self.outc(x)\n",
    "        if self.debug: print(x.shape)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 101, 101])\n",
      "torch.Size([10, 64, 101, 101])\n",
      "torch.Size([10, 128, 50, 50])\n",
      "torch.Size([10, 256, 25, 25])\n",
      "torch.Size([10, 512, 12, 12])\n",
      "torch.Size([10, 512, 6, 6])\n",
      "before up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 256, 12, 12])\n",
      "torch.Size([10, 128, 25, 25])\n",
      "torch.Size([10, 64, 50, 50])\n",
      "torch.Size([10, 64, 101, 101])\n",
      "torch.Size([10, 1, 101, 101])\n",
      "torch.Size([10, 101, 101])\n"
     ]
    }
   ],
   "source": [
    "model = UNet(debug=True)\n",
    "x = torch.randn(10,101,101)\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.1'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UDNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UDNet,self).__init__()\n",
    "        self.dn = DN_()\n",
    "        self.un1 = UNet(debug=True)\n",
    "        self.un2 = UNet(debug=True)\n",
    "    def forward(self,x,d):\n",
    "        x = self.un1(x)\n",
    "        x.unsqueeze_(1)\n",
    "        x = self.dn(x,d)\n",
    "        x.squeeze_(1)\n",
    "        x = self.un2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 101, 101])\n",
      "torch.Size([10, 64, 101, 101])\n",
      "torch.Size([10, 128, 50, 50])\n",
      "torch.Size([10, 256, 25, 25])\n",
      "torch.Size([10, 512, 12, 12])\n",
      "torch.Size([10, 512, 6, 6])\n",
      "before up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 256, 12, 12])\n",
      "torch.Size([10, 128, 25, 25])\n",
      "torch.Size([10, 64, 50, 50])\n",
      "torch.Size([10, 64, 101, 101])\n",
      "torch.Size([10, 1, 101, 101])\n",
      "torch.Size([10, 1, 101, 101])\n",
      "torch.Size([10, 64, 101, 101])\n",
      "torch.Size([10, 128, 50, 50])\n",
      "torch.Size([10, 256, 25, 25])\n",
      "torch.Size([10, 512, 12, 12])\n",
      "torch.Size([10, 512, 6, 6])\n",
      "before up\n"
     ]
    }
   ],
   "source": [
    "model = UDNet()\n",
    "x = torch.randn(10,101,101)\n",
    "print(model(x,2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
